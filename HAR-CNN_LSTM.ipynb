{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HAR CNN + LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train,\n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Build Convolutional Layer(s)\n",
    "\n",
    "Questions: \n",
    "* Should we use a different activation? Like tf.nn.tanh?\n",
    "* Should we use pooling? average or max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convolutional layers\n",
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 128, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    n_ch = n_channels *2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, pass to LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(conv1, [1,0,2]) # reshape into (seq_len, batch, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_ch]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define forward pass and cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-crnn') == False):\n",
    "    !mkdir checkpoints-crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.805513 Train acc: 0.173333\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.800610 Train acc: 0.188333\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.779288 Train acc: 0.233333\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.762740 Train acc: 0.258333\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.776284 Train acc: 0.230000\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.750286 Validation acc: 0.353333\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.748076 Train acc: 0.316667\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.737274 Train acc: 0.320000\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.744393 Train acc: 0.281667\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.733301 Train acc: 0.325000\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.682359 Train acc: 0.411667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.686710 Validation acc: 0.416667\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.692414 Train acc: 0.350000\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.671572 Train acc: 0.391667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.648381 Train acc: 0.390000\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.652862 Train acc: 0.366667\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.634961 Train acc: 0.378333\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.610955 Validation acc: 0.432778\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.626276 Train acc: 0.386667\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.618268 Train acc: 0.383333\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.600246 Train acc: 0.406667\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.549322 Train acc: 0.430000\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.566012 Train acc: 0.380000\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.524187 Validation acc: 0.461667\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.526553 Train acc: 0.426667\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.510153 Train acc: 0.431667\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.506012 Train acc: 0.435000\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.489927 Train acc: 0.463333\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.475247 Train acc: 0.463333\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.427328 Validation acc: 0.492222\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.465757 Train acc: 0.430000\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.462262 Train acc: 0.423333\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.371661 Train acc: 0.525000\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.399097 Train acc: 0.480000\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.338202 Train acc: 0.495000\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.315384 Validation acc: 0.536111\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.355636 Train acc: 0.476667\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.362162 Train acc: 0.451667\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.307165 Train acc: 0.523333\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.311393 Train acc: 0.510000\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.281741 Train acc: 0.496667\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.199100 Validation acc: 0.567778\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.284209 Train acc: 0.500000\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.205491 Train acc: 0.540000\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.230555 Train acc: 0.510000\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.193094 Train acc: 0.500000\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.181952 Train acc: 0.543333\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.105678 Validation acc: 0.567222\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.192287 Train acc: 0.525000\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.201871 Train acc: 0.498333\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.164965 Train acc: 0.520000\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.152007 Train acc: 0.491667\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.137227 Train acc: 0.540000\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.037588 Validation acc: 0.574444\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.072886 Train acc: 0.576667\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.115727 Train acc: 0.545000\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.052978 Train acc: 0.555000\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.091310 Train acc: 0.523333\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.109593 Train acc: 0.523333\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 0.982385 Validation acc: 0.588333\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.078735 Train acc: 0.551667\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.042299 Train acc: 0.556667\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.056391 Train acc: 0.555000\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.064821 Train acc: 0.538333\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.011934 Train acc: 0.566667\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 0.935766 Validation acc: 0.610556\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.021779 Train acc: 0.583333\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 0.995945 Train acc: 0.573333\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.014384 Train acc: 0.538333\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 0.995828 Train acc: 0.560000\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 0.997518 Train acc: 0.561667\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 0.894231 Validation acc: 0.627778\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 0.982794 Train acc: 0.561667\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 0.987857 Train acc: 0.561667\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 0.976406 Train acc: 0.573333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 0.928650 Train acc: 0.623333\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 0.948063 Train acc: 0.603333\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 0.857794 Validation acc: 0.635556\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 0.913892 Train acc: 0.590000\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 0.920664 Train acc: 0.596667\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 0.954493 Train acc: 0.568333\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 0.941455 Train acc: 0.608333\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 0.936433 Train acc: 0.595000\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 0.822844 Validation acc: 0.650555\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 0.932610 Train acc: 0.596667\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 0.899032 Train acc: 0.620000\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 0.871472 Train acc: 0.611667\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 0.883922 Train acc: 0.608333\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 0.863382 Train acc: 0.636667\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 0.792065 Validation acc: 0.666667\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 0.900825 Train acc: 0.593333\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 0.880227 Train acc: 0.618333\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 0.883146 Train acc: 0.613333\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.850290 Train acc: 0.633333\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 0.867644 Train acc: 0.641667\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.763327 Validation acc: 0.681111\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.862071 Train acc: 0.646667\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.874204 Train acc: 0.611667\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.851932 Train acc: 0.626667\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.814378 Train acc: 0.640000\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.855318 Train acc: 0.653333\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.742087 Validation acc: 0.690000\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.853429 Train acc: 0.616667\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.859136 Train acc: 0.608333\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.839307 Train acc: 0.635000\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.865019 Train acc: 0.600000\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.809777 Train acc: 0.650000\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.725137 Validation acc: 0.702222\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.782164 Train acc: 0.645000\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.784962 Train acc: 0.686667\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.785430 Train acc: 0.663333\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.802155 Train acc: 0.665000\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.800049 Train acc: 0.640000\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.702896 Validation acc: 0.711667\n",
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.816361 Train acc: 0.633333\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.754754 Train acc: 0.708333\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.805823 Train acc: 0.653333\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.795799 Train acc: 0.645000\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.757908 Train acc: 0.673333\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.681859 Validation acc: 0.732778\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.766528 Train acc: 0.690000\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.741530 Train acc: 0.703333\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.792653 Train acc: 0.656667\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.756358 Train acc: 0.666667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.784001 Train acc: 0.656667\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.660267 Validation acc: 0.761667\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.762072 Train acc: 0.678333\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.778541 Train acc: 0.671667\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.740083 Train acc: 0.695000\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.719934 Train acc: 0.701667\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.721806 Train acc: 0.701667\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.632301 Validation acc: 0.794444\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.700873 Train acc: 0.705000\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.714348 Train acc: 0.700000\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.711304 Train acc: 0.726667\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.733005 Train acc: 0.701667\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.698056 Train acc: 0.726667\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.600450 Validation acc: 0.800000\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.718993 Train acc: 0.731667\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.717369 Train acc: 0.713333\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.698379 Train acc: 0.730000\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.669683 Train acc: 0.765000\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.642670 Train acc: 0.755000\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.570031 Validation acc: 0.805000\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.681288 Train acc: 0.730000\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.668000 Train acc: 0.741667\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.690106 Train acc: 0.710000\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.661709 Train acc: 0.753333\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.649176 Train acc: 0.776667\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.535077 Validation acc: 0.822222\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.655462 Train acc: 0.740000\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.640270 Train acc: 0.738333\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.618735 Train acc: 0.791667\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.606095 Train acc: 0.775000\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.598847 Train acc: 0.786667\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.505890 Validation acc: 0.820556\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.587043 Train acc: 0.801667\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.622858 Train acc: 0.760000\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.577995 Train acc: 0.795000\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.610572 Train acc: 0.775000\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.633489 Train acc: 0.761667\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.480550 Validation acc: 0.839444\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.573986 Train acc: 0.798333\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.556556 Train acc: 0.803333\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.542708 Train acc: 0.813333\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.575988 Train acc: 0.801667\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.547999 Train acc: 0.811667\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.457392 Validation acc: 0.855556\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.578580 Train acc: 0.781667\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.564029 Train acc: 0.785000\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.551598 Train acc: 0.825000\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.569154 Train acc: 0.813333\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.560092 Train acc: 0.801667\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.426467 Validation acc: 0.863889\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.511119 Train acc: 0.831667\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.496359 Train acc: 0.828333\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.508726 Train acc: 0.848333\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.496844 Train acc: 0.858333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.542066 Train acc: 0.801667\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.401952 Validation acc: 0.869444\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.512733 Train acc: 0.843333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.513992 Train acc: 0.841667\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.509583 Train acc: 0.841667\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.492686 Train acc: 0.825000\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.479976 Train acc: 0.860000\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.374641 Validation acc: 0.888889\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.461612 Train acc: 0.855000\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.456633 Train acc: 0.870000\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.464548 Train acc: 0.875000\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.512888 Train acc: 0.843333\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.428040 Train acc: 0.890000\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.357433 Validation acc: 0.888333\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.461153 Train acc: 0.871667\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.495970 Train acc: 0.851667\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.447852 Train acc: 0.866667\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.444855 Train acc: 0.885000\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.420294 Train acc: 0.895000\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.328983 Validation acc: 0.908333\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.425430 Train acc: 0.896667\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.439156 Train acc: 0.886667\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.448175 Train acc: 0.865000\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.400924 Train acc: 0.896667\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.443702 Train acc: 0.888333\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.312291 Validation acc: 0.910556\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.440303 Train acc: 0.870000\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.392212 Train acc: 0.878333\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.379893 Train acc: 0.916667\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.369716 Train acc: 0.913333\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.395988 Train acc: 0.890000\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.297876 Validation acc: 0.920556\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.384467 Train acc: 0.910000\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.423916 Train acc: 0.878333\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.362952 Train acc: 0.915000\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.395317 Train acc: 0.891667\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.393992 Train acc: 0.900000\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.285675 Validation acc: 0.917222\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.366247 Train acc: 0.918333\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.356272 Train acc: 0.918333\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.325684 Train acc: 0.915000\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.371318 Train acc: 0.901667\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.350434 Train acc: 0.911667\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.260469 Validation acc: 0.930000\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.387522 Train acc: 0.895000\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.333206 Train acc: 0.923333\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.345501 Train acc: 0.908333\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.374971 Train acc: 0.911667\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.359066 Train acc: 0.918333\n",
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.250108 Validation acc: 0.933333\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.346422 Train acc: 0.911667\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.307108 Train acc: 0.943333\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.325623 Train acc: 0.935000\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.332389 Train acc: 0.913333\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.365550 Train acc: 0.903333\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.234921 Validation acc: 0.932778\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.310864 Train acc: 0.921667\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.334469 Train acc: 0.910000\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.344034 Train acc: 0.928333\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.324127 Train acc: 0.920000\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.312870 Train acc: 0.926667\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.221344 Validation acc: 0.937222\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.304120 Train acc: 0.925000\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.310888 Train acc: 0.943333\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.308984 Train acc: 0.925000\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.334463 Train acc: 0.905000\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.279785 Train acc: 0.943333\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.216150 Validation acc: 0.936111\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.318133 Train acc: 0.928333\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.320481 Train acc: 0.930000\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.289837 Train acc: 0.923333\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.295838 Train acc: 0.923333\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.293955 Train acc: 0.935000\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.206512 Validation acc: 0.937778\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.326600 Train acc: 0.915000\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.287819 Train acc: 0.941667\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.346626 Train acc: 0.901667\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.271344 Train acc: 0.941667\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.333306 Train acc: 0.910000\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.203310 Validation acc: 0.933333\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.320182 Train acc: 0.923333\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.288090 Train acc: 0.930000\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.285954 Train acc: 0.936667\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.279598 Train acc: 0.936667\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.291053 Train acc: 0.941667\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.192133 Validation acc: 0.939444\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.280158 Train acc: 0.931667\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.291203 Train acc: 0.921667\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.258540 Train acc: 0.953333\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.301889 Train acc: 0.910000\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.275945 Train acc: 0.931667\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.189881 Validation acc: 0.941667\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.264501 Train acc: 0.928333\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.285170 Train acc: 0.936667\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.251014 Train acc: 0.948333\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.262060 Train acc: 0.936667\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.248891 Train acc: 0.931667\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.183292 Validation acc: 0.940556\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.280226 Train acc: 0.926667\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.250207 Train acc: 0.950000\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.275245 Train acc: 0.928333\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.276752 Train acc: 0.928333\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.275587 Train acc: 0.928333\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.177314 Validation acc: 0.944444\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.261620 Train acc: 0.936667\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.247011 Train acc: 0.941667\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.247972 Train acc: 0.938333\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.259165 Train acc: 0.941667\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.290718 Train acc: 0.911667\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.174592 Validation acc: 0.943333\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.256383 Train acc: 0.933333\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.279706 Train acc: 0.928333\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.277551 Train acc: 0.930000\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.273886 Train acc: 0.928333\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.269293 Train acc: 0.935000\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.170213 Validation acc: 0.945000\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.237607 Train acc: 0.950000\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.242549 Train acc: 0.945000\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.258083 Train acc: 0.940000\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.277689 Train acc: 0.926667\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.223203 Train acc: 0.951667\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.167498 Validation acc: 0.942778\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.275719 Train acc: 0.928333\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.256632 Train acc: 0.943333\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.247644 Train acc: 0.935000\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.243646 Train acc: 0.943333\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.230099 Train acc: 0.943333\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.168441 Validation acc: 0.941111\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.231280 Train acc: 0.951667\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.243828 Train acc: 0.943333\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.267654 Train acc: 0.923333\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.231814 Train acc: 0.945000\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.257903 Train acc: 0.941667\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.163538 Validation acc: 0.943333\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.248226 Train acc: 0.936667\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.245064 Train acc: 0.935000\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.252637 Train acc: 0.931667\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.222737 Train acc: 0.943333\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.236258 Train acc: 0.955000\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.159341 Validation acc: 0.945000\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.223734 Train acc: 0.946667\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.241396 Train acc: 0.938333\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.203275 Train acc: 0.958333\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.267575 Train acc: 0.918333\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.261074 Train acc: 0.928333\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.160300 Validation acc: 0.943333\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.242558 Train acc: 0.933333\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.207155 Train acc: 0.950000\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.225875 Train acc: 0.941667\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.203418 Train acc: 0.960000\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.229013 Train acc: 0.946667\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.154572 Validation acc: 0.946667\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.259828 Train acc: 0.933333\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.214981 Train acc: 0.950000\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.237859 Train acc: 0.936667\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.246590 Train acc: 0.943333\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.221069 Train acc: 0.938333\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.155693 Validation acc: 0.943889\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.224091 Train acc: 0.953333\n",
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.225446 Train acc: 0.941667\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.226910 Train acc: 0.950000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.224122 Train acc: 0.945000\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.234722 Train acc: 0.931667\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.155525 Validation acc: 0.942222\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.189680 Train acc: 0.961667\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.251931 Train acc: 0.926667\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.226536 Train acc: 0.936667\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.224234 Train acc: 0.938333\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.218004 Train acc: 0.948333\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.153952 Validation acc: 0.945556\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.211174 Train acc: 0.953333\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.228712 Train acc: 0.941667\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.215827 Train acc: 0.948333\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.234754 Train acc: 0.931667\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.216948 Train acc: 0.955000\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.149017 Validation acc: 0.945556\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.255154 Train acc: 0.925000\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.235007 Train acc: 0.935000\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.219157 Train acc: 0.941667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.216542 Train acc: 0.938333\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.209451 Train acc: 0.945000\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.143815 Validation acc: 0.941111\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.229965 Train acc: 0.943333\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.223205 Train acc: 0.940000\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.216652 Train acc: 0.945000\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.192994 Train acc: 0.950000\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.225173 Train acc: 0.933333\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.142333 Validation acc: 0.944444\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.227430 Train acc: 0.935000\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.220363 Train acc: 0.935000\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.215211 Train acc: 0.946667\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.194398 Train acc: 0.953333\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.220755 Train acc: 0.946667\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.148357 Validation acc: 0.940000\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.210804 Train acc: 0.945000\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.228946 Train acc: 0.928333\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.196055 Train acc: 0.951667\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.255080 Train acc: 0.921667\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.240781 Train acc: 0.923333\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.143956 Validation acc: 0.945556\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.211505 Train acc: 0.930000\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.217181 Train acc: 0.933333\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.190498 Train acc: 0.946667\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.203111 Train acc: 0.955000\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.221405 Train acc: 0.943333\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.141094 Validation acc: 0.943333\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.231200 Train acc: 0.926667\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.199384 Train acc: 0.953333\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.235715 Train acc: 0.926667\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.216761 Train acc: 0.940000\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.195052 Train acc: 0.940000\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.139505 Validation acc: 0.946111\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.204251 Train acc: 0.945000\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.182244 Train acc: 0.945000\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.196765 Train acc: 0.946667\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.207336 Train acc: 0.946667\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.226727 Train acc: 0.930000\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.140364 Validation acc: 0.945556\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.197145 Train acc: 0.951667\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.210986 Train acc: 0.950000\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.220468 Train acc: 0.941667\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.193898 Train acc: 0.943333\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.201839 Train acc: 0.951667\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.141601 Validation acc: 0.944444\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.181746 Train acc: 0.956667\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.196316 Train acc: 0.951667\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.201351 Train acc: 0.940000\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.228102 Train acc: 0.930000\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.186684 Train acc: 0.955000\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.130328 Validation acc: 0.945556\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.218907 Train acc: 0.936667\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.201039 Train acc: 0.943333\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.217699 Train acc: 0.936667\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.191527 Train acc: 0.943333\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.193030 Train acc: 0.938333\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.128520 Validation acc: 0.945556\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.182256 Train acc: 0.950000\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.215632 Train acc: 0.945000\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.213701 Train acc: 0.935000\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.180228 Train acc: 0.953333\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.231835 Train acc: 0.928333\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.135087 Validation acc: 0.945000\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.198777 Train acc: 0.945000\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.189374 Train acc: 0.948333\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.188955 Train acc: 0.953333\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.168307 Train acc: 0.960000\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.183304 Train acc: 0.946667\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.130718 Validation acc: 0.945556\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.205576 Train acc: 0.941667\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.214320 Train acc: 0.936667\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.163387 Train acc: 0.960000\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.212930 Train acc: 0.938333\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.199985 Train acc: 0.946667\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.133669 Validation acc: 0.946111\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.166160 Train acc: 0.956667\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.191602 Train acc: 0.945000\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.178313 Train acc: 0.956667\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.181947 Train acc: 0.953333\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.208333 Train acc: 0.931667\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.131422 Validation acc: 0.946111\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.200927 Train acc: 0.931667\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.166315 Train acc: 0.956667\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.213451 Train acc: 0.940000\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.194203 Train acc: 0.946667\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.188608 Train acc: 0.943333\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.128133 Validation acc: 0.947222\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.181002 Train acc: 0.945000\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.165390 Train acc: 0.945000\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.194031 Train acc: 0.953333\n",
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.178536 Train acc: 0.953333\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.200117 Train acc: 0.943333\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.132086 Validation acc: 0.945556\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.165417 Train acc: 0.956667\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.196075 Train acc: 0.936667\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.207481 Train acc: 0.948333\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.184756 Train acc: 0.936667\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.167210 Train acc: 0.953333\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.130022 Validation acc: 0.945556\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.176079 Train acc: 0.946667\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.187805 Train acc: 0.950000\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.189375 Train acc: 0.941667\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.201102 Train acc: 0.933333\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.172138 Train acc: 0.960000\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.128272 Validation acc: 0.946111\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.193910 Train acc: 0.940000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.198306 Train acc: 0.938333\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.184272 Train acc: 0.946667\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.186512 Train acc: 0.940000\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.164799 Train acc: 0.951667\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.130931 Validation acc: 0.946111\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.184212 Train acc: 0.958333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.185564 Train acc: 0.936667\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.203819 Train acc: 0.938333\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.147815 Train acc: 0.966667\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.186170 Train acc: 0.948333\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.126281 Validation acc: 0.948333\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.178952 Train acc: 0.948333\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.195950 Train acc: 0.938333\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.183676 Train acc: 0.948333\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.157735 Train acc: 0.958333\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.177692 Train acc: 0.951667\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.123202 Validation acc: 0.948333\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.189581 Train acc: 0.945000\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.194023 Train acc: 0.938333\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.152186 Train acc: 0.961667\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.205540 Train acc: 0.930000\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.196783 Train acc: 0.943333\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.125314 Validation acc: 0.948333\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.178467 Train acc: 0.946667\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.156262 Train acc: 0.955000\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.164939 Train acc: 0.958333\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.168485 Train acc: 0.956667\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.183506 Train acc: 0.950000\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.126000 Validation acc: 0.948889\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.189809 Train acc: 0.936667\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.142917 Train acc: 0.966667\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.198669 Train acc: 0.933333\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.195504 Train acc: 0.948333\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.174301 Train acc: 0.936667\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.118105 Validation acc: 0.950000\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.165862 Train acc: 0.946667\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.160818 Train acc: 0.948333\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.178440 Train acc: 0.951667\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.187089 Train acc: 0.953333\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.209078 Train acc: 0.933333\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.124266 Validation acc: 0.947778\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.150506 Train acc: 0.961667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.189598 Train acc: 0.930000\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.194465 Train acc: 0.943333\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.184751 Train acc: 0.951667\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.153643 Train acc: 0.960000\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.116994 Validation acc: 0.950000\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.154873 Train acc: 0.953333\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.153787 Train acc: 0.956667\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.187247 Train acc: 0.951667\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.180063 Train acc: 0.945000\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.126481 Train acc: 0.968333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.116102 Validation acc: 0.951667\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.180394 Train acc: 0.930000\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.172005 Train acc: 0.958333\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.172121 Train acc: 0.953333\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.155383 Train acc: 0.958333\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.140890 Train acc: 0.963333\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.118051 Validation acc: 0.950556\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.174447 Train acc: 0.955000\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.163478 Train acc: 0.940000\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.193111 Train acc: 0.933333\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.142784 Train acc: 0.963333\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.195191 Train acc: 0.935000\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.126261 Validation acc: 0.948889\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.183342 Train acc: 0.951667\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.180663 Train acc: 0.948333\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.155635 Train acc: 0.946667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.142463 Train acc: 0.953333\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.143645 Train acc: 0.960000\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.125160 Validation acc: 0.949444\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.185557 Train acc: 0.946667\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.195924 Train acc: 0.940000\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.133237 Train acc: 0.970000\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.178324 Train acc: 0.940000\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.185937 Train acc: 0.943333\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.120835 Validation acc: 0.951667\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.172873 Train acc: 0.945000\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.154725 Train acc: 0.953333\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.150124 Train acc: 0.956667\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.160157 Train acc: 0.958333\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.167315 Train acc: 0.950000\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.109405 Validation acc: 0.954444\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.186032 Train acc: 0.943333\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.119289 Train acc: 0.966667\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.185063 Train acc: 0.941667\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.188146 Train acc: 0.945000\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.162952 Train acc: 0.948333\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.122477 Validation acc: 0.948889\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.138510 Train acc: 0.960000\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.144550 Train acc: 0.960000\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.163975 Train acc: 0.955000\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.164410 Train acc: 0.951667\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.183410 Train acc: 0.940000\n",
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.125479 Validation acc: 0.950000\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.126380 Train acc: 0.970000\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.180024 Train acc: 0.943333\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.174241 Train acc: 0.945000\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.164134 Train acc: 0.956667\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.124258 Train acc: 0.968333\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.115535 Validation acc: 0.955000\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.136288 Train acc: 0.965000\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.146736 Train acc: 0.955000\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.174381 Train acc: 0.946667\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.167044 Train acc: 0.948333\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.112111 Train acc: 0.978333\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.112524 Validation acc: 0.952778\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.177411 Train acc: 0.940000\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.172026 Train acc: 0.936667\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.159751 Train acc: 0.955000\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.132157 Train acc: 0.961667\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.150425 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.109031 Validation acc: 0.956667\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.156211 Train acc: 0.958333\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.172853 Train acc: 0.940000\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.179515 Train acc: 0.943333\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.116096 Train acc: 0.966667\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.172343 Train acc: 0.938333\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.109398 Validation acc: 0.953889\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.164444 Train acc: 0.950000\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.158316 Train acc: 0.948333\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.138884 Train acc: 0.955000\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.134825 Train acc: 0.953333\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.144922 Train acc: 0.965000\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.107005 Validation acc: 0.957222\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.169020 Train acc: 0.951667\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.161791 Train acc: 0.943333\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.135242 Train acc: 0.956667\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.167230 Train acc: 0.945000\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.151227 Train acc: 0.956667\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.114698 Validation acc: 0.952778\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.151256 Train acc: 0.955000\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.146384 Train acc: 0.956667\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.137574 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.168637 Train acc: 0.956667\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.173892 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.116140 Validation acc: 0.953889\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.165578 Train acc: 0.941667\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.123392 Train acc: 0.966667\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.166602 Train acc: 0.941667\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.182685 Train acc: 0.941667\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.152221 Train acc: 0.946667\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.106844 Validation acc: 0.958333\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.116273 Train acc: 0.970000\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.146464 Train acc: 0.965000\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.133050 Train acc: 0.961667\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.180424 Train acc: 0.946667\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.162433 Train acc: 0.946667\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.110762 Validation acc: 0.956667\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.137956 Train acc: 0.958333\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.190819 Train acc: 0.926667\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.168312 Train acc: 0.951667\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.151009 Train acc: 0.951667\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.132600 Train acc: 0.961667\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.106239 Validation acc: 0.957222\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.131476 Train acc: 0.963333\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.150058 Train acc: 0.956667\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.163724 Train acc: 0.948333\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.184680 Train acc: 0.945000\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.104017 Train acc: 0.971667\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.102589 Validation acc: 0.957222\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.175058 Train acc: 0.936667\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.164307 Train acc: 0.953333\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.146302 Train acc: 0.946667\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.135275 Train acc: 0.955000\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.119432 Train acc: 0.970000\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.101247 Validation acc: 0.959444\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.143338 Train acc: 0.960000\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.143193 Train acc: 0.955000\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.165453 Train acc: 0.940000\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.131875 Train acc: 0.961667\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.172564 Train acc: 0.943333\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.112780 Validation acc: 0.957222\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.169189 Train acc: 0.950000\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.148963 Train acc: 0.961667\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.142745 Train acc: 0.953333\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.150540 Train acc: 0.948333\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.157416 Train acc: 0.955000\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.101002 Validation acc: 0.958333\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.157625 Train acc: 0.958333\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.168562 Train acc: 0.943333\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.111984 Train acc: 0.965000\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.148862 Train acc: 0.953333\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.167926 Train acc: 0.943333\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.094894 Validation acc: 0.959445\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.139447 Train acc: 0.955000\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.133074 Train acc: 0.955000\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.130769 Train acc: 0.965000\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.143829 Train acc: 0.958333\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.151070 Train acc: 0.948333\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.092350 Validation acc: 0.960556\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.168401 Train acc: 0.941667\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.116548 Train acc: 0.970000\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.174253 Train acc: 0.935000\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.162859 Train acc: 0.948333\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.146155 Train acc: 0.958333\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.097163 Validation acc: 0.959444\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.118717 Train acc: 0.965000\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.119974 Train acc: 0.963333\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.148590 Train acc: 0.966667\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.150789 Train acc: 0.956667\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.164661 Train acc: 0.943333\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.106635 Validation acc: 0.956667\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.099929 Train acc: 0.975000\n",
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.161371 Train acc: 0.946667\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.155475 Train acc: 0.948333\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.131514 Train acc: 0.955000\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.128796 Train acc: 0.958333\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.103834 Validation acc: 0.956111\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.133440 Train acc: 0.953333\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.159321 Train acc: 0.961667\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.156200 Train acc: 0.951667\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.170370 Train acc: 0.933333\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.115519 Train acc: 0.966667\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.098687 Validation acc: 0.959445\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.159699 Train acc: 0.945000\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.169868 Train acc: 0.948333\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.151369 Train acc: 0.948333\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.114769 Train acc: 0.965000\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.128203 Train acc: 0.961667\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.100870 Validation acc: 0.958333\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.127577 Train acc: 0.966667\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.151901 Train acc: 0.950000\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.161368 Train acc: 0.943333\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.116117 Train acc: 0.963333\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.154261 Train acc: 0.940000\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.108919 Validation acc: 0.956111\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.152438 Train acc: 0.951667\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.130221 Train acc: 0.956667\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.112675 Train acc: 0.966667\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.128172 Train acc: 0.955000\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.139470 Train acc: 0.958333\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.110118 Validation acc: 0.956667\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.173854 Train acc: 0.953333\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.178719 Train acc: 0.941667\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.114583 Train acc: 0.971667\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.147213 Train acc: 0.950000\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.168213 Train acc: 0.938333\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.097285 Validation acc: 0.960000\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.130435 Train acc: 0.955000\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.116669 Train acc: 0.968333\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.123908 Train acc: 0.961667\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.129790 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.152797 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.097405 Validation acc: 0.962778\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.157981 Train acc: 0.943333\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.107432 Train acc: 0.971667\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.174921 Train acc: 0.936667\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.155357 Train acc: 0.950000\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.148400 Train acc: 0.955000\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.094782 Validation acc: 0.961667\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.122747 Train acc: 0.961667\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.116293 Train acc: 0.968333\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.136353 Train acc: 0.965000\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.158271 Train acc: 0.946667\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.160431 Train acc: 0.943333\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.097446 Validation acc: 0.960000\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.111569 Train acc: 0.968333\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.156090 Train acc: 0.945000\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.140178 Train acc: 0.955000\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.135544 Train acc: 0.941667\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.116355 Train acc: 0.965000\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.102139 Validation acc: 0.958333\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.107765 Train acc: 0.968333\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.136618 Train acc: 0.961667\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.137813 Train acc: 0.953333\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.151143 Train acc: 0.941667\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.112041 Train acc: 0.963333\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.101595 Validation acc: 0.958889\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.154649 Train acc: 0.953333\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.162337 Train acc: 0.948333\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.127420 Train acc: 0.958333\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.124006 Train acc: 0.966667\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.111422 Train acc: 0.960000\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.095607 Validation acc: 0.960000\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.125618 Train acc: 0.965000\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.143938 Train acc: 0.955000\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.154271 Train acc: 0.951667\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.108298 Train acc: 0.975000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.152168 Train acc: 0.943333\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.102757 Validation acc: 0.957222\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.157356 Train acc: 0.951667\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.132022 Train acc: 0.961667\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.113710 Train acc: 0.965000\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.102950 Train acc: 0.968333\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.125523 Train acc: 0.970000\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.100918 Validation acc: 0.958333\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.128973 Train acc: 0.955000\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.142195 Train acc: 0.948333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.110241 Train acc: 0.968333\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.149694 Train acc: 0.951667\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.152006 Train acc: 0.946667\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.105169 Validation acc: 0.955000\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.133936 Train acc: 0.953333\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.115536 Train acc: 0.961667\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.112906 Train acc: 0.958333\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.130950 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.138011 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.096387 Validation acc: 0.959444\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.149192 Train acc: 0.945000\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.107075 Train acc: 0.963333\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.158237 Train acc: 0.946667\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.155829 Train acc: 0.951667\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.134568 Train acc: 0.955000\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.095578 Validation acc: 0.961111\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.108307 Train acc: 0.965000\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.117155 Train acc: 0.961667\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.127300 Train acc: 0.965000\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.142009 Train acc: 0.956667\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.148090 Train acc: 0.943333\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.105001 Validation acc: 0.957222\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.108218 Train acc: 0.980000\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.148172 Train acc: 0.940000\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.161511 Train acc: 0.943333\n",
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.142346 Train acc: 0.955000\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.125739 Train acc: 0.953333\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.097840 Validation acc: 0.958333\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.109558 Train acc: 0.963333\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.127481 Train acc: 0.966667\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.132459 Train acc: 0.961667\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.149483 Train acc: 0.943333\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.095544 Train acc: 0.973333\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.101394 Validation acc: 0.958889\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.149369 Train acc: 0.948333\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.144744 Train acc: 0.951667\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.131909 Train acc: 0.956667\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.114759 Train acc: 0.963333\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.105525 Train acc: 0.965000\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.099141 Validation acc: 0.959444\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.124172 Train acc: 0.963333\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.155609 Train acc: 0.953333\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.146565 Train acc: 0.950000\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.110640 Train acc: 0.965000\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.148352 Train acc: 0.950000\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.098684 Validation acc: 0.959444\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.146710 Train acc: 0.940000\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.121994 Train acc: 0.958333\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.108537 Train acc: 0.966667\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.108873 Train acc: 0.958333\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.120959 Train acc: 0.961667\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.104926 Validation acc: 0.958333\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.134365 Train acc: 0.960000\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.157207 Train acc: 0.948333\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.104639 Train acc: 0.966667\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.151042 Train acc: 0.941667\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.154496 Train acc: 0.945000\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.114984 Validation acc: 0.956111\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.125659 Train acc: 0.956667\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.101222 Train acc: 0.973333\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.115429 Train acc: 0.958333\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.136281 Train acc: 0.955000\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.141340 Train acc: 0.958333\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.107570 Validation acc: 0.956667\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.149765 Train acc: 0.945000\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.096326 Train acc: 0.970000\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.146665 Train acc: 0.945000\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.148400 Train acc: 0.953333\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.131453 Train acc: 0.966667\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.093728 Validation acc: 0.957778\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.104967 Train acc: 0.961667\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.108299 Train acc: 0.965000\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.125176 Train acc: 0.958333\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.125665 Train acc: 0.960000\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.148927 Train acc: 0.946667\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.099478 Validation acc: 0.957778\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.100322 Train acc: 0.973333\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.146405 Train acc: 0.936667\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.151273 Train acc: 0.956667\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.116881 Train acc: 0.961667\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.116212 Train acc: 0.965000\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.093542 Validation acc: 0.960556\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.107444 Train acc: 0.965000\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.122632 Train acc: 0.968333\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.141847 Train acc: 0.955000\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.141279 Train acc: 0.953333\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.089535 Train acc: 0.970000\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.094652 Validation acc: 0.959444\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.144421 Train acc: 0.945000\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.153598 Train acc: 0.948333\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.122451 Train acc: 0.950000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.114217 Train acc: 0.963333\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.097881 Train acc: 0.970000\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.095064 Validation acc: 0.962222\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.125240 Train acc: 0.963333\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.119599 Train acc: 0.960000\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.142372 Train acc: 0.951667\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.095739 Train acc: 0.970000\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.133514 Train acc: 0.950000\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.097872 Validation acc: 0.960556\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.137293 Train acc: 0.948333\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.123910 Train acc: 0.955000\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.112714 Train acc: 0.968333\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.110599 Train acc: 0.953333\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.130029 Train acc: 0.965000\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.089533 Validation acc: 0.959444\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.134460 Train acc: 0.961667\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.140232 Train acc: 0.960000\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.097995 Train acc: 0.970000\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.147128 Train acc: 0.940000\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.142680 Train acc: 0.950000\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.094709 Validation acc: 0.958333\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.110248 Train acc: 0.966667\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.096912 Train acc: 0.970000\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.100613 Train acc: 0.966667\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.119476 Train acc: 0.958333\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.141697 Train acc: 0.948333\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.095613 Validation acc: 0.961667\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.139114 Train acc: 0.953333\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.084050 Train acc: 0.973333\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.146178 Train acc: 0.948333\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.124329 Train acc: 0.955000\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.126394 Train acc: 0.951667\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.100697 Validation acc: 0.961667\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.112778 Train acc: 0.961667\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.094206 Train acc: 0.970000\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.122393 Train acc: 0.961667\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.131991 Train acc: 0.955000\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.133344 Train acc: 0.956667\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.096140 Validation acc: 0.960000\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.090691 Train acc: 0.965000\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.141014 Train acc: 0.948333\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.133437 Train acc: 0.955000\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.120596 Train acc: 0.955000\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.102892 Train acc: 0.960000\n",
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.096569 Validation acc: 0.959444\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.097956 Train acc: 0.970000\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.117154 Train acc: 0.963333\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.124178 Train acc: 0.965000\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.148387 Train acc: 0.941667\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.110574 Train acc: 0.960000\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.094379 Validation acc: 0.960000\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.154381 Train acc: 0.945000\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.149175 Train acc: 0.955000\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.124850 Train acc: 0.955000\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.107893 Train acc: 0.955000\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.090406 Train acc: 0.968333\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.091589 Validation acc: 0.960556\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.125026 Train acc: 0.958333\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.115547 Train acc: 0.965000\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.141974 Train acc: 0.941667\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.081791 Train acc: 0.976667\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.152528 Train acc: 0.938333\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.111803 Validation acc: 0.957222\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.152496 Train acc: 0.946667\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.142312 Train acc: 0.943333\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.112024 Train acc: 0.956667\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.110039 Train acc: 0.960000\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.133523 Train acc: 0.955000\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.106435 Validation acc: 0.957778\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.138914 Train acc: 0.950000\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.135495 Train acc: 0.953333\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.093120 Train acc: 0.975000\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.127452 Train acc: 0.951667\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.140821 Train acc: 0.946667\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.094754 Validation acc: 0.961667\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.125701 Train acc: 0.956667\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.101368 Train acc: 0.976667\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.089019 Train acc: 0.965000\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.124920 Train acc: 0.956667\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.120248 Train acc: 0.963333\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.092073 Validation acc: 0.961667\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.131761 Train acc: 0.956667\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.078671 Train acc: 0.981667\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.144174 Train acc: 0.946667\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.136465 Train acc: 0.953333\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.118083 Train acc: 0.961667\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.093814 Validation acc: 0.960556\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.109475 Train acc: 0.961667\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.100618 Train acc: 0.965000\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.127382 Train acc: 0.966667\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.129814 Train acc: 0.960000\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.142828 Train acc: 0.950000\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.093049 Validation acc: 0.962778\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.090777 Train acc: 0.975000\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.143792 Train acc: 0.950000\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.123594 Train acc: 0.955000\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.112316 Train acc: 0.955000\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.105479 Train acc: 0.961667\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.097474 Validation acc: 0.960556\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.088730 Train acc: 0.968333\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.121712 Train acc: 0.963333\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.132705 Train acc: 0.956667\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.130975 Train acc: 0.953333\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.093404 Train acc: 0.975000\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.090069 Validation acc: 0.963333\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.131715 Train acc: 0.946667\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.145278 Train acc: 0.943333\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.116108 Train acc: 0.956667\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.109633 Train acc: 0.961667\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.093898 Train acc: 0.966667\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.090044 Validation acc: 0.963333\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.097265 Train acc: 0.971667\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.135449 Train acc: 0.951667\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.143399 Train acc: 0.945000\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.080962 Train acc: 0.978333\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.152110 Train acc: 0.943333\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.091541 Validation acc: 0.963333\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.158859 Train acc: 0.943333\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.105025 Train acc: 0.956667\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.098668 Train acc: 0.975000\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.092454 Train acc: 0.966667\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.127128 Train acc: 0.958333\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.085346 Validation acc: 0.963889\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.120977 Train acc: 0.963333\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.148661 Train acc: 0.953333\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.080834 Train acc: 0.973333\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.132374 Train acc: 0.955000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.131200 Train acc: 0.956667\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.091823 Validation acc: 0.962222\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.102439 Train acc: 0.965000\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.097395 Train acc: 0.966667\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.083865 Train acc: 0.975000\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.111339 Train acc: 0.971667\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.124792 Train acc: 0.961667\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.090144 Validation acc: 0.962778\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.139624 Train acc: 0.938333\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.086238 Train acc: 0.971667\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.130003 Train acc: 0.950000\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.137177 Train acc: 0.946667\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.100259 Train acc: 0.963333\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.096252 Validation acc: 0.961111\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.107521 Train acc: 0.963333\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.090523 Train acc: 0.966667\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.114726 Train acc: 0.965000\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.132791 Train acc: 0.958333\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.127700 Train acc: 0.951667\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.087867 Validation acc: 0.962778\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.081092 Train acc: 0.981667\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.140553 Train acc: 0.950000\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.131630 Train acc: 0.951667\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.112374 Train acc: 0.966667\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.098787 Train acc: 0.961667\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.086966 Validation acc: 0.963333\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.089262 Train acc: 0.975000\n",
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.127621 Train acc: 0.963333\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.116461 Train acc: 0.960000\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.126909 Train acc: 0.948333\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.077894 Train acc: 0.968333\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.088917 Validation acc: 0.962222\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.142387 Train acc: 0.945000\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.124620 Train acc: 0.955000\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.106460 Train acc: 0.960000\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.108320 Train acc: 0.963333\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.087490 Train acc: 0.975000\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.087079 Validation acc: 0.962778\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.110706 Train acc: 0.968333\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.124901 Train acc: 0.958333\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.151601 Train acc: 0.946667\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.087320 Train acc: 0.976667\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.155777 Train acc: 0.946667\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.084624 Validation acc: 0.963333\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.140681 Train acc: 0.951667\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.115713 Train acc: 0.965000\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.100541 Train acc: 0.966667\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.080727 Train acc: 0.975000\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.114211 Train acc: 0.961667\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.087667 Validation acc: 0.963333\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.132186 Train acc: 0.960000\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.146528 Train acc: 0.941667\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.086787 Train acc: 0.970000\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.124665 Train acc: 0.951667\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.135071 Train acc: 0.953333\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.086372 Validation acc: 0.962222\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.113693 Train acc: 0.956667\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.095118 Train acc: 0.965000\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.095178 Train acc: 0.973333\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.103019 Train acc: 0.973333\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.109687 Train acc: 0.971667\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.088643 Validation acc: 0.962778\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.116471 Train acc: 0.956667\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.070712 Train acc: 0.978333\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.131397 Train acc: 0.945000\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.121803 Train acc: 0.963333\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.109706 Train acc: 0.966667\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.088446 Validation acc: 0.963333\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.106299 Train acc: 0.965000\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.085306 Train acc: 0.965000\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.125616 Train acc: 0.961667\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.123355 Train acc: 0.960000\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.133919 Train acc: 0.948333\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.109267 Validation acc: 0.956667\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.080517 Train acc: 0.978333\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.138777 Train acc: 0.948333\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.142469 Train acc: 0.943333\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.123566 Train acc: 0.946667\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.097834 Train acc: 0.961667\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.084437 Validation acc: 0.966111\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.085555 Train acc: 0.971667\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.117351 Train acc: 0.966667\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.127699 Train acc: 0.956667\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.127572 Train acc: 0.958333\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.078156 Train acc: 0.976667\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.090749 Validation acc: 0.961111\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.148660 Train acc: 0.946667\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.123049 Train acc: 0.963333\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.111434 Train acc: 0.961667\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.096412 Train acc: 0.960000\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.097148 Train acc: 0.963333\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.098063 Validation acc: 0.959444\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.111340 Train acc: 0.961667\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.112716 Train acc: 0.956667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.148604 Train acc: 0.945000\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.082668 Train acc: 0.975000\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.129187 Train acc: 0.946667\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.085766 Validation acc: 0.962778\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.131293 Train acc: 0.956667\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.112029 Train acc: 0.953333\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.091008 Train acc: 0.968333\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.087615 Train acc: 0.978333\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.109293 Train acc: 0.968333\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.088620 Validation acc: 0.962222\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.116033 Train acc: 0.965000\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.122043 Train acc: 0.956667\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.068388 Train acc: 0.980000\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.135467 Train acc: 0.945000\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.126652 Train acc: 0.960000\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.084141 Validation acc: 0.963889\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.106706 Train acc: 0.951667\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.093367 Train acc: 0.966667\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.072924 Train acc: 0.971667\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.110401 Train acc: 0.961667\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.119705 Train acc: 0.961667\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.088532 Validation acc: 0.961667\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.127776 Train acc: 0.953333\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.075759 Train acc: 0.973333\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.119048 Train acc: 0.956667\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.134514 Train acc: 0.950000\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.112271 Train acc: 0.958333\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.085235 Validation acc: 0.963889\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.107126 Train acc: 0.961667\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.077033 Train acc: 0.973333\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.113369 Train acc: 0.958333\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.119012 Train acc: 0.966667\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.135034 Train acc: 0.945000\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.083918 Validation acc: 0.962222\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.070842 Train acc: 0.983333\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.123526 Train acc: 0.956667\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.122375 Train acc: 0.948333\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.101736 Train acc: 0.966667\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.105301 Train acc: 0.961667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.084336 Validation acc: 0.962222\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.078869 Train acc: 0.968333\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.112962 Train acc: 0.966667\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.123898 Train acc: 0.963333\n",
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.113508 Train acc: 0.951667\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.070607 Train acc: 0.981667\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.087108 Validation acc: 0.962222\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.119463 Train acc: 0.951667\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.147758 Train acc: 0.948333\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.091159 Train acc: 0.966667\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.111601 Train acc: 0.961667\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.075112 Train acc: 0.978333\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.083973 Validation acc: 0.963889\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.108623 Train acc: 0.966667\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.115860 Train acc: 0.963333\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.121161 Train acc: 0.951667\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.071279 Train acc: 0.980000\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.139584 Train acc: 0.948333\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.094654 Validation acc: 0.960556\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.115000 Train acc: 0.958333\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.102271 Train acc: 0.963333\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.097305 Train acc: 0.963333\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.082593 Train acc: 0.978333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.106704 Train acc: 0.960000\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.091352 Validation acc: 0.960000\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.118762 Train acc: 0.961667\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.117985 Train acc: 0.951667\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.069946 Train acc: 0.978333\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.122442 Train acc: 0.946667\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.122677 Train acc: 0.953333\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.084903 Validation acc: 0.964444\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.109602 Train acc: 0.953333\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.096226 Train acc: 0.966667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.081549 Train acc: 0.970000\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.092333 Train acc: 0.970000\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.113675 Train acc: 0.963333\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.084468 Validation acc: 0.963333\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.120252 Train acc: 0.955000\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.070341 Train acc: 0.980000\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.128756 Train acc: 0.946667\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.122500 Train acc: 0.948333\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.107319 Train acc: 0.963333\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.085911 Validation acc: 0.961111\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.084376 Train acc: 0.973333\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.089617 Train acc: 0.976667\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.098194 Train acc: 0.963333\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.115710 Train acc: 0.965000\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.124990 Train acc: 0.950000\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.083950 Validation acc: 0.964444\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.070339 Train acc: 0.976667\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.134053 Train acc: 0.945000\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.114761 Train acc: 0.958333\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.104255 Train acc: 0.961667\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.088500 Train acc: 0.973333\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.083877 Validation acc: 0.963333\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.080540 Train acc: 0.970000\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.115716 Train acc: 0.963333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.128453 Train acc: 0.960000\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.126563 Train acc: 0.961667\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.065551 Train acc: 0.980000\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.083340 Validation acc: 0.962222\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.131493 Train acc: 0.951667\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.113291 Train acc: 0.958333\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.105684 Train acc: 0.971667\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.093961 Train acc: 0.971667\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.086081 Train acc: 0.973333\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.083236 Validation acc: 0.963333\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.108091 Train acc: 0.970000\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.102772 Train acc: 0.958333\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.121168 Train acc: 0.958333\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.074049 Train acc: 0.975000\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.127781 Train acc: 0.946667\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.084931 Validation acc: 0.962222\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.131160 Train acc: 0.953333\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.098984 Train acc: 0.966667\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.091250 Train acc: 0.965000\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.078960 Train acc: 0.976667\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.100380 Train acc: 0.973333\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.089867 Validation acc: 0.962222\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.116330 Train acc: 0.963333\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.131969 Train acc: 0.953333\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.065233 Train acc: 0.978333\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.133267 Train acc: 0.953333\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.140034 Train acc: 0.950000\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.086495 Validation acc: 0.962778\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.095472 Train acc: 0.970000\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.078659 Train acc: 0.971667\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.076633 Train acc: 0.973333\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.105266 Train acc: 0.970000\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.101539 Train acc: 0.970000\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.082121 Validation acc: 0.965556\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.142079 Train acc: 0.940000\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.072688 Train acc: 0.973333\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.130723 Train acc: 0.951667\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.123289 Train acc: 0.950000\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.094668 Train acc: 0.968333\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.082358 Validation acc: 0.964444\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.093676 Train acc: 0.973333\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.067180 Train acc: 0.980000\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.113116 Train acc: 0.968333\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.100995 Train acc: 0.970000\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.109197 Train acc: 0.953333\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.077769 Validation acc: 0.965555\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.078602 Train acc: 0.985000\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.127469 Train acc: 0.940000\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.121927 Train acc: 0.956667\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.106339 Train acc: 0.963333\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.095235 Train acc: 0.961667\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.084892 Validation acc: 0.963333\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.078517 Train acc: 0.968333\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.102067 Train acc: 0.975000\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.116084 Train acc: 0.963333\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.119861 Train acc: 0.953333\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.071541 Train acc: 0.981667\n",
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.087355 Validation acc: 0.962222\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.117939 Train acc: 0.953333\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.136990 Train acc: 0.950000\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.103980 Train acc: 0.963333\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.097036 Train acc: 0.965000\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.069521 Train acc: 0.976667\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.085509 Validation acc: 0.963333\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.102409 Train acc: 0.956667\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.123246 Train acc: 0.961667\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.122986 Train acc: 0.956667\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.067028 Train acc: 0.980000\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.135266 Train acc: 0.950000\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.090357 Validation acc: 0.962222\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.123259 Train acc: 0.953333\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.087790 Train acc: 0.966667\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.100276 Train acc: 0.965000\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.080003 Train acc: 0.973333\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.096163 Train acc: 0.973333\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.086847 Validation acc: 0.963889\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.122792 Train acc: 0.965000\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.123447 Train acc: 0.956667\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.064916 Train acc: 0.983333\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.131745 Train acc: 0.955000\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.128260 Train acc: 0.951667\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.092554 Validation acc: 0.961111\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.085413 Train acc: 0.961667\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.088525 Train acc: 0.973333\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.075739 Train acc: 0.968333\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.096390 Train acc: 0.975000\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.103306 Train acc: 0.973333\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.079912 Validation acc: 0.963889\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.114391 Train acc: 0.961667\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.063673 Train acc: 0.976667\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.126776 Train acc: 0.955000\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.114022 Train acc: 0.961667\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.102835 Train acc: 0.966667\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.088666 Validation acc: 0.962222\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.090435 Train acc: 0.973333\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.071427 Train acc: 0.980000\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.113426 Train acc: 0.966667\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.112172 Train acc: 0.968333\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.120255 Train acc: 0.955000\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.084840 Validation acc: 0.965556\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.057503 Train acc: 0.981667\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.130484 Train acc: 0.948333\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.115627 Train acc: 0.956667\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.096995 Train acc: 0.968333\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.077618 Train acc: 0.976667\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.080527 Validation acc: 0.966667\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.075869 Train acc: 0.973333\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.099482 Train acc: 0.965000\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.106839 Train acc: 0.968333\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.124458 Train acc: 0.953333\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.064284 Train acc: 0.983333\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.080772 Validation acc: 0.962778\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.113892 Train acc: 0.956667\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.116616 Train acc: 0.958333\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.104399 Train acc: 0.963333\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.101612 Train acc: 0.968333\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.077361 Train acc: 0.973333\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.086172 Validation acc: 0.963333\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.111254 Train acc: 0.971667\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.104309 Train acc: 0.965000\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.116138 Train acc: 0.958333\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.071288 Train acc: 0.976667\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.131209 Train acc: 0.943333\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.087264 Validation acc: 0.963889\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.116342 Train acc: 0.956667\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.103439 Train acc: 0.970000\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.079455 Train acc: 0.970000\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.078586 Train acc: 0.975000\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.102841 Train acc: 0.965000\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.081837 Validation acc: 0.963889\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.122842 Train acc: 0.963333\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.117621 Train acc: 0.951667\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.061668 Train acc: 0.980000\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.118204 Train acc: 0.960000\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.113263 Train acc: 0.956667\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.079872 Validation acc: 0.965000\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.103635 Train acc: 0.958333\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.087743 Train acc: 0.970000\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.063673 Train acc: 0.975000\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.097383 Train acc: 0.971667\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.113220 Train acc: 0.966667\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.079626 Validation acc: 0.965000\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.110786 Train acc: 0.956667\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.063073 Train acc: 0.980000\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.117973 Train acc: 0.948333\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.118839 Train acc: 0.958333\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.097425 Train acc: 0.958333\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.080132 Validation acc: 0.966111\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.092004 Train acc: 0.968333\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.072462 Train acc: 0.970000\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.106466 Train acc: 0.968333\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.112434 Train acc: 0.970000\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.110179 Train acc: 0.955000\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.083514 Validation acc: 0.964444\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.056719 Train acc: 0.983333\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.124123 Train acc: 0.951667\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.105939 Train acc: 0.956667\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.094109 Train acc: 0.971667\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.087113 Train acc: 0.976667\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.078062 Validation acc: 0.963333\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.073689 Train acc: 0.968333\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.100430 Train acc: 0.965000\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.109183 Train acc: 0.960000\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.119507 Train acc: 0.958333\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.056801 Train acc: 0.988333\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.079367 Validation acc: 0.964444\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.131918 Train acc: 0.950000\n",
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.105448 Train acc: 0.960000\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.097680 Train acc: 0.965000\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.095046 Train acc: 0.958333\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.070009 Train acc: 0.971667\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.081158 Validation acc: 0.963889\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.097447 Train acc: 0.968333\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.105426 Train acc: 0.968333\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.110783 Train acc: 0.961667\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.060981 Train acc: 0.988333\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.129189 Train acc: 0.953333\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.090820 Validation acc: 0.962222\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.120217 Train acc: 0.955000\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.092201 Train acc: 0.966667\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.085484 Train acc: 0.973333\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.074996 Train acc: 0.970000\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.101849 Train acc: 0.965000\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.084117 Validation acc: 0.963889\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.107479 Train acc: 0.971667\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.112688 Train acc: 0.960000\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.057670 Train acc: 0.981667\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.130479 Train acc: 0.956667\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.112670 Train acc: 0.960000\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.084479 Validation acc: 0.963889\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.099885 Train acc: 0.956667\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.083783 Train acc: 0.966667\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.083003 Train acc: 0.971667\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.096933 Train acc: 0.971667\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.100762 Train acc: 0.965000\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.088370 Validation acc: 0.964444\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.123531 Train acc: 0.955000\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.063781 Train acc: 0.978333\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.127482 Train acc: 0.943333\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.112309 Train acc: 0.956667\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.098585 Train acc: 0.965000\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.083492 Validation acc: 0.965000\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.096528 Train acc: 0.966667\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.071781 Train acc: 0.976667\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.089147 Train acc: 0.973333\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.107825 Train acc: 0.971667\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.101133 Train acc: 0.963333\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.083013 Validation acc: 0.962222\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.056532 Train acc: 0.985000\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.120429 Train acc: 0.950000\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.111456 Train acc: 0.956667\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.099490 Train acc: 0.966667\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.093738 Train acc: 0.961667\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.080457 Validation acc: 0.963333\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.074809 Train acc: 0.973333\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.094702 Train acc: 0.965000\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.107556 Train acc: 0.963333\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.124797 Train acc: 0.956667\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.063254 Train acc: 0.981667\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.083981 Validation acc: 0.961111\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.135094 Train acc: 0.945000\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.103340 Train acc: 0.965000\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.103322 Train acc: 0.960000\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.079649 Train acc: 0.970000\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.068316 Train acc: 0.976667\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.079610 Validation acc: 0.965555\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.090911 Train acc: 0.971667\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.111586 Train acc: 0.965000\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.107036 Train acc: 0.958333\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.060259 Train acc: 0.983333\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.121177 Train acc: 0.946667\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.082185 Validation acc: 0.964444\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.118114 Train acc: 0.960000\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.095605 Train acc: 0.970000\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.087349 Train acc: 0.966667\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.074901 Train acc: 0.976667\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.116999 Train acc: 0.970000\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.084827 Validation acc: 0.963333\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.116439 Train acc: 0.961667\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.117942 Train acc: 0.956667\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.068738 Train acc: 0.976667\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.129749 Train acc: 0.941667\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.106220 Train acc: 0.956667\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.081961 Validation acc: 0.964444\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.094905 Train acc: 0.965000\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.089744 Train acc: 0.960000\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.070323 Train acc: 0.971667\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.096260 Train acc: 0.966667\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.110268 Train acc: 0.966667\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.085944 Validation acc: 0.962222\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.119396 Train acc: 0.951667\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.063869 Train acc: 0.985000\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.128656 Train acc: 0.950000\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.115689 Train acc: 0.958333\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.101374 Train acc: 0.966667\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.076782 Validation acc: 0.965555\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.092786 Train acc: 0.963333\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.081734 Train acc: 0.973333\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.088203 Train acc: 0.966667\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.105705 Train acc: 0.966667\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.111623 Train acc: 0.961667\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.078193 Validation acc: 0.964444\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.055669 Train acc: 0.986667\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.122150 Train acc: 0.948333\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.109394 Train acc: 0.963333\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.096372 Train acc: 0.960000\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.076435 Train acc: 0.975000\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.081237 Validation acc: 0.964444\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.055813 Train acc: 0.983333\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.109038 Train acc: 0.966667\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.108629 Train acc: 0.961667\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.110919 Train acc: 0.958333\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.056797 Train acc: 0.978333\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.080784 Validation acc: 0.964444\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.104751 Train acc: 0.965000\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.108534 Train acc: 0.961667\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.082267 Train acc: 0.966667\n",
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.092736 Train acc: 0.968333\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.075893 Train acc: 0.971667\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.080423 Validation acc: 0.962778\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.096333 Train acc: 0.973333\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.103287 Train acc: 0.970000\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.114663 Train acc: 0.953333\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.059319 Train acc: 0.980000\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.119075 Train acc: 0.948333\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.080416 Validation acc: 0.964444\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.115653 Train acc: 0.961667\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.094376 Train acc: 0.970000\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.092123 Train acc: 0.973333\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.072321 Train acc: 0.970000\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.096928 Train acc: 0.970000\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.085648 Validation acc: 0.963333\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.112005 Train acc: 0.963333\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.112497 Train acc: 0.955000\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.062523 Train acc: 0.985000\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.108513 Train acc: 0.956667\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.098179 Train acc: 0.960000\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.074640 Validation acc: 0.965555\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.086585 Train acc: 0.966667\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.079442 Train acc: 0.971667\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.069514 Train acc: 0.976667\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.100049 Train acc: 0.971667\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.106993 Train acc: 0.968333\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.075741 Validation acc: 0.967222\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.111099 Train acc: 0.955000\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.053333 Train acc: 0.985000\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.123336 Train acc: 0.958333\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.111827 Train acc: 0.950000\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.082876 Train acc: 0.971667\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.082466 Validation acc: 0.963889\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.081607 Train acc: 0.973333\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.060907 Train acc: 0.975000\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.093683 Train acc: 0.966667\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.093769 Train acc: 0.966667\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.115135 Train acc: 0.953333\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.080012 Validation acc: 0.965555\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.059788 Train acc: 0.978333\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.128421 Train acc: 0.941667\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.120398 Train acc: 0.953333\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.088767 Train acc: 0.966667\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.086617 Train acc: 0.971667\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.084747 Validation acc: 0.963333\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.067595 Train acc: 0.975000\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.097300 Train acc: 0.970000\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.107616 Train acc: 0.968333\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.106767 Train acc: 0.951667\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.071454 Train acc: 0.978333\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.080178 Validation acc: 0.963333\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.121646 Train acc: 0.963333\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.103802 Train acc: 0.953333\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.086266 Train acc: 0.965000\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.084336 Train acc: 0.970000\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.063715 Train acc: 0.975000\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.089531 Validation acc: 0.963333\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.100630 Train acc: 0.968333\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.093777 Train acc: 0.966667\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.122501 Train acc: 0.948333\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.060390 Train acc: 0.981667\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.135094 Train acc: 0.948333\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.080853 Validation acc: 0.963889\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.107947 Train acc: 0.960000\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.083060 Train acc: 0.971667\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.076048 Train acc: 0.976667\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.075322 Train acc: 0.975000\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.112870 Train acc: 0.968333\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.084495 Validation acc: 0.962778\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.100957 Train acc: 0.971667\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.119807 Train acc: 0.961667\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.058787 Train acc: 0.980000\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.118025 Train acc: 0.951667\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.101924 Train acc: 0.960000\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.083203 Validation acc: 0.964444\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.087714 Train acc: 0.975000\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.084931 Train acc: 0.970000\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.062987 Train acc: 0.981667\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.085639 Train acc: 0.970000\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.098462 Train acc: 0.973333\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.077677 Validation acc: 0.965556\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.120658 Train acc: 0.960000\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.062870 Train acc: 0.976667\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.116095 Train acc: 0.953333\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.116853 Train acc: 0.961667\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.080383 Train acc: 0.968333\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.077752 Validation acc: 0.965555\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.074983 Train acc: 0.973333\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.067065 Train acc: 0.975000\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.083845 Train acc: 0.975000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.098804 Train acc: 0.971667\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.106538 Train acc: 0.965000\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.078288 Validation acc: 0.965000\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.060063 Train acc: 0.983333\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.111037 Train acc: 0.955000\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.112314 Train acc: 0.960000\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.088384 Train acc: 0.968333\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.086241 Train acc: 0.968333\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.076997 Validation acc: 0.965000\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.064975 Train acc: 0.976667\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.091000 Train acc: 0.968333\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.100307 Train acc: 0.968333\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.110694 Train acc: 0.955000\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.056792 Train acc: 0.981667\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.076752 Validation acc: 0.966111\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.113641 Train acc: 0.956667\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.106240 Train acc: 0.958333\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.085729 Train acc: 0.971667\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.080947 Train acc: 0.971667\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.062159 Train acc: 0.978333\n",
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.074804 Validation acc: 0.965555\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.103725 Train acc: 0.966667\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.100494 Train acc: 0.971667\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.099952 Train acc: 0.958333\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.058246 Train acc: 0.983333\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.112649 Train acc: 0.953333\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.084219 Validation acc: 0.965000\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.111687 Train acc: 0.958333\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.090480 Train acc: 0.965000\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.084740 Train acc: 0.971667\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.067782 Train acc: 0.975000\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.099898 Train acc: 0.966667\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.080056 Validation acc: 0.966111\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.103506 Train acc: 0.966667\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.099830 Train acc: 0.956667\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.058600 Train acc: 0.983333\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.112764 Train acc: 0.956667\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.104401 Train acc: 0.961667\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.079995 Validation acc: 0.965555\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.083665 Train acc: 0.970000\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.084069 Train acc: 0.968333\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.072008 Train acc: 0.970000\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.106975 Train acc: 0.968333\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.108531 Train acc: 0.975000\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.080587 Validation acc: 0.964444\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.111590 Train acc: 0.958333\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.056374 Train acc: 0.986667\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.119412 Train acc: 0.946667\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.090338 Train acc: 0.966667\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.099308 Train acc: 0.961667\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.076308 Validation acc: 0.965555\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.090503 Train acc: 0.966667\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.073739 Train acc: 0.968333\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.088117 Train acc: 0.971667\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.126092 Train acc: 0.960000\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.114262 Train acc: 0.956667\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.080836 Validation acc: 0.964444\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.082347 Train acc: 0.970000\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.112108 Train acc: 0.955000\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.097474 Train acc: 0.968333\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.118397 Train acc: 0.948333\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.079450 Train acc: 0.970000\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.081770 Validation acc: 0.962222\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.089981 Train acc: 0.961667\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.085327 Train acc: 0.973333\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.095755 Train acc: 0.965000\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.123582 Train acc: 0.951667\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.060745 Train acc: 0.985000\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.079035 Validation acc: 0.966111\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.108356 Train acc: 0.960000\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.108542 Train acc: 0.966667\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.091414 Train acc: 0.966667\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.075803 Train acc: 0.971667\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.065383 Train acc: 0.975000\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.076144 Validation acc: 0.964444\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.115353 Train acc: 0.965000\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.099739 Train acc: 0.970000\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.109846 Train acc: 0.956667\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.053851 Train acc: 0.990000\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.113761 Train acc: 0.955000\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.079424 Validation acc: 0.963333\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.115795 Train acc: 0.965000\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.094101 Train acc: 0.961667\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.076652 Train acc: 0.968333\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.067012 Train acc: 0.980000\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.103320 Train acc: 0.965000\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.078001 Validation acc: 0.965555\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.089095 Train acc: 0.976667\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.106310 Train acc: 0.955000\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.054656 Train acc: 0.986667\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.113947 Train acc: 0.948333\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.102283 Train acc: 0.966667\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.075832 Validation acc: 0.965555\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.084881 Train acc: 0.968333\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.076987 Train acc: 0.971667\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.060558 Train acc: 0.980000\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.092577 Train acc: 0.968333\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.090216 Train acc: 0.970000\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.076259 Validation acc: 0.966667\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.099414 Train acc: 0.965000\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.047591 Train acc: 0.985000\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.109162 Train acc: 0.951667\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.103713 Train acc: 0.968333\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.080395 Train acc: 0.968333\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.075957 Validation acc: 0.965555\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.077123 Train acc: 0.976667\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.058516 Train acc: 0.978333\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.081208 Train acc: 0.973333\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.095665 Train acc: 0.963333\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.112836 Train acc: 0.956667\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.079357 Validation acc: 0.965555\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.058994 Train acc: 0.976667\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.121391 Train acc: 0.951667\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.108262 Train acc: 0.963333\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.109928 Train acc: 0.963333\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.077435 Train acc: 0.973333\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.075358 Validation acc: 0.965000\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.071077 Train acc: 0.978333\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.094637 Train acc: 0.973333\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.107699 Train acc: 0.966667\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.099963 Train acc: 0.968333\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.052797 Train acc: 0.990000\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.076798 Validation acc: 0.966111\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.111688 Train acc: 0.950000\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.099725 Train acc: 0.966667\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.099503 Train acc: 0.966667\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.073880 Train acc: 0.970000\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.064204 Train acc: 0.981667\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.074812 Validation acc: 0.966111\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.099455 Train acc: 0.975000\n",
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.113265 Train acc: 0.960000\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.110132 Train acc: 0.956667\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.054306 Train acc: 0.981667\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.110269 Train acc: 0.955000\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.076833 Validation acc: 0.965555\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.100020 Train acc: 0.968333\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.079517 Train acc: 0.976667\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.073834 Train acc: 0.971667\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.062948 Train acc: 0.985000\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.085598 Train acc: 0.970000\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.079084 Validation acc: 0.963889\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.095607 Train acc: 0.966667\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.098234 Train acc: 0.961667\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.054479 Train acc: 0.976667\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.118128 Train acc: 0.948333\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.104360 Train acc: 0.963333\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.075499 Validation acc: 0.967778\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.123364 Train acc: 0.955000\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.071769 Train acc: 0.970000\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.072006 Train acc: 0.973333\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.092350 Train acc: 0.971667\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.095652 Train acc: 0.965000\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.077049 Validation acc: 0.966111\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.110285 Train acc: 0.955000\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.053120 Train acc: 0.976667\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.114883 Train acc: 0.955000\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.091773 Train acc: 0.958333\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.099441 Train acc: 0.963333\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.079599 Validation acc: 0.965555\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.072303 Train acc: 0.970000\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.062368 Train acc: 0.981667\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.093733 Train acc: 0.968333\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.094160 Train acc: 0.973333\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.105450 Train acc: 0.958333\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.077898 Validation acc: 0.965555\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.053245 Train acc: 0.986667\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.114252 Train acc: 0.950000\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.100179 Train acc: 0.963333\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.091003 Train acc: 0.966667\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.075053 Train acc: 0.965000\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.078002 Validation acc: 0.969444\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.069324 Train acc: 0.968333\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.093874 Train acc: 0.971667\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.092543 Train acc: 0.968333\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.113087 Train acc: 0.963333\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.054503 Train acc: 0.983333\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.078433 Validation acc: 0.966111\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.112996 Train acc: 0.958333\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.100869 Train acc: 0.963333\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.090009 Train acc: 0.965000\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.075479 Train acc: 0.968333\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.056147 Train acc: 0.985000\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.077847 Validation acc: 0.967778\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.100355 Train acc: 0.963333\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.105249 Train acc: 0.965000\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.109659 Train acc: 0.956667\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.056840 Train acc: 0.981667\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.113070 Train acc: 0.953333\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.078543 Validation acc: 0.965555\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.107945 Train acc: 0.958333\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.094059 Train acc: 0.961667\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.083210 Train acc: 0.971667\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.057582 Train acc: 0.978333\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.095225 Train acc: 0.970000\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.079594 Validation acc: 0.965555\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.100153 Train acc: 0.966667\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.110715 Train acc: 0.958333\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.051736 Train acc: 0.985000\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.119709 Train acc: 0.946667\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.109899 Train acc: 0.963333\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.070930 Validation acc: 0.970000\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.083500 Train acc: 0.965000\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.070417 Train acc: 0.978333\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.059242 Train acc: 0.978333\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.089029 Train acc: 0.973333\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.099826 Train acc: 0.968333\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.069743 Validation acc: 0.969444\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.106162 Train acc: 0.960000\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.051762 Train acc: 0.983333\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.121544 Train acc: 0.948333\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.100691 Train acc: 0.961667\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.081434 Train acc: 0.971667\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.076890 Validation acc: 0.965000\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.074753 Train acc: 0.975000\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.053190 Train acc: 0.981667\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.086691 Train acc: 0.971667\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.090626 Train acc: 0.963333\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.107766 Train acc: 0.955000\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.075191 Validation acc: 0.966667\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.056706 Train acc: 0.978333\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.111850 Train acc: 0.956667\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.098133 Train acc: 0.966667\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.092601 Train acc: 0.963333\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.079461 Train acc: 0.976667\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.075712 Validation acc: 0.967778\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.057609 Train acc: 0.978333\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.086062 Train acc: 0.973333\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.095997 Train acc: 0.971667\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.092402 Train acc: 0.958333\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.055842 Train acc: 0.980000\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.072811 Validation acc: 0.967778\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.120650 Train acc: 0.946667\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.102883 Train acc: 0.966667\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.084335 Train acc: 0.966667\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.077652 Train acc: 0.968333\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.066351 Train acc: 0.971667\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.074790 Validation acc: 0.969444\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.088944 Train acc: 0.973333\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.091499 Train acc: 0.968333\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.098911 Train acc: 0.961667\n",
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.055480 Train acc: 0.983333\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.112794 Train acc: 0.958333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.075067 Validation acc: 0.965555\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.094764 Train acc: 0.973333\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.104124 Train acc: 0.961667\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.079372 Train acc: 0.966667\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.054580 Train acc: 0.985000\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.101001 Train acc: 0.970000\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.077433 Validation acc: 0.967778\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.104047 Train acc: 0.970000\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.101298 Train acc: 0.958333\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.057207 Train acc: 0.980000\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.110228 Train acc: 0.956667\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.098608 Train acc: 0.965000\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.078086 Validation acc: 0.968333\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.090560 Train acc: 0.961667\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.082054 Train acc: 0.965000\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.061356 Train acc: 0.980000\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.093072 Train acc: 0.973333\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.095735 Train acc: 0.970000\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.076222 Validation acc: 0.968333\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.104493 Train acc: 0.958333\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.053136 Train acc: 0.981667\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.107280 Train acc: 0.961667\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.098027 Train acc: 0.975000\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.081951 Train acc: 0.970000\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.073677 Validation acc: 0.967222\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.074579 Train acc: 0.975000\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.060057 Train acc: 0.975000\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.096299 Train acc: 0.965000\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.104113 Train acc: 0.970000\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.112688 Train acc: 0.965000\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.078444 Validation acc: 0.967222\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.051816 Train acc: 0.981667\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.111715 Train acc: 0.950000\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.100638 Train acc: 0.965000\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.076408 Train acc: 0.976667\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.077660 Train acc: 0.965000\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.073613 Validation acc: 0.967222\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.062838 Train acc: 0.970000\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.096289 Train acc: 0.965000\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.089561 Train acc: 0.973333\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.109200 Train acc: 0.965000\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.053935 Train acc: 0.985000\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.073665 Validation acc: 0.968333\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.103948 Train acc: 0.950000\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.098718 Train acc: 0.963333\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.097793 Train acc: 0.963333\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.072429 Train acc: 0.973333\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.052245 Train acc: 0.983333\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.073979 Validation acc: 0.967222\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.093060 Train acc: 0.971667\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.087593 Train acc: 0.975000\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.102670 Train acc: 0.961667\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.052796 Train acc: 0.983333\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.116371 Train acc: 0.951667\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.077761 Validation acc: 0.968889\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.091373 Train acc: 0.966667\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.084357 Train acc: 0.963333\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.077957 Train acc: 0.975000\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.050274 Train acc: 0.983333\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.094794 Train acc: 0.968333\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.071863 Validation acc: 0.970556\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.092560 Train acc: 0.975000\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.097510 Train acc: 0.956667\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.050740 Train acc: 0.983333\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.112493 Train acc: 0.951667\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.087792 Train acc: 0.968333\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.072045 Validation acc: 0.969444\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.083511 Train acc: 0.965000\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.074154 Train acc: 0.963333\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.063786 Train acc: 0.971667\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.084382 Train acc: 0.965000\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.099716 Train acc: 0.966667\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.073340 Validation acc: 0.965000\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.115040 Train acc: 0.958333\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.053819 Train acc: 0.985000\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.113739 Train acc: 0.951667\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.084959 Train acc: 0.970000\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.083184 Train acc: 0.968333\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.077416 Validation acc: 0.965555\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.069470 Train acc: 0.966667\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.057356 Train acc: 0.975000\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.090752 Train acc: 0.975000\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.104292 Train acc: 0.958333\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.111633 Train acc: 0.958333\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.073643 Validation acc: 0.968333\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.050717 Train acc: 0.988333\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.113848 Train acc: 0.946667\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.102640 Train acc: 0.960000\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.088789 Train acc: 0.970000\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.077907 Train acc: 0.966667\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.075715 Validation acc: 0.966667\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.059391 Train acc: 0.976667\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.086907 Train acc: 0.976667\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.093494 Train acc: 0.963333\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.091574 Train acc: 0.961667\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.048821 Train acc: 0.985000\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.075424 Validation acc: 0.970000\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.108551 Train acc: 0.956667\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.099543 Train acc: 0.963333\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.091662 Train acc: 0.970000\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.092345 Train acc: 0.965000\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.060096 Train acc: 0.975000\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.073935 Validation acc: 0.967778\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.091772 Train acc: 0.976667\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.104508 Train acc: 0.973333\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.094141 Train acc: 0.958333\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.050079 Train acc: 0.986667\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.095659 Train acc: 0.965000\n",
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.075762 Validation acc: 0.967778\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.087146 Train acc: 0.968333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.084651 Train acc: 0.971667\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.072464 Train acc: 0.973333\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.058929 Train acc: 0.975000\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.083292 Train acc: 0.971667\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.074498 Validation acc: 0.968333\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.089013 Train acc: 0.975000\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.090481 Train acc: 0.970000\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.049193 Train acc: 0.988333\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.105245 Train acc: 0.955000\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.092494 Train acc: 0.965000\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.074108 Validation acc: 0.967222\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.081556 Train acc: 0.968333\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.073498 Train acc: 0.973333\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.064239 Train acc: 0.981667\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.082018 Train acc: 0.976667\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.081528 Train acc: 0.970000\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.074652 Validation acc: 0.968889\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.116400 Train acc: 0.953333\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.049642 Train acc: 0.981667\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.107742 Train acc: 0.956667\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.087958 Train acc: 0.965000\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.086804 Train acc: 0.961667\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.080177 Validation acc: 0.966667\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.070394 Train acc: 0.975000\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.062862 Train acc: 0.978333\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.090856 Train acc: 0.965000\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.092981 Train acc: 0.973333\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.103558 Train acc: 0.958333\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.079591 Validation acc: 0.966111\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.057778 Train acc: 0.981667\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.104634 Train acc: 0.953333\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.093265 Train acc: 0.970000\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.078107 Train acc: 0.970000\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.065476 Train acc: 0.970000\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.078242 Validation acc: 0.968333\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.052415 Train acc: 0.983333\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.087954 Train acc: 0.971667\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.087094 Train acc: 0.970000\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.114189 Train acc: 0.961667\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.055907 Train acc: 0.981667\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.077936 Validation acc: 0.968889\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.109822 Train acc: 0.958333\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.090181 Train acc: 0.966667\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.088652 Train acc: 0.971667\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.070335 Train acc: 0.976667\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.059032 Train acc: 0.978333\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.076593 Validation acc: 0.969444\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.095857 Train acc: 0.965000\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.088728 Train acc: 0.973333\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.108604 Train acc: 0.958333\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.047278 Train acc: 0.985000\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.100058 Train acc: 0.953333\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.076591 Validation acc: 0.969444\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.095010 Train acc: 0.965000\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.074897 Train acc: 0.966667\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.080426 Train acc: 0.968333\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.052667 Train acc: 0.980000\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.081401 Train acc: 0.971667\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.078398 Validation acc: 0.970000\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.087092 Train acc: 0.973333\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.104234 Train acc: 0.960000\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.050062 Train acc: 0.981667\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.113488 Train acc: 0.955000\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.098592 Train acc: 0.968333\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.077999 Validation acc: 0.967222\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.075938 Train acc: 0.975000\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.070427 Train acc: 0.971667\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.054693 Train acc: 0.985000\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.081521 Train acc: 0.973333\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.091471 Train acc: 0.970000\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.077373 Validation acc: 0.968889\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.100475 Train acc: 0.968333\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.051399 Train acc: 0.985000\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.112140 Train acc: 0.951667\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.085425 Train acc: 0.975000\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.082202 Train acc: 0.968333\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.073097 Validation acc: 0.967222\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.066679 Train acc: 0.976667\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.061289 Train acc: 0.983333\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.081467 Train acc: 0.973333\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.087506 Train acc: 0.971667\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.099223 Train acc: 0.963333\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.072191 Validation acc: 0.970000\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.046244 Train acc: 0.990000\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.092999 Train acc: 0.961667\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.093386 Train acc: 0.968333\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.081363 Train acc: 0.973333\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.071176 Train acc: 0.975000\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.075007 Validation acc: 0.969444\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.058644 Train acc: 0.978333\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.086420 Train acc: 0.970000\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.091242 Train acc: 0.975000\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.082980 Train acc: 0.963333\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.042282 Train acc: 0.991667\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.082253 Validation acc: 0.968333\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.106999 Train acc: 0.955000\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.082348 Train acc: 0.971667\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.085307 Train acc: 0.968333\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.066393 Train acc: 0.978333\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.049399 Train acc: 0.986667\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.079239 Validation acc: 0.969444\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.088445 Train acc: 0.971667\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.092761 Train acc: 0.973333\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.094249 Train acc: 0.960000\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.049266 Train acc: 0.983333\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.099296 Train acc: 0.955000\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.073239 Validation acc: 0.970000\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.099661 Train acc: 0.970000\n",
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.078584 Train acc: 0.983333\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.075622 Train acc: 0.966667\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.057881 Train acc: 0.973333\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.082995 Train acc: 0.971667\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.090109 Validation acc: 0.966667\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.102352 Train acc: 0.965000\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.093540 Train acc: 0.963333\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.052194 Train acc: 0.978333\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.105087 Train acc: 0.951667\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.141964 Train acc: 0.958333\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.159839 Validation acc: 0.957222\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.132577 Train acc: 0.968333\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.081848 Train acc: 0.963333\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.063003 Train acc: 0.975000\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.096501 Train acc: 0.968333\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.098949 Train acc: 0.971667\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.078645 Validation acc: 0.964444\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.096275 Train acc: 0.960000\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.046567 Train acc: 0.985000\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.100969 Train acc: 0.955000\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.093752 Train acc: 0.966667\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.083333 Train acc: 0.966667\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.072086 Validation acc: 0.969444\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.069154 Train acc: 0.975000\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.056389 Train acc: 0.983333\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.085720 Train acc: 0.971667\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.094178 Train acc: 0.970000\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.092386 Train acc: 0.963333\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.071740 Validation acc: 0.968333\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.054671 Train acc: 0.983333\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.096119 Train acc: 0.958333\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.092490 Train acc: 0.960000\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.081966 Train acc: 0.971667\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.071822 Train acc: 0.973333\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.074660 Validation acc: 0.970556\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.064101 Train acc: 0.971667\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.090563 Train acc: 0.973333\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.106128 Train acc: 0.963333\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.098418 Train acc: 0.963333\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.047166 Train acc: 0.985000\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.073524 Validation acc: 0.969444\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.106372 Train acc: 0.956667\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.091561 Train acc: 0.968333\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.080797 Train acc: 0.963333\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.069938 Train acc: 0.980000\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.056257 Train acc: 0.981667\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.071873 Validation acc: 0.968333\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.082515 Train acc: 0.973333\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.089600 Train acc: 0.971667\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.088111 Train acc: 0.961667\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.043732 Train acc: 0.986667\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.096327 Train acc: 0.953333\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.072706 Validation acc: 0.970556\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.076264 Train acc: 0.973333\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.081133 Train acc: 0.971667\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.074568 Train acc: 0.976667\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.051394 Train acc: 0.980000\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.087339 Train acc: 0.971667\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.077042 Validation acc: 0.970000\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.095086 Train acc: 0.973333\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.104087 Train acc: 0.951667\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.045935 Train acc: 0.985000\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.104878 Train acc: 0.955000\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.080482 Train acc: 0.971667\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.072660 Validation acc: 0.970556\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.081397 Train acc: 0.965000\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.072609 Train acc: 0.971667\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.051851 Train acc: 0.980000\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.095430 Train acc: 0.971667\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.100985 Train acc: 0.970000\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.074604 Validation acc: 0.970556\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.092603 Train acc: 0.965000\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.043925 Train acc: 0.983333\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.100569 Train acc: 0.956667\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.091476 Train acc: 0.966667\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.079721 Train acc: 0.970000\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.072350 Validation acc: 0.968333\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.064418 Train acc: 0.975000\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.053632 Train acc: 0.980000\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.085350 Train acc: 0.970000\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.089032 Train acc: 0.971667\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.093308 Train acc: 0.966667\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.075523 Validation acc: 0.971111\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.045580 Train acc: 0.988333\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.101173 Train acc: 0.955000\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.093383 Train acc: 0.966667\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.071321 Train acc: 0.975000\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.064469 Train acc: 0.976667\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.073574 Validation acc: 0.969444\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.049792 Train acc: 0.978333\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.091983 Train acc: 0.970000\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.087470 Train acc: 0.975000\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.107277 Train acc: 0.961667\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.050382 Train acc: 0.986667\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.075991 Validation acc: 0.968333\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.104854 Train acc: 0.956667\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.096630 Train acc: 0.966667\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.078383 Train acc: 0.966667\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.069992 Train acc: 0.976667\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.053361 Train acc: 0.976667\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.071915 Validation acc: 0.970556\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.080904 Train acc: 0.970000\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.087989 Train acc: 0.968333\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.088208 Train acc: 0.965000\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.044154 Train acc: 0.991667\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.108322 Train acc: 0.951667\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.072756 Validation acc: 0.970556\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.086201 Train acc: 0.975000\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.078392 Train acc: 0.973333\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.073726 Train acc: 0.976667\n",
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.054695 Train acc: 0.976667\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.097097 Train acc: 0.966667\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.075789 Validation acc: 0.968889\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.075575 Train acc: 0.976667\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.097375 Train acc: 0.958333\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.047558 Train acc: 0.988333\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.105345 Train acc: 0.960000\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.103629 Train acc: 0.968333\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.084071 Validation acc: 0.966111\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.084089 Train acc: 0.966667\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.068477 Train acc: 0.975000\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.058041 Train acc: 0.976667\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.077863 Train acc: 0.973333\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.082433 Train acc: 0.971667\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.073407 Validation acc: 0.968889\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.100465 Train acc: 0.958333\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.047048 Train acc: 0.985000\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.115337 Train acc: 0.945000\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.088470 Train acc: 0.966667\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.088246 Train acc: 0.970000\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.078107 Validation acc: 0.968889\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.069262 Train acc: 0.970000\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.052228 Train acc: 0.978333\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.088562 Train acc: 0.970000\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.083106 Train acc: 0.971667\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.094843 Train acc: 0.965000\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.087760 Validation acc: 0.967778\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.045403 Train acc: 0.985000\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.106406 Train acc: 0.961667\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.096387 Train acc: 0.966667\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.080646 Train acc: 0.971667\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.071307 Train acc: 0.968333\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.073766 Validation acc: 0.971111\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.053079 Train acc: 0.983333\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.084036 Train acc: 0.970000\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.098687 Train acc: 0.968333\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.095772 Train acc: 0.956667\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.048542 Train acc: 0.988333\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.071717 Validation acc: 0.971111\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.111086 Train acc: 0.951667\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.077715 Train acc: 0.973333\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.075329 Train acc: 0.971667\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.069270 Train acc: 0.975000\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.051863 Train acc: 0.983333\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.078258 Validation acc: 0.969444\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.085610 Train acc: 0.973333\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.091521 Train acc: 0.973333\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.087124 Train acc: 0.965000\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.050944 Train acc: 0.978333\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.105270 Train acc: 0.956667\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.071429 Validation acc: 0.970000\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.084420 Train acc: 0.973333\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.065158 Train acc: 0.978333\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.074410 Train acc: 0.975000\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.046180 Train acc: 0.985000\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.081246 Train acc: 0.978333\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.072331 Validation acc: 0.970556\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.083102 Train acc: 0.970000\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.101678 Train acc: 0.963333\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.044860 Train acc: 0.990000\n",
      "Epoch: 999/1000 Iteration: 8995 Train loss: 0.110905 Train acc: 0.946667\n",
      "Epoch: 999/1000 Iteration: 9000 Train loss: 0.082684 Train acc: 0.973333\n",
      "Epoch: 999/1000 Iteration: 9000 Validation loss: 0.075262 Validation acc: 0.967778\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-crnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed459330f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wMvo9E76tCgnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed4cfe7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.884167\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-crnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
