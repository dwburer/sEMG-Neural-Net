{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_acc_x\n",
      "body_acc_y\n",
      "body_acc_z\n",
      "body_gyro_x\n",
      "body_gyro_y\n",
      "body_gyro_z\n",
      "total_acc_x\n",
      "total_acc_y\n",
      "total_acc_z\n",
      "body_acc_x\n",
      "body_acc_y\n",
      "body_acc_z\n",
      "body_gyro_x\n",
      "body_gyro_y\n",
      "body_gyro_z\n",
      "total_acc_x\n",
      "total_acc_y\n",
      "total_acc_z\n"
     ]
    }
   ],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 64, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 64, 18) --> (batch, 32, 36)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=36, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 32, 36) --> (batch, 16, 72)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=72, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 16, 72) --> (batch, 8, 144)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=144, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_4, (-1, 8*144))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.780657 Train acc: 0.190000\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.741611 Train acc: 0.211667\n",
      "Epoch: 1/1000 Iteration: 10 Validation loss: 1.678074 Validation acc: 0.234444\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.692218 Train acc: 0.235000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.601657 Train acc: 0.288333\n",
      "Epoch: 2/1000 Iteration: 20 Validation loss: 1.593624 Validation acc: 0.351667\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.601781 Train acc: 0.295000\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.562732 Train acc: 0.325000\n",
      "Epoch: 3/1000 Iteration: 30 Validation loss: 1.525895 Validation acc: 0.359444\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.518851 Train acc: 0.336667\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.495055 Train acc: 0.353333\n",
      "Epoch: 4/1000 Iteration: 40 Validation loss: 1.461727 Validation acc: 0.372222\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.493745 Train acc: 0.321667\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.404542 Train acc: 0.390000\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.396678 Validation acc: 0.383333\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.401706 Train acc: 0.383333\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.367593 Train acc: 0.380000\n",
      "Epoch: 6/1000 Iteration: 60 Validation loss: 1.334705 Validation acc: 0.401667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.306734 Train acc: 0.403333\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.298501 Train acc: 0.408333\n",
      "Epoch: 7/1000 Iteration: 70 Validation loss: 1.279583 Validation acc: 0.435556\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.307585 Train acc: 0.405000\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.285735 Train acc: 0.416667\n",
      "Epoch: 8/1000 Iteration: 80 Validation loss: 1.232174 Validation acc: 0.517778\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.288013 Train acc: 0.411667\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.279841 Train acc: 0.460000\n",
      "Epoch: 9/1000 Iteration: 90 Validation loss: 1.191500 Validation acc: 0.571667\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.177909 Train acc: 0.505000\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.200132 Train acc: 0.508333\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.154944 Validation acc: 0.613889\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.161245 Train acc: 0.533333\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.126794 Train acc: 0.531667\n",
      "Epoch: 12/1000 Iteration: 110 Validation loss: 1.119432 Validation acc: 0.658889\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.136215 Train acc: 0.585000\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.137711 Train acc: 0.585000\n",
      "Epoch: 13/1000 Iteration: 120 Validation loss: 1.082107 Validation acc: 0.708889\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.135109 Train acc: 0.576667\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.128237 Train acc: 0.590000\n",
      "Epoch: 14/1000 Iteration: 130 Validation loss: 1.041745 Validation acc: 0.747222\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.118637 Train acc: 0.638333\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.010563 Train acc: 0.711667\n",
      "Epoch: 15/1000 Iteration: 140 Validation loss: 0.997533 Validation acc: 0.777778\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.017686 Train acc: 0.678333\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 0.981734 Train acc: 0.703333\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 0.948807 Validation acc: 0.805000\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 0.933066 Train acc: 0.728333\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 0.938259 Train acc: 0.736667\n",
      "Epoch: 17/1000 Iteration: 160 Validation loss: 0.895312 Validation acc: 0.829444\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 0.935690 Train acc: 0.728333\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 0.901447 Train acc: 0.778333\n",
      "Epoch: 18/1000 Iteration: 170 Validation loss: 0.836895 Validation acc: 0.846667\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 0.894648 Train acc: 0.753333\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 0.854605 Train acc: 0.785000\n",
      "Epoch: 19/1000 Iteration: 180 Validation loss: 0.774351 Validation acc: 0.867222\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 0.774973 Train acc: 0.805000\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 0.757353 Train acc: 0.791667\n",
      "Epoch: 21/1000 Iteration: 190 Validation loss: 0.707906 Validation acc: 0.875556\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 0.724309 Train acc: 0.810000\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 0.669544 Train acc: 0.848333\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 0.641405 Validation acc: 0.884444\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 0.649433 Train acc: 0.835000\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 0.658887 Train acc: 0.820000\n",
      "Epoch: 23/1000 Iteration: 210 Validation loss: 0.575753 Validation acc: 0.896667\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 0.605488 Train acc: 0.860000\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 0.627381 Train acc: 0.801667\n",
      "Epoch: 24/1000 Iteration: 220 Validation loss: 0.514135 Validation acc: 0.904444\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 0.566131 Train acc: 0.843333\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 0.498903 Train acc: 0.876667\n",
      "Epoch: 25/1000 Iteration: 230 Validation loss: 0.458742 Validation acc: 0.908333\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 0.514594 Train acc: 0.846667\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 0.469053 Train acc: 0.871667\n",
      "Epoch: 26/1000 Iteration: 240 Validation loss: 0.409485 Validation acc: 0.908889\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 0.429253 Train acc: 0.891667\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 0.415949 Train acc: 0.886667\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 0.368103 Validation acc: 0.909444\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 0.426608 Train acc: 0.865000\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 0.362349 Train acc: 0.898333\n",
      "Epoch: 28/1000 Iteration: 260 Validation loss: 0.332177 Validation acc: 0.908889\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 0.405417 Train acc: 0.858333\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 0.370315 Train acc: 0.896667\n",
      "Epoch: 29/1000 Iteration: 270 Validation loss: 0.303265 Validation acc: 0.910556\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 0.342952 Train acc: 0.901667\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 0.335364 Train acc: 0.891667\n",
      "Epoch: 31/1000 Iteration: 280 Validation loss: 0.278148 Validation acc: 0.913889\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 0.307275 Train acc: 0.898333\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 0.286314 Train acc: 0.916667\n",
      "Epoch: 32/1000 Iteration: 290 Validation loss: 0.257942 Validation acc: 0.918333\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 0.287139 Train acc: 0.913333\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 0.295892 Train acc: 0.898333\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 0.241647 Validation acc: 0.920556\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 0.257400 Train acc: 0.918333\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 0.290527 Train acc: 0.888333\n",
      "Epoch: 34/1000 Iteration: 310 Validation loss: 0.227322 Validation acc: 0.925000\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 0.257446 Train acc: 0.918333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 0.245958 Train acc: 0.920000\n",
      "Epoch: 35/1000 Iteration: 320 Validation loss: 0.215212 Validation acc: 0.928333\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 0.249548 Train acc: 0.915000\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 0.225242 Train acc: 0.921667\n",
      "Epoch: 36/1000 Iteration: 330 Validation loss: 0.205309 Validation acc: 0.928333\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 0.223455 Train acc: 0.936667\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 0.217938 Train acc: 0.916667\n",
      "Epoch: 37/1000 Iteration: 340 Validation loss: 0.197508 Validation acc: 0.931111\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 0.247560 Train acc: 0.898333\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 0.187946 Train acc: 0.930000\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 0.189730 Validation acc: 0.931667\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 0.234346 Train acc: 0.901667\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 0.212128 Train acc: 0.931667\n",
      "Epoch: 39/1000 Iteration: 360 Validation loss: 0.183454 Validation acc: 0.931667\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 0.201977 Train acc: 0.933333\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 0.210893 Train acc: 0.918333\n",
      "Epoch: 41/1000 Iteration: 370 Validation loss: 0.178292 Validation acc: 0.933889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/1000 Iteration: 375 Train loss: 0.177088 Train acc: 0.945000\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 0.186437 Train acc: 0.935000\n",
      "Epoch: 42/1000 Iteration: 380 Validation loss: 0.172822 Validation acc: 0.936667\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 0.197420 Train acc: 0.930000\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 0.212771 Train acc: 0.913333\n",
      "Epoch: 43/1000 Iteration: 390 Validation loss: 0.168912 Validation acc: 0.935555\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.153085 Train acc: 0.950000\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 0.204223 Train acc: 0.911667\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.164626 Validation acc: 0.937222\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.193127 Train acc: 0.936667\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.179157 Train acc: 0.933333\n",
      "Epoch: 45/1000 Iteration: 410 Validation loss: 0.161027 Validation acc: 0.937222\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.171222 Train acc: 0.930000\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.168194 Train acc: 0.936667\n",
      "Epoch: 46/1000 Iteration: 420 Validation loss: 0.158583 Validation acc: 0.939444\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.166651 Train acc: 0.940000\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.168865 Train acc: 0.931667\n",
      "Epoch: 47/1000 Iteration: 430 Validation loss: 0.155127 Validation acc: 0.937778\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.185078 Train acc: 0.911667\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.136659 Train acc: 0.956667\n",
      "Epoch: 48/1000 Iteration: 440 Validation loss: 0.152509 Validation acc: 0.940556\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.185937 Train acc: 0.926667\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.172759 Train acc: 0.940000\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.150091 Validation acc: 0.939444\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.158941 Train acc: 0.956667\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.153863 Train acc: 0.935000\n",
      "Epoch: 51/1000 Iteration: 460 Validation loss: 0.148179 Validation acc: 0.940556\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.142781 Train acc: 0.953333\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.142831 Train acc: 0.956667\n",
      "Epoch: 52/1000 Iteration: 470 Validation loss: 0.146366 Validation acc: 0.940000\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.149286 Train acc: 0.943333\n",
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.179316 Train acc: 0.918333\n",
      "Epoch: 53/1000 Iteration: 480 Validation loss: 0.144742 Validation acc: 0.940556\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.135564 Train acc: 0.956667\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.178509 Train acc: 0.926667\n",
      "Epoch: 54/1000 Iteration: 490 Validation loss: 0.142415 Validation acc: 0.940556\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.166683 Train acc: 0.941667\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.152429 Train acc: 0.940000\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.140585 Validation acc: 0.941111\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.147075 Train acc: 0.943333\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.140524 Train acc: 0.940000\n",
      "Epoch: 56/1000 Iteration: 510 Validation loss: 0.139264 Validation acc: 0.942222\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.138307 Train acc: 0.951667\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.142308 Train acc: 0.948333\n",
      "Epoch: 57/1000 Iteration: 520 Validation loss: 0.137443 Validation acc: 0.941667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.160022 Train acc: 0.923333\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.113851 Train acc: 0.961667\n",
      "Epoch: 58/1000 Iteration: 530 Validation loss: 0.136115 Validation acc: 0.940556\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.163997 Train acc: 0.930000\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.149428 Train acc: 0.943333\n",
      "Epoch: 59/1000 Iteration: 540 Validation loss: 0.134857 Validation acc: 0.941111\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.145932 Train acc: 0.938333\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.143383 Train acc: 0.941667\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.133774 Validation acc: 0.940000\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.130113 Train acc: 0.953333\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.132321 Train acc: 0.953333\n",
      "Epoch: 62/1000 Iteration: 560 Validation loss: 0.132382 Validation acc: 0.942222\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.136929 Train acc: 0.946667\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.156544 Train acc: 0.928333\n",
      "Epoch: 63/1000 Iteration: 570 Validation loss: 0.131615 Validation acc: 0.943333\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.104347 Train acc: 0.960000\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.157324 Train acc: 0.945000\n",
      "Epoch: 64/1000 Iteration: 580 Validation loss: 0.130181 Validation acc: 0.943889\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.148577 Train acc: 0.950000\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.134657 Train acc: 0.941667\n",
      "Epoch: 65/1000 Iteration: 590 Validation loss: 0.129600 Validation acc: 0.943333\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.128484 Train acc: 0.945000\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.124024 Train acc: 0.946667\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.128378 Validation acc: 0.944444\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.133511 Train acc: 0.950000\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.136345 Train acc: 0.941667\n",
      "Epoch: 67/1000 Iteration: 610 Validation loss: 0.127895 Validation acc: 0.943889\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.147652 Train acc: 0.926667\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.105126 Train acc: 0.961667\n",
      "Epoch: 68/1000 Iteration: 620 Validation loss: 0.126734 Validation acc: 0.945000\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.148405 Train acc: 0.926667\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.144827 Train acc: 0.945000\n",
      "Epoch: 69/1000 Iteration: 630 Validation loss: 0.126137 Validation acc: 0.944444\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.132110 Train acc: 0.946667\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.123422 Train acc: 0.953333\n",
      "Epoch: 71/1000 Iteration: 640 Validation loss: 0.125225 Validation acc: 0.946111\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.122916 Train acc: 0.950000\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.125846 Train acc: 0.953333\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.124474 Validation acc: 0.945556\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.126039 Train acc: 0.941667\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.151064 Train acc: 0.933333\n",
      "Epoch: 73/1000 Iteration: 660 Validation loss: 0.123747 Validation acc: 0.946667\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.108391 Train acc: 0.953333\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.145209 Train acc: 0.930000\n",
      "Epoch: 74/1000 Iteration: 670 Validation loss: 0.123238 Validation acc: 0.947778\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.127494 Train acc: 0.950000\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.128611 Train acc: 0.953333\n",
      "Epoch: 75/1000 Iteration: 680 Validation loss: 0.122787 Validation acc: 0.949444\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.123935 Train acc: 0.948333\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.120438 Train acc: 0.948333\n",
      "Epoch: 76/1000 Iteration: 690 Validation loss: 0.122135 Validation acc: 0.946111\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.123870 Train acc: 0.960000\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.122585 Train acc: 0.956667\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.122260 Validation acc: 0.948889\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.146398 Train acc: 0.931667\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.101250 Train acc: 0.956667\n",
      "Epoch: 78/1000 Iteration: 710 Validation loss: 0.120871 Validation acc: 0.947222\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.146267 Train acc: 0.931667\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.138702 Train acc: 0.948333\n",
      "Epoch: 79/1000 Iteration: 720 Validation loss: 0.120860 Validation acc: 0.948889\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.128430 Train acc: 0.946667\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.113298 Train acc: 0.953333\n",
      "Epoch: 81/1000 Iteration: 730 Validation loss: 0.120162 Validation acc: 0.947778\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.115782 Train acc: 0.955000\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.117533 Train acc: 0.956667\n",
      "Epoch: 82/1000 Iteration: 740 Validation loss: 0.119573 Validation acc: 0.948333\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.120522 Train acc: 0.948333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.142479 Train acc: 0.940000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.119208 Validation acc: 0.949444\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.095309 Train acc: 0.963333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.141691 Train acc: 0.935000\n",
      "Epoch: 84/1000 Iteration: 760 Validation loss: 0.118750 Validation acc: 0.950000\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.127053 Train acc: 0.953333\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.119437 Train acc: 0.956667\n",
      "Epoch: 85/1000 Iteration: 770 Validation loss: 0.118171 Validation acc: 0.950000\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.112604 Train acc: 0.958333\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.110373 Train acc: 0.951667\n",
      "Epoch: 86/1000 Iteration: 780 Validation loss: 0.117669 Validation acc: 0.950000\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.119712 Train acc: 0.955000\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.118592 Train acc: 0.950000\n",
      "Epoch: 87/1000 Iteration: 790 Validation loss: 0.117576 Validation acc: 0.950000\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.145223 Train acc: 0.926667\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.093128 Train acc: 0.963333\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.117362 Validation acc: 0.950000\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.141354 Train acc: 0.936667\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.122390 Train acc: 0.950000\n",
      "Epoch: 89/1000 Iteration: 810 Validation loss: 0.116667 Validation acc: 0.950000\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.119358 Train acc: 0.945000\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.117485 Train acc: 0.950000\n",
      "Epoch: 91/1000 Iteration: 820 Validation loss: 0.115930 Validation acc: 0.950000\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.106629 Train acc: 0.950000\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.112325 Train acc: 0.956667\n",
      "Epoch: 92/1000 Iteration: 830 Validation loss: 0.115709 Validation acc: 0.950000\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.115029 Train acc: 0.960000\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.145426 Train acc: 0.926667\n",
      "Epoch: 93/1000 Iteration: 840 Validation loss: 0.115573 Validation acc: 0.951111\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.091143 Train acc: 0.965000\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.132065 Train acc: 0.938333\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.115309 Validation acc: 0.950556\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.115367 Train acc: 0.953333\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.106620 Train acc: 0.963333\n",
      "Epoch: 95/1000 Iteration: 860 Validation loss: 0.114854 Validation acc: 0.950556\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.108468 Train acc: 0.960000\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.097210 Train acc: 0.961667\n",
      "Epoch: 96/1000 Iteration: 870 Validation loss: 0.114823 Validation acc: 0.951111\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.104439 Train acc: 0.965000\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.118182 Train acc: 0.946667\n",
      "Epoch: 97/1000 Iteration: 880 Validation loss: 0.114310 Validation acc: 0.950556\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.137372 Train acc: 0.938333\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.086820 Train acc: 0.961667\n",
      "Epoch: 98/1000 Iteration: 890 Validation loss: 0.113828 Validation acc: 0.950556\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.134982 Train acc: 0.933333\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.123084 Train acc: 0.953333\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.113581 Validation acc: 0.951111\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.111262 Train acc: 0.958333\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.097783 Train acc: 0.960000\n",
      "Epoch: 101/1000 Iteration: 910 Validation loss: 0.113129 Validation acc: 0.951111\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.108778 Train acc: 0.950000\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.105682 Train acc: 0.965000\n",
      "Epoch: 102/1000 Iteration: 920 Validation loss: 0.113388 Validation acc: 0.951667\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.109987 Train acc: 0.956667\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.136361 Train acc: 0.930000\n",
      "Epoch: 103/1000 Iteration: 930 Validation loss: 0.112836 Validation acc: 0.951667\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.090217 Train acc: 0.956667\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.131594 Train acc: 0.933333\n",
      "Epoch: 104/1000 Iteration: 940 Validation loss: 0.112506 Validation acc: 0.951111\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.114333 Train acc: 0.948333\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.112595 Train acc: 0.951667\n",
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.111789 Validation acc: 0.951667\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.102942 Train acc: 0.955000\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.103693 Train acc: 0.953333\n",
      "Epoch: 106/1000 Iteration: 960 Validation loss: 0.111628 Validation acc: 0.952222\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.109835 Train acc: 0.963333\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.112771 Train acc: 0.953333\n",
      "Epoch: 107/1000 Iteration: 970 Validation loss: 0.111544 Validation acc: 0.952222\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.130901 Train acc: 0.931667\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.081272 Train acc: 0.965000\n",
      "Epoch: 108/1000 Iteration: 980 Validation loss: 0.111258 Validation acc: 0.951667\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.133983 Train acc: 0.936667\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.112136 Train acc: 0.955000\n",
      "Epoch: 109/1000 Iteration: 990 Validation loss: 0.110160 Validation acc: 0.952222\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.110601 Train acc: 0.953333\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.092744 Train acc: 0.963333\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.109944 Validation acc: 0.951667\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.098598 Train acc: 0.958333\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.099527 Train acc: 0.965000\n",
      "Epoch: 112/1000 Iteration: 1010 Validation loss: 0.110775 Validation acc: 0.952222\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.114322 Train acc: 0.951667\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.132904 Train acc: 0.940000\n",
      "Epoch: 113/1000 Iteration: 1020 Validation loss: 0.109903 Validation acc: 0.953889\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.077681 Train acc: 0.965000\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.128798 Train acc: 0.936667\n",
      "Epoch: 114/1000 Iteration: 1030 Validation loss: 0.110378 Validation acc: 0.952778\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.115140 Train acc: 0.955000\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.103242 Train acc: 0.955000\n",
      "Epoch: 115/1000 Iteration: 1040 Validation loss: 0.109180 Validation acc: 0.952222\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.108208 Train acc: 0.955000\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.093047 Train acc: 0.960000\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.109334 Validation acc: 0.953333\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.093056 Train acc: 0.970000\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.109295 Train acc: 0.951667\n",
      "Epoch: 117/1000 Iteration: 1060 Validation loss: 0.108970 Validation acc: 0.951667\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.127529 Train acc: 0.938333\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.080181 Train acc: 0.970000\n",
      "Epoch: 118/1000 Iteration: 1070 Validation loss: 0.108737 Validation acc: 0.951111\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.127023 Train acc: 0.940000\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.106079 Train acc: 0.955000\n",
      "Epoch: 119/1000 Iteration: 1080 Validation loss: 0.108723 Validation acc: 0.953333\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.111792 Train acc: 0.955000\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.100444 Train acc: 0.958333\n",
      "Epoch: 121/1000 Iteration: 1090 Validation loss: 0.108347 Validation acc: 0.951111\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.098897 Train acc: 0.950000\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.105915 Train acc: 0.963333\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.108287 Validation acc: 0.953889\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.108805 Train acc: 0.950000\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.130505 Train acc: 0.931667\n",
      "Epoch: 123/1000 Iteration: 1110 Validation loss: 0.107888 Validation acc: 0.953333\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.077546 Train acc: 0.968333\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.120562 Train acc: 0.940000\n",
      "Epoch: 124/1000 Iteration: 1120 Validation loss: 0.107725 Validation acc: 0.952778\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.112922 Train acc: 0.950000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.107176 Train acc: 0.948333\n",
      "Epoch: 125/1000 Iteration: 1130 Validation loss: 0.107596 Validation acc: 0.953333\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.093080 Train acc: 0.960000\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.094040 Train acc: 0.960000\n",
      "Epoch: 126/1000 Iteration: 1140 Validation loss: 0.107199 Validation acc: 0.953889\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.096476 Train acc: 0.961667\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.105436 Train acc: 0.956667\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.107328 Validation acc: 0.952778\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.124120 Train acc: 0.933333\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.082746 Train acc: 0.966667\n",
      "Epoch: 128/1000 Iteration: 1160 Validation loss: 0.106523 Validation acc: 0.952778\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.119667 Train acc: 0.940000\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.114987 Train acc: 0.956667\n",
      "Epoch: 129/1000 Iteration: 1170 Validation loss: 0.106382 Validation acc: 0.952778\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.103235 Train acc: 0.960000\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.099908 Train acc: 0.960000\n",
      "Epoch: 131/1000 Iteration: 1180 Validation loss: 0.105884 Validation acc: 0.953333\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.096946 Train acc: 0.960000\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.100482 Train acc: 0.963333\n",
      "Epoch: 132/1000 Iteration: 1190 Validation loss: 0.106207 Validation acc: 0.953889\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.106099 Train acc: 0.960000\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.128354 Train acc: 0.935000\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.105730 Validation acc: 0.952778\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.084667 Train acc: 0.965000\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.123998 Train acc: 0.940000\n",
      "Epoch: 134/1000 Iteration: 1210 Validation loss: 0.105712 Validation acc: 0.955000\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.114217 Train acc: 0.948333\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.105724 Train acc: 0.956667\n",
      "Epoch: 135/1000 Iteration: 1220 Validation loss: 0.105885 Validation acc: 0.955000\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.094968 Train acc: 0.956667\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.096692 Train acc: 0.951667\n",
      "Epoch: 136/1000 Iteration: 1230 Validation loss: 0.105238 Validation acc: 0.954444\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.102588 Train acc: 0.960000\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.101122 Train acc: 0.958333\n",
      "Epoch: 137/1000 Iteration: 1240 Validation loss: 0.105117 Validation acc: 0.955556\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.118717 Train acc: 0.945000\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.077039 Train acc: 0.966667\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.104617 Validation acc: 0.954444\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.118636 Train acc: 0.938333\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.101680 Train acc: 0.965000\n",
      "Epoch: 139/1000 Iteration: 1260 Validation loss: 0.103938 Validation acc: 0.955555\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.106312 Train acc: 0.955000\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.088109 Train acc: 0.960000\n",
      "Epoch: 141/1000 Iteration: 1270 Validation loss: 0.104047 Validation acc: 0.955556\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.092326 Train acc: 0.956667\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.097747 Train acc: 0.960000\n",
      "Epoch: 142/1000 Iteration: 1280 Validation loss: 0.103381 Validation acc: 0.955555\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.097834 Train acc: 0.958333\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.125004 Train acc: 0.933333\n",
      "Epoch: 143/1000 Iteration: 1290 Validation loss: 0.103357 Validation acc: 0.955556\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.077164 Train acc: 0.966667\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.119140 Train acc: 0.938333\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.103117 Validation acc: 0.955555\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.101663 Train acc: 0.965000\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.096681 Train acc: 0.958333\n",
      "Epoch: 145/1000 Iteration: 1310 Validation loss: 0.102931 Validation acc: 0.956111\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.089759 Train acc: 0.963333\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.090371 Train acc: 0.956667\n",
      "Epoch: 146/1000 Iteration: 1320 Validation loss: 0.102691 Validation acc: 0.956111\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.095994 Train acc: 0.961667\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.099587 Train acc: 0.960000\n",
      "Epoch: 147/1000 Iteration: 1330 Validation loss: 0.102606 Validation acc: 0.956111\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.120645 Train acc: 0.936667\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.077721 Train acc: 0.963333\n",
      "Epoch: 148/1000 Iteration: 1340 Validation loss: 0.102515 Validation acc: 0.956111\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.113204 Train acc: 0.943333\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.102226 Train acc: 0.955000\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.101942 Validation acc: 0.956111\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.102254 Train acc: 0.951667\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.091651 Train acc: 0.960000\n",
      "Epoch: 151/1000 Iteration: 1360 Validation loss: 0.101966 Validation acc: 0.955556\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.087407 Train acc: 0.958333\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.093957 Train acc: 0.963333\n",
      "Epoch: 152/1000 Iteration: 1370 Validation loss: 0.101989 Validation acc: 0.955000\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.097505 Train acc: 0.961667\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.117233 Train acc: 0.946667\n",
      "Epoch: 153/1000 Iteration: 1380 Validation loss: 0.101947 Validation acc: 0.955000\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.074489 Train acc: 0.961667\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.116834 Train acc: 0.940000\n",
      "Epoch: 154/1000 Iteration: 1390 Validation loss: 0.101573 Validation acc: 0.955555\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.101529 Train acc: 0.961667\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.098391 Train acc: 0.958333\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.101228 Validation acc: 0.955555\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.087169 Train acc: 0.961667\n",
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.089869 Train acc: 0.960000\n",
      "Epoch: 156/1000 Iteration: 1410 Validation loss: 0.100955 Validation acc: 0.956667\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.089017 Train acc: 0.965000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.099908 Train acc: 0.956667\n",
      "Epoch: 157/1000 Iteration: 1420 Validation loss: 0.100743 Validation acc: 0.956111\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.117974 Train acc: 0.938333\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.071398 Train acc: 0.970000\n",
      "Epoch: 158/1000 Iteration: 1430 Validation loss: 0.100106 Validation acc: 0.956111\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.113555 Train acc: 0.940000\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.101673 Train acc: 0.958333\n",
      "Epoch: 159/1000 Iteration: 1440 Validation loss: 0.100436 Validation acc: 0.955556\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.104171 Train acc: 0.956667\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.089338 Train acc: 0.961667\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.099968 Validation acc: 0.956111\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.089866 Train acc: 0.956667\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.091176 Train acc: 0.960000\n",
      "Epoch: 162/1000 Iteration: 1460 Validation loss: 0.099501 Validation acc: 0.956667\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.097622 Train acc: 0.961667\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.115858 Train acc: 0.941667\n",
      "Epoch: 163/1000 Iteration: 1470 Validation loss: 0.099313 Validation acc: 0.956111\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.072946 Train acc: 0.971667\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.107884 Train acc: 0.945000\n",
      "Epoch: 164/1000 Iteration: 1480 Validation loss: 0.099169 Validation acc: 0.955555\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.096415 Train acc: 0.963333\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.099192 Train acc: 0.955000\n",
      "Epoch: 165/1000 Iteration: 1490 Validation loss: 0.098558 Validation acc: 0.956667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.083384 Train acc: 0.968333\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.093336 Train acc: 0.955000\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.098475 Validation acc: 0.955555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.088092 Train acc: 0.960000\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.089919 Train acc: 0.966667\n",
      "Epoch: 167/1000 Iteration: 1510 Validation loss: 0.098070 Validation acc: 0.956111\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.113228 Train acc: 0.941667\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.071888 Train acc: 0.970000\n",
      "Epoch: 168/1000 Iteration: 1520 Validation loss: 0.097776 Validation acc: 0.956667\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.105455 Train acc: 0.945000\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.094057 Train acc: 0.961667\n",
      "Epoch: 169/1000 Iteration: 1530 Validation loss: 0.098085 Validation acc: 0.956111\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.096802 Train acc: 0.953333\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.083078 Train acc: 0.963333\n",
      "Epoch: 171/1000 Iteration: 1540 Validation loss: 0.097641 Validation acc: 0.956667\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.086233 Train acc: 0.960000\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.091599 Train acc: 0.958333\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.097355 Validation acc: 0.956667\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.092986 Train acc: 0.963333\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.109389 Train acc: 0.948333\n",
      "Epoch: 173/1000 Iteration: 1560 Validation loss: 0.097366 Validation acc: 0.956111\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.068317 Train acc: 0.968333\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.106340 Train acc: 0.945000\n",
      "Epoch: 174/1000 Iteration: 1570 Validation loss: 0.097290 Validation acc: 0.955555\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.089161 Train acc: 0.965000\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.096529 Train acc: 0.955000\n",
      "Epoch: 175/1000 Iteration: 1580 Validation loss: 0.096965 Validation acc: 0.955556\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.088543 Train acc: 0.963333\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.084316 Train acc: 0.965000\n",
      "Epoch: 176/1000 Iteration: 1590 Validation loss: 0.096546 Validation acc: 0.956667\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.084326 Train acc: 0.961667\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.093611 Train acc: 0.960000\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.096447 Validation acc: 0.956667\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.113179 Train acc: 0.946667\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.067988 Train acc: 0.966667\n",
      "Epoch: 178/1000 Iteration: 1610 Validation loss: 0.096160 Validation acc: 0.957222\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.105376 Train acc: 0.953333\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.096592 Train acc: 0.956667\n",
      "Epoch: 179/1000 Iteration: 1620 Validation loss: 0.095788 Validation acc: 0.956667\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.090044 Train acc: 0.965000\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.083288 Train acc: 0.965000\n",
      "Epoch: 181/1000 Iteration: 1630 Validation loss: 0.095619 Validation acc: 0.957222\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.085089 Train acc: 0.956667\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.079069 Train acc: 0.965000\n",
      "Epoch: 182/1000 Iteration: 1640 Validation loss: 0.095686 Validation acc: 0.956667\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.090275 Train acc: 0.965000\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.109884 Train acc: 0.943333\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.095073 Validation acc: 0.956667\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.070309 Train acc: 0.970000\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.100195 Train acc: 0.953333\n",
      "Epoch: 184/1000 Iteration: 1660 Validation loss: 0.094867 Validation acc: 0.956111\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.087278 Train acc: 0.958333\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.095871 Train acc: 0.955000\n",
      "Epoch: 185/1000 Iteration: 1670 Validation loss: 0.094605 Validation acc: 0.956111\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.079850 Train acc: 0.968333\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.081820 Train acc: 0.961667\n",
      "Epoch: 186/1000 Iteration: 1680 Validation loss: 0.094321 Validation acc: 0.956111\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.088224 Train acc: 0.963333\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.087746 Train acc: 0.965000\n",
      "Epoch: 187/1000 Iteration: 1690 Validation loss: 0.094112 Validation acc: 0.957222\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.107645 Train acc: 0.943333\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.068228 Train acc: 0.971667\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.093857 Validation acc: 0.957778\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.105915 Train acc: 0.948333\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.091635 Train acc: 0.960000\n",
      "Epoch: 189/1000 Iteration: 1710 Validation loss: 0.094010 Validation acc: 0.956667\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.093596 Train acc: 0.961667\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.080649 Train acc: 0.961667\n",
      "Epoch: 191/1000 Iteration: 1720 Validation loss: 0.093040 Validation acc: 0.957778\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.078292 Train acc: 0.963333\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.081426 Train acc: 0.968333\n",
      "Epoch: 192/1000 Iteration: 1730 Validation loss: 0.092548 Validation acc: 0.957222\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.079534 Train acc: 0.970000\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.109657 Train acc: 0.945000\n",
      "Epoch: 193/1000 Iteration: 1740 Validation loss: 0.092165 Validation acc: 0.957222\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.068822 Train acc: 0.973333\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.101115 Train acc: 0.948333\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.092488 Validation acc: 0.956667\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.098101 Train acc: 0.966667\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.093070 Train acc: 0.960000\n",
      "Epoch: 195/1000 Iteration: 1760 Validation loss: 0.091762 Validation acc: 0.960556\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.081633 Train acc: 0.963333\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.083459 Train acc: 0.965000\n",
      "Epoch: 196/1000 Iteration: 1770 Validation loss: 0.091688 Validation acc: 0.957222\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.079628 Train acc: 0.963333\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.085849 Train acc: 0.963333\n",
      "Epoch: 197/1000 Iteration: 1780 Validation loss: 0.091572 Validation acc: 0.960000\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.103998 Train acc: 0.943333\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.068557 Train acc: 0.968333\n",
      "Epoch: 198/1000 Iteration: 1790 Validation loss: 0.090974 Validation acc: 0.959444\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.100839 Train acc: 0.953333\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.089250 Train acc: 0.966667\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.090783 Validation acc: 0.958889\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.092712 Train acc: 0.956667\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.079362 Train acc: 0.970000\n",
      "Epoch: 201/1000 Iteration: 1810 Validation loss: 0.090436 Validation acc: 0.959444\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.077910 Train acc: 0.960000\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.075625 Train acc: 0.963333\n",
      "Epoch: 202/1000 Iteration: 1820 Validation loss: 0.090264 Validation acc: 0.958333\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.087044 Train acc: 0.963333\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.103583 Train acc: 0.945000\n",
      "Epoch: 203/1000 Iteration: 1830 Validation loss: 0.090115 Validation acc: 0.960000\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.069054 Train acc: 0.971667\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.105890 Train acc: 0.950000\n",
      "Epoch: 204/1000 Iteration: 1840 Validation loss: 0.089482 Validation acc: 0.958333\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.085999 Train acc: 0.966667\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.088713 Train acc: 0.961667\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.088970 Validation acc: 0.957222\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.075621 Train acc: 0.968333\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.076722 Train acc: 0.965000\n",
      "Epoch: 206/1000 Iteration: 1860 Validation loss: 0.088584 Validation acc: 0.960556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.082835 Train acc: 0.961667\n",
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.077092 Train acc: 0.970000\n",
      "Epoch: 207/1000 Iteration: 1870 Validation loss: 0.088926 Validation acc: 0.957222\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.103507 Train acc: 0.950000\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.061051 Train acc: 0.976667\n",
      "Epoch: 208/1000 Iteration: 1880 Validation loss: 0.087827 Validation acc: 0.960555\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.098919 Train acc: 0.950000\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.088607 Train acc: 0.966667\n",
      "Epoch: 209/1000 Iteration: 1890 Validation loss: 0.087475 Validation acc: 0.958889\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.090778 Train acc: 0.966667\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.076761 Train acc: 0.968333\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.087713 Validation acc: 0.962222\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.078298 Train acc: 0.960000\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.072488 Train acc: 0.968333\n",
      "Epoch: 212/1000 Iteration: 1910 Validation loss: 0.087424 Validation acc: 0.958889\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.082252 Train acc: 0.963333\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.105115 Train acc: 0.943333\n",
      "Epoch: 213/1000 Iteration: 1920 Validation loss: 0.086865 Validation acc: 0.962778\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.064450 Train acc: 0.970000\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.095906 Train acc: 0.956667\n",
      "Epoch: 214/1000 Iteration: 1930 Validation loss: 0.087147 Validation acc: 0.960000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.085522 Train acc: 0.965000\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.088034 Train acc: 0.961667\n",
      "Epoch: 215/1000 Iteration: 1940 Validation loss: 0.086755 Validation acc: 0.958889\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.079442 Train acc: 0.963333\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.076663 Train acc: 0.961667\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.086892 Validation acc: 0.960000\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.072626 Train acc: 0.968333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.078883 Train acc: 0.966667\n",
      "Epoch: 217/1000 Iteration: 1960 Validation loss: 0.086735 Validation acc: 0.959444\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.099415 Train acc: 0.951667\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.063930 Train acc: 0.963333\n",
      "Epoch: 218/1000 Iteration: 1970 Validation loss: 0.085730 Validation acc: 0.961667\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.098944 Train acc: 0.950000\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.077182 Train acc: 0.971667\n",
      "Epoch: 219/1000 Iteration: 1980 Validation loss: 0.085283 Validation acc: 0.960556\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.078851 Train acc: 0.966667\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.074574 Train acc: 0.968333\n",
      "Epoch: 221/1000 Iteration: 1990 Validation loss: 0.084843 Validation acc: 0.961111\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.070951 Train acc: 0.966667\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.068287 Train acc: 0.965000\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.084828 Validation acc: 0.960556\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.074041 Train acc: 0.975000\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.098720 Train acc: 0.950000\n",
      "Epoch: 223/1000 Iteration: 2010 Validation loss: 0.084502 Validation acc: 0.961111\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.056217 Train acc: 0.971667\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.094689 Train acc: 0.950000\n",
      "Epoch: 224/1000 Iteration: 2020 Validation loss: 0.084035 Validation acc: 0.960000\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.080170 Train acc: 0.966667\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.082574 Train acc: 0.961667\n",
      "Epoch: 225/1000 Iteration: 2030 Validation loss: 0.083741 Validation acc: 0.960556\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.075228 Train acc: 0.970000\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.072950 Train acc: 0.971667\n",
      "Epoch: 226/1000 Iteration: 2040 Validation loss: 0.083435 Validation acc: 0.960556\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.069272 Train acc: 0.968333\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.075974 Train acc: 0.965000\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.083266 Validation acc: 0.962778\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.097155 Train acc: 0.951667\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.062407 Train acc: 0.975000\n",
      "Epoch: 228/1000 Iteration: 2060 Validation loss: 0.083082 Validation acc: 0.962778\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.093101 Train acc: 0.950000\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.075977 Train acc: 0.968333\n",
      "Epoch: 229/1000 Iteration: 2070 Validation loss: 0.082769 Validation acc: 0.962778\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.082916 Train acc: 0.961667\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.070032 Train acc: 0.970000\n",
      "Epoch: 231/1000 Iteration: 2080 Validation loss: 0.082512 Validation acc: 0.961111\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.069900 Train acc: 0.971667\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.068963 Train acc: 0.970000\n",
      "Epoch: 232/1000 Iteration: 2090 Validation loss: 0.082085 Validation acc: 0.963333\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.072067 Train acc: 0.968333\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.090844 Train acc: 0.956667\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.082043 Validation acc: 0.961667\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.063935 Train acc: 0.966667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.087190 Train acc: 0.953333\n",
      "Epoch: 234/1000 Iteration: 2110 Validation loss: 0.082134 Validation acc: 0.960000\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.081180 Train acc: 0.970000\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.079551 Train acc: 0.960000\n",
      "Epoch: 235/1000 Iteration: 2120 Validation loss: 0.081066 Validation acc: 0.962778\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.066802 Train acc: 0.971667\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.069088 Train acc: 0.966667\n",
      "Epoch: 236/1000 Iteration: 2130 Validation loss: 0.080853 Validation acc: 0.961111\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.065894 Train acc: 0.970000\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.068255 Train acc: 0.968333\n",
      "Epoch: 237/1000 Iteration: 2140 Validation loss: 0.080004 Validation acc: 0.963333\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.093506 Train acc: 0.953333\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.058105 Train acc: 0.973333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.079852 Validation acc: 0.963889\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.090598 Train acc: 0.955000\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.074512 Train acc: 0.970000\n",
      "Epoch: 239/1000 Iteration: 2160 Validation loss: 0.079483 Validation acc: 0.962222\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.077325 Train acc: 0.953333\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.063863 Train acc: 0.973333\n",
      "Epoch: 241/1000 Iteration: 2170 Validation loss: 0.079213 Validation acc: 0.963889\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.066706 Train acc: 0.970000\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.066628 Train acc: 0.968333\n",
      "Epoch: 242/1000 Iteration: 2180 Validation loss: 0.078836 Validation acc: 0.963333\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.071258 Train acc: 0.968333\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.099361 Train acc: 0.951667\n",
      "Epoch: 243/1000 Iteration: 2190 Validation loss: 0.078656 Validation acc: 0.962222\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.053652 Train acc: 0.978333\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.088850 Train acc: 0.955000\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.078366 Validation acc: 0.962778\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.071896 Train acc: 0.971667\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.073990 Train acc: 0.965000\n",
      "Epoch: 245/1000 Iteration: 2210 Validation loss: 0.078191 Validation acc: 0.962222\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.068908 Train acc: 0.973333\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.069028 Train acc: 0.966667\n",
      "Epoch: 246/1000 Iteration: 2220 Validation loss: 0.077725 Validation acc: 0.961111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.063919 Train acc: 0.970000\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.067481 Train acc: 0.976667\n",
      "Epoch: 247/1000 Iteration: 2230 Validation loss: 0.077560 Validation acc: 0.963889\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.086695 Train acc: 0.958333\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.055043 Train acc: 0.973333\n",
      "Epoch: 248/1000 Iteration: 2240 Validation loss: 0.077387 Validation acc: 0.962778\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.089269 Train acc: 0.956667\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.071574 Train acc: 0.970000\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.077452 Validation acc: 0.963889\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.075846 Train acc: 0.966667\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.068116 Train acc: 0.970000\n",
      "Epoch: 251/1000 Iteration: 2260 Validation loss: 0.076493 Validation acc: 0.963889\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.068354 Train acc: 0.963333\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.064315 Train acc: 0.966667\n",
      "Epoch: 252/1000 Iteration: 2270 Validation loss: 0.076591 Validation acc: 0.962778\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.070214 Train acc: 0.971667\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.081542 Train acc: 0.963333\n",
      "Epoch: 253/1000 Iteration: 2280 Validation loss: 0.076334 Validation acc: 0.962778\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.052897 Train acc: 0.976667\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.083531 Train acc: 0.956667\n",
      "Epoch: 254/1000 Iteration: 2290 Validation loss: 0.075964 Validation acc: 0.961667\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.074818 Train acc: 0.971667\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.073946 Train acc: 0.960000\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.075773 Validation acc: 0.962778\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.065961 Train acc: 0.976667\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.066089 Train acc: 0.966667\n",
      "Epoch: 256/1000 Iteration: 2310 Validation loss: 0.075682 Validation acc: 0.961667\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.060994 Train acc: 0.968333\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.061481 Train acc: 0.973333\n",
      "Epoch: 257/1000 Iteration: 2320 Validation loss: 0.075188 Validation acc: 0.962222\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.086193 Train acc: 0.958333\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.048964 Train acc: 0.981667\n",
      "Epoch: 258/1000 Iteration: 2330 Validation loss: 0.075189 Validation acc: 0.963889\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.083578 Train acc: 0.960000\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.067775 Train acc: 0.973333\n",
      "Epoch: 259/1000 Iteration: 2340 Validation loss: 0.074630 Validation acc: 0.962222\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.070326 Train acc: 0.963333\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.064007 Train acc: 0.978333\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.074217 Validation acc: 0.962778\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.059865 Train acc: 0.970000\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.059979 Train acc: 0.973333\n",
      "Epoch: 262/1000 Iteration: 2360 Validation loss: 0.074293 Validation acc: 0.962222\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.065685 Train acc: 0.971667\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.080580 Train acc: 0.960000\n",
      "Epoch: 263/1000 Iteration: 2370 Validation loss: 0.073779 Validation acc: 0.963333\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.053149 Train acc: 0.978333\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.075563 Train acc: 0.966667\n",
      "Epoch: 264/1000 Iteration: 2380 Validation loss: 0.073443 Validation acc: 0.962222\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.069919 Train acc: 0.965000\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.074657 Train acc: 0.965000\n",
      "Epoch: 265/1000 Iteration: 2390 Validation loss: 0.073870 Validation acc: 0.962778\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.065267 Train acc: 0.971667\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.058174 Train acc: 0.973333\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.073318 Validation acc: 0.963333\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.058413 Train acc: 0.971667\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.061699 Train acc: 0.973333\n",
      "Epoch: 267/1000 Iteration: 2410 Validation loss: 0.072781 Validation acc: 0.963889\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.085572 Train acc: 0.956667\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.052425 Train acc: 0.978333\n",
      "Epoch: 268/1000 Iteration: 2420 Validation loss: 0.072620 Validation acc: 0.962778\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.081356 Train acc: 0.956667\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.065547 Train acc: 0.971667\n",
      "Epoch: 269/1000 Iteration: 2430 Validation loss: 0.072270 Validation acc: 0.963333\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.068777 Train acc: 0.970000\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.063981 Train acc: 0.975000\n",
      "Epoch: 271/1000 Iteration: 2440 Validation loss: 0.072018 Validation acc: 0.963333\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.061236 Train acc: 0.975000\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.057784 Train acc: 0.975000\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.071816 Validation acc: 0.964444\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.060581 Train acc: 0.975000\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.086130 Train acc: 0.953333\n",
      "Epoch: 273/1000 Iteration: 2460 Validation loss: 0.072000 Validation acc: 0.963333\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.048522 Train acc: 0.983333\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.078680 Train acc: 0.963333\n",
      "Epoch: 274/1000 Iteration: 2470 Validation loss: 0.071860 Validation acc: 0.965000\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.067656 Train acc: 0.973333\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.068993 Train acc: 0.966667\n",
      "Epoch: 275/1000 Iteration: 2480 Validation loss: 0.071378 Validation acc: 0.964444\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.059028 Train acc: 0.975000\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.057884 Train acc: 0.973333\n",
      "Epoch: 276/1000 Iteration: 2490 Validation loss: 0.070813 Validation acc: 0.963889\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.060033 Train acc: 0.971667\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.062574 Train acc: 0.975000\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.070757 Validation acc: 0.965000\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.080196 Train acc: 0.960000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.045184 Train acc: 0.985000\n",
      "Epoch: 278/1000 Iteration: 2510 Validation loss: 0.070561 Validation acc: 0.963333\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.080626 Train acc: 0.960000\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.065606 Train acc: 0.973333\n",
      "Epoch: 279/1000 Iteration: 2520 Validation loss: 0.070161 Validation acc: 0.964444\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.065077 Train acc: 0.971667\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.057786 Train acc: 0.983333\n",
      "Epoch: 281/1000 Iteration: 2530 Validation loss: 0.070355 Validation acc: 0.964444\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.061268 Train acc: 0.976667\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.052530 Train acc: 0.976667\n",
      "Epoch: 282/1000 Iteration: 2540 Validation loss: 0.069996 Validation acc: 0.964444\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.060229 Train acc: 0.970000\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.080194 Train acc: 0.961667\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.069626 Validation acc: 0.963889\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.045380 Train acc: 0.981667\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.074804 Train acc: 0.970000\n",
      "Epoch: 284/1000 Iteration: 2560 Validation loss: 0.069349 Validation acc: 0.965000\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.060834 Train acc: 0.975000\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.065815 Train acc: 0.968333\n",
      "Epoch: 285/1000 Iteration: 2570 Validation loss: 0.069910 Validation acc: 0.965555\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.062388 Train acc: 0.975000\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.054171 Train acc: 0.976667\n",
      "Epoch: 286/1000 Iteration: 2580 Validation loss: 0.069103 Validation acc: 0.966111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.055184 Train acc: 0.973333\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.058432 Train acc: 0.971667\n",
      "Epoch: 287/1000 Iteration: 2590 Validation loss: 0.068989 Validation acc: 0.965555\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.070795 Train acc: 0.973333\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.044856 Train acc: 0.981667\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.068915 Validation acc: 0.966667\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.075596 Train acc: 0.966667\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.059589 Train acc: 0.978333\n",
      "Epoch: 289/1000 Iteration: 2610 Validation loss: 0.068680 Validation acc: 0.968333\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.063372 Train acc: 0.971667\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.060340 Train acc: 0.971667\n",
      "Epoch: 291/1000 Iteration: 2620 Validation loss: 0.068646 Validation acc: 0.966111\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.055943 Train acc: 0.980000\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.047897 Train acc: 0.976667\n",
      "Epoch: 292/1000 Iteration: 2630 Validation loss: 0.068418 Validation acc: 0.966111\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.053351 Train acc: 0.978333\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.082193 Train acc: 0.960000\n",
      "Epoch: 293/1000 Iteration: 2640 Validation loss: 0.067911 Validation acc: 0.965555\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.044390 Train acc: 0.976667\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.076972 Train acc: 0.961667\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.068165 Validation acc: 0.965555\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.059723 Train acc: 0.975000\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.064182 Train acc: 0.970000\n",
      "Epoch: 295/1000 Iteration: 2660 Validation loss: 0.068100 Validation acc: 0.966111\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.059080 Train acc: 0.975000\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.051066 Train acc: 0.980000\n",
      "Epoch: 296/1000 Iteration: 2670 Validation loss: 0.067818 Validation acc: 0.966111\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.052617 Train acc: 0.980000\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.054297 Train acc: 0.973333\n",
      "Epoch: 297/1000 Iteration: 2680 Validation loss: 0.067860 Validation acc: 0.971667\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.074456 Train acc: 0.963333\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.044510 Train acc: 0.983333\n",
      "Epoch: 298/1000 Iteration: 2690 Validation loss: 0.067371 Validation acc: 0.970555\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.072254 Train acc: 0.973333\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.055737 Train acc: 0.976667\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.067230 Validation acc: 0.972222\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.056762 Train acc: 0.975000\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.054035 Train acc: 0.985000\n",
      "Epoch: 301/1000 Iteration: 2710 Validation loss: 0.067039 Validation acc: 0.969444\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.050785 Train acc: 0.983333\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.053907 Train acc: 0.976667\n",
      "Epoch: 302/1000 Iteration: 2720 Validation loss: 0.066899 Validation acc: 0.966111\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.049701 Train acc: 0.981667\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.071962 Train acc: 0.966667\n",
      "Epoch: 303/1000 Iteration: 2730 Validation loss: 0.066224 Validation acc: 0.971111\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.039483 Train acc: 0.985000\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.075808 Train acc: 0.963333\n",
      "Epoch: 304/1000 Iteration: 2740 Validation loss: 0.066259 Validation acc: 0.971111\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.059747 Train acc: 0.971667\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.065593 Train acc: 0.971667\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.066728 Validation acc: 0.967222\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.056393 Train acc: 0.980000\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.044734 Train acc: 0.986667\n",
      "Epoch: 306/1000 Iteration: 2760 Validation loss: 0.065986 Validation acc: 0.970556\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.049058 Train acc: 0.978333\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.051953 Train acc: 0.973333\n",
      "Epoch: 307/1000 Iteration: 2770 Validation loss: 0.065806 Validation acc: 0.971667\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.071779 Train acc: 0.971667\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.040053 Train acc: 0.981667\n",
      "Epoch: 308/1000 Iteration: 2780 Validation loss: 0.065516 Validation acc: 0.972222\n",
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.073468 Train acc: 0.963333\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.061774 Train acc: 0.971667\n",
      "Epoch: 309/1000 Iteration: 2790 Validation loss: 0.065873 Validation acc: 0.970000\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.058765 Train acc: 0.971667\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.050859 Train acc: 0.981667\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.065664 Validation acc: 0.971111\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.048865 Train acc: 0.986667\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.048396 Train acc: 0.978333\n",
      "Epoch: 312/1000 Iteration: 2810 Validation loss: 0.065353 Validation acc: 0.972778\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.059241 Train acc: 0.963333\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.069357 Train acc: 0.968333\n",
      "Epoch: 313/1000 Iteration: 2820 Validation loss: 0.065345 Validation acc: 0.970555\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.040098 Train acc: 0.983333\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.068691 Train acc: 0.966667\n",
      "Epoch: 314/1000 Iteration: 2830 Validation loss: 0.065390 Validation acc: 0.970555\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.054957 Train acc: 0.980000\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.061193 Train acc: 0.968333\n",
      "Epoch: 315/1000 Iteration: 2840 Validation loss: 0.065231 Validation acc: 0.970000\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.051481 Train acc: 0.981667\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.048871 Train acc: 0.981667\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.064781 Validation acc: 0.971667\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.046785 Train acc: 0.980000\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.058353 Train acc: 0.970000\n",
      "Epoch: 317/1000 Iteration: 2860 Validation loss: 0.064622 Validation acc: 0.972222\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.066790 Train acc: 0.966667\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.037218 Train acc: 0.985000\n",
      "Epoch: 318/1000 Iteration: 2870 Validation loss: 0.064347 Validation acc: 0.972778\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.074900 Train acc: 0.968333\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.053784 Train acc: 0.975000\n",
      "Epoch: 319/1000 Iteration: 2880 Validation loss: 0.064516 Validation acc: 0.972778\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.057958 Train acc: 0.975000\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.050452 Train acc: 0.983333\n",
      "Epoch: 321/1000 Iteration: 2890 Validation loss: 0.064086 Validation acc: 0.973333\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.052323 Train acc: 0.980000\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.047638 Train acc: 0.981667\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.064070 Validation acc: 0.973889\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.050362 Train acc: 0.981667\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.067867 Train acc: 0.966667\n",
      "Epoch: 323/1000 Iteration: 2910 Validation loss: 0.064017 Validation acc: 0.973333\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.035084 Train acc: 0.990000\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.069061 Train acc: 0.966667\n",
      "Epoch: 324/1000 Iteration: 2920 Validation loss: 0.063996 Validation acc: 0.971111\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.052018 Train acc: 0.976667\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.055097 Train acc: 0.978333\n",
      "Epoch: 325/1000 Iteration: 2930 Validation loss: 0.063666 Validation acc: 0.973333\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.046705 Train acc: 0.988333\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.050422 Train acc: 0.978333\n",
      "Epoch: 326/1000 Iteration: 2940 Validation loss: 0.063470 Validation acc: 0.973889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.048675 Train acc: 0.980000\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.050768 Train acc: 0.970000\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.063861 Validation acc: 0.972778\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.065267 Train acc: 0.971667\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.035161 Train acc: 0.990000\n",
      "Epoch: 328/1000 Iteration: 2960 Validation loss: 0.063479 Validation acc: 0.975000\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.069954 Train acc: 0.965000\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.047284 Train acc: 0.978333\n",
      "Epoch: 329/1000 Iteration: 2970 Validation loss: 0.063623 Validation acc: 0.974444\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.056882 Train acc: 0.975000\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.049328 Train acc: 0.980000\n",
      "Epoch: 331/1000 Iteration: 2980 Validation loss: 0.063426 Validation acc: 0.975000\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.044887 Train acc: 0.985000\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.048593 Train acc: 0.980000\n",
      "Epoch: 332/1000 Iteration: 2990 Validation loss: 0.063644 Validation acc: 0.975000\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.051661 Train acc: 0.981667\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.068002 Train acc: 0.973333\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.063515 Validation acc: 0.972778\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.033603 Train acc: 0.985000\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.064648 Train acc: 0.971667\n",
      "Epoch: 334/1000 Iteration: 3010 Validation loss: 0.063208 Validation acc: 0.974444\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.048316 Train acc: 0.981667\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.050909 Train acc: 0.980000\n",
      "Epoch: 335/1000 Iteration: 3020 Validation loss: 0.063062 Validation acc: 0.973889\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.047130 Train acc: 0.985000\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.047135 Train acc: 0.983333\n",
      "Epoch: 336/1000 Iteration: 3030 Validation loss: 0.062940 Validation acc: 0.974444\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.043672 Train acc: 0.978333\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.050795 Train acc: 0.973333\n",
      "Epoch: 337/1000 Iteration: 3040 Validation loss: 0.062948 Validation acc: 0.974444\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.063451 Train acc: 0.975000\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.039149 Train acc: 0.988333\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.062564 Validation acc: 0.976111\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.069074 Train acc: 0.968333\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.050199 Train acc: 0.973333\n",
      "Epoch: 339/1000 Iteration: 3060 Validation loss: 0.062772 Validation acc: 0.975000\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.054404 Train acc: 0.975000\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.050244 Train acc: 0.980000\n",
      "Epoch: 341/1000 Iteration: 3070 Validation loss: 0.062616 Validation acc: 0.975556\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.046540 Train acc: 0.986667\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.043702 Train acc: 0.980000\n",
      "Epoch: 342/1000 Iteration: 3080 Validation loss: 0.062262 Validation acc: 0.975000\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.046301 Train acc: 0.980000\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.062717 Train acc: 0.975000\n",
      "Epoch: 343/1000 Iteration: 3090 Validation loss: 0.062388 Validation acc: 0.975000\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.031956 Train acc: 0.990000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.063647 Train acc: 0.968333\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.062854 Validation acc: 0.976111\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.048063 Train acc: 0.978333\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.052232 Train acc: 0.980000\n",
      "Epoch: 345/1000 Iteration: 3110 Validation loss: 0.062056 Validation acc: 0.975000\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.048360 Train acc: 0.980000\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.042225 Train acc: 0.986667\n",
      "Epoch: 346/1000 Iteration: 3120 Validation loss: 0.062535 Validation acc: 0.976111\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.042810 Train acc: 0.983333\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.045229 Train acc: 0.981667\n",
      "Epoch: 347/1000 Iteration: 3130 Validation loss: 0.062237 Validation acc: 0.974444\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.064406 Train acc: 0.968333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.030459 Train acc: 0.993333\n",
      "Epoch: 348/1000 Iteration: 3140 Validation loss: 0.061759 Validation acc: 0.975000\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.068863 Train acc: 0.961667\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.047076 Train acc: 0.980000\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.061626 Validation acc: 0.975000\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.046246 Train acc: 0.981667\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.044212 Train acc: 0.985000\n",
      "Epoch: 351/1000 Iteration: 3160 Validation loss: 0.061488 Validation acc: 0.976667\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.040588 Train acc: 0.983333\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.040594 Train acc: 0.981667\n",
      "Epoch: 352/1000 Iteration: 3170 Validation loss: 0.062013 Validation acc: 0.975556\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.045910 Train acc: 0.981667\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.062291 Train acc: 0.971667\n",
      "Epoch: 353/1000 Iteration: 3180 Validation loss: 0.062204 Validation acc: 0.976111\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.030047 Train acc: 0.990000\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.061029 Train acc: 0.976667\n",
      "Epoch: 354/1000 Iteration: 3190 Validation loss: 0.061811 Validation acc: 0.978333\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.047112 Train acc: 0.980000\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.052201 Train acc: 0.973333\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.060978 Validation acc: 0.976111\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.049405 Train acc: 0.980000\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.043445 Train acc: 0.985000\n",
      "Epoch: 356/1000 Iteration: 3210 Validation loss: 0.060922 Validation acc: 0.976111\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.042118 Train acc: 0.981667\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.045463 Train acc: 0.986667\n",
      "Epoch: 357/1000 Iteration: 3220 Validation loss: 0.060724 Validation acc: 0.977222\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.065062 Train acc: 0.965000\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.032491 Train acc: 0.990000\n",
      "Epoch: 358/1000 Iteration: 3230 Validation loss: 0.060832 Validation acc: 0.976667\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.066404 Train acc: 0.965000\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.045659 Train acc: 0.978333\n",
      "Epoch: 359/1000 Iteration: 3240 Validation loss: 0.060984 Validation acc: 0.977222\n",
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.051485 Train acc: 0.978333\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.044700 Train acc: 0.986667\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.060854 Validation acc: 0.976667\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.040928 Train acc: 0.988333\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.043107 Train acc: 0.981667\n",
      "Epoch: 362/1000 Iteration: 3260 Validation loss: 0.060713 Validation acc: 0.977778\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.048965 Train acc: 0.975000\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.063809 Train acc: 0.971667\n",
      "Epoch: 363/1000 Iteration: 3270 Validation loss: 0.060756 Validation acc: 0.977778\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.032850 Train acc: 0.988333\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.062243 Train acc: 0.973333\n",
      "Epoch: 364/1000 Iteration: 3280 Validation loss: 0.060544 Validation acc: 0.978333\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.045524 Train acc: 0.978333\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.051536 Train acc: 0.975000\n",
      "Epoch: 365/1000 Iteration: 3290 Validation loss: 0.060217 Validation acc: 0.978333\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.046558 Train acc: 0.978333\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.041488 Train acc: 0.986667\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.060527 Validation acc: 0.978333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.041576 Train acc: 0.981667\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.044938 Train acc: 0.983333\n",
      "Epoch: 367/1000 Iteration: 3310 Validation loss: 0.060012 Validation acc: 0.978333\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.059092 Train acc: 0.968333\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.029570 Train acc: 0.990000\n",
      "Epoch: 368/1000 Iteration: 3320 Validation loss: 0.060152 Validation acc: 0.977778\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.062818 Train acc: 0.966667\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.044722 Train acc: 0.980000\n",
      "Epoch: 369/1000 Iteration: 3330 Validation loss: 0.060535 Validation acc: 0.977222\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.049898 Train acc: 0.976667\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.043789 Train acc: 0.985000\n",
      "Epoch: 371/1000 Iteration: 3340 Validation loss: 0.059660 Validation acc: 0.977778\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.038969 Train acc: 0.986667\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.038583 Train acc: 0.983333\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.059726 Validation acc: 0.977778\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.042163 Train acc: 0.986667\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.057352 Train acc: 0.978333\n",
      "Epoch: 373/1000 Iteration: 3360 Validation loss: 0.060108 Validation acc: 0.978333\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.031513 Train acc: 0.990000\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.057884 Train acc: 0.976667\n",
      "Epoch: 374/1000 Iteration: 3370 Validation loss: 0.060047 Validation acc: 0.978333\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.039301 Train acc: 0.980000\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.054060 Train acc: 0.971667\n",
      "Epoch: 375/1000 Iteration: 3380 Validation loss: 0.059886 Validation acc: 0.977778\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.042119 Train acc: 0.986667\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.043955 Train acc: 0.980000\n",
      "Epoch: 376/1000 Iteration: 3390 Validation loss: 0.059396 Validation acc: 0.979445\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.039071 Train acc: 0.983333\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.042970 Train acc: 0.980000\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.059366 Validation acc: 0.977222\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.057151 Train acc: 0.971667\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.030882 Train acc: 0.991667\n",
      "Epoch: 378/1000 Iteration: 3410 Validation loss: 0.059606 Validation acc: 0.978333\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.063913 Train acc: 0.966667\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.043324 Train acc: 0.976667\n",
      "Epoch: 379/1000 Iteration: 3420 Validation loss: 0.059847 Validation acc: 0.977222\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.050372 Train acc: 0.985000\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.042474 Train acc: 0.985000\n",
      "Epoch: 381/1000 Iteration: 3430 Validation loss: 0.059930 Validation acc: 0.975556\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.040460 Train acc: 0.985000\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.040350 Train acc: 0.983333\n",
      "Epoch: 382/1000 Iteration: 3440 Validation loss: 0.059596 Validation acc: 0.978333\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.038593 Train acc: 0.985000\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.058270 Train acc: 0.966667\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.059788 Validation acc: 0.977778\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.029819 Train acc: 0.993333\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.059834 Train acc: 0.970000\n",
      "Epoch: 384/1000 Iteration: 3460 Validation loss: 0.059768 Validation acc: 0.977222\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.046717 Train acc: 0.980000\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.043039 Train acc: 0.983333\n",
      "Epoch: 385/1000 Iteration: 3470 Validation loss: 0.059271 Validation acc: 0.978333\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.041942 Train acc: 0.991667\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.040541 Train acc: 0.986667\n",
      "Epoch: 386/1000 Iteration: 3480 Validation loss: 0.059648 Validation acc: 0.977222\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.034029 Train acc: 0.983333\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.041260 Train acc: 0.985000\n",
      "Epoch: 387/1000 Iteration: 3490 Validation loss: 0.059597 Validation acc: 0.977222\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.056901 Train acc: 0.980000\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.027130 Train acc: 0.995000\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.059076 Validation acc: 0.978333\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.057275 Train acc: 0.970000\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.040506 Train acc: 0.983333\n",
      "Epoch: 389/1000 Iteration: 3510 Validation loss: 0.058998 Validation acc: 0.978333\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.045218 Train acc: 0.985000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.038170 Train acc: 0.986667\n",
      "Epoch: 391/1000 Iteration: 3520 Validation loss: 0.059418 Validation acc: 0.977222\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.040722 Train acc: 0.985000\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.037930 Train acc: 0.981667\n",
      "Epoch: 392/1000 Iteration: 3530 Validation loss: 0.059501 Validation acc: 0.977222\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.047979 Train acc: 0.981667\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.055988 Train acc: 0.978333\n",
      "Epoch: 393/1000 Iteration: 3540 Validation loss: 0.059531 Validation acc: 0.978333\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.032193 Train acc: 0.995000\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.058827 Train acc: 0.975000\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.059415 Validation acc: 0.976111\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.037102 Train acc: 0.981667\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.043697 Train acc: 0.983333\n",
      "Epoch: 395/1000 Iteration: 3560 Validation loss: 0.058418 Validation acc: 0.978333\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.039448 Train acc: 0.990000\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.037448 Train acc: 0.983333\n",
      "Epoch: 396/1000 Iteration: 3570 Validation loss: 0.058449 Validation acc: 0.977778\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.031347 Train acc: 0.988333\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.041071 Train acc: 0.985000\n",
      "Epoch: 397/1000 Iteration: 3580 Validation loss: 0.058446 Validation acc: 0.977778\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.053712 Train acc: 0.975000\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.028892 Train acc: 0.990000\n",
      "Epoch: 398/1000 Iteration: 3590 Validation loss: 0.058543 Validation acc: 0.977778\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.061182 Train acc: 0.970000\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.038326 Train acc: 0.988333\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.058471 Validation acc: 0.977778\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.045979 Train acc: 0.980000\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.037004 Train acc: 0.988333\n",
      "Epoch: 401/1000 Iteration: 3610 Validation loss: 0.058801 Validation acc: 0.978333\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.035260 Train acc: 0.991667\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.039361 Train acc: 0.983333\n",
      "Epoch: 402/1000 Iteration: 3620 Validation loss: 0.058697 Validation acc: 0.977778\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.042334 Train acc: 0.980000\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.055345 Train acc: 0.973333\n",
      "Epoch: 403/1000 Iteration: 3630 Validation loss: 0.058455 Validation acc: 0.977778\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.029983 Train acc: 0.991667\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.056046 Train acc: 0.975000\n",
      "Epoch: 404/1000 Iteration: 3640 Validation loss: 0.058167 Validation acc: 0.978333\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.039270 Train acc: 0.978333\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.047621 Train acc: 0.978333\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.058291 Validation acc: 0.977778\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.037177 Train acc: 0.985000\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.037186 Train acc: 0.988333\n",
      "Epoch: 406/1000 Iteration: 3660 Validation loss: 0.058165 Validation acc: 0.977778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.033798 Train acc: 0.983333\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.039464 Train acc: 0.981667\n",
      "Epoch: 407/1000 Iteration: 3670 Validation loss: 0.058375 Validation acc: 0.978333\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.057331 Train acc: 0.971667\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.026931 Train acc: 0.993333\n",
      "Epoch: 408/1000 Iteration: 3680 Validation loss: 0.058372 Validation acc: 0.977778\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.055150 Train acc: 0.976667\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.039903 Train acc: 0.981667\n",
      "Epoch: 409/1000 Iteration: 3690 Validation loss: 0.058711 Validation acc: 0.977778\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.039493 Train acc: 0.988333\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.037637 Train acc: 0.986667\n",
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.058831 Validation acc: 0.977778\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.037123 Train acc: 0.990000\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.033087 Train acc: 0.986667\n",
      "Epoch: 412/1000 Iteration: 3710 Validation loss: 0.058551 Validation acc: 0.978333\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.037692 Train acc: 0.983333\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.053207 Train acc: 0.973333\n",
      "Epoch: 413/1000 Iteration: 3720 Validation loss: 0.058452 Validation acc: 0.978333\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.024895 Train acc: 0.993333\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.055124 Train acc: 0.971667\n",
      "Epoch: 414/1000 Iteration: 3730 Validation loss: 0.058335 Validation acc: 0.978333\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.038225 Train acc: 0.980000\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.045780 Train acc: 0.975000\n",
      "Epoch: 415/1000 Iteration: 3740 Validation loss: 0.058905 Validation acc: 0.977778\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.036781 Train acc: 0.993333\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.037026 Train acc: 0.990000\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.058880 Validation acc: 0.978889\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.034769 Train acc: 0.983333\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.038529 Train acc: 0.981667\n",
      "Epoch: 417/1000 Iteration: 3760 Validation loss: 0.058962 Validation acc: 0.977222\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.049668 Train acc: 0.975000\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.023244 Train acc: 0.995000\n",
      "Epoch: 418/1000 Iteration: 3770 Validation loss: 0.058700 Validation acc: 0.977222\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.054727 Train acc: 0.978333\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.036720 Train acc: 0.985000\n",
      "Epoch: 419/1000 Iteration: 3780 Validation loss: 0.058480 Validation acc: 0.978889\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.044175 Train acc: 0.981667\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.039599 Train acc: 0.981667\n",
      "Epoch: 421/1000 Iteration: 3790 Validation loss: 0.057971 Validation acc: 0.978889\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.035511 Train acc: 0.990000\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.032085 Train acc: 0.983333\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.058001 Validation acc: 0.978889\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.035113 Train acc: 0.985000\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.055277 Train acc: 0.976667\n",
      "Epoch: 423/1000 Iteration: 3810 Validation loss: 0.059341 Validation acc: 0.977222\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.027174 Train acc: 0.988333\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.050642 Train acc: 0.983333\n",
      "Epoch: 424/1000 Iteration: 3820 Validation loss: 0.058358 Validation acc: 0.978889\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.038714 Train acc: 0.981667\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.043181 Train acc: 0.978333\n",
      "Epoch: 425/1000 Iteration: 3830 Validation loss: 0.057032 Validation acc: 0.978889\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.037140 Train acc: 0.985000\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.034200 Train acc: 0.990000\n",
      "Epoch: 426/1000 Iteration: 3840 Validation loss: 0.056584 Validation acc: 0.978889\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.032236 Train acc: 0.985000\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.038103 Train acc: 0.983333\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.056918 Validation acc: 0.979445\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.052081 Train acc: 0.978333\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.026100 Train acc: 0.993333\n",
      "Epoch: 428/1000 Iteration: 3860 Validation loss: 0.057361 Validation acc: 0.980000\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.056519 Train acc: 0.973333\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.037757 Train acc: 0.978333\n",
      "Epoch: 429/1000 Iteration: 3870 Validation loss: 0.057016 Validation acc: 0.980556\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.040838 Train acc: 0.978333\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.036846 Train acc: 0.988333\n",
      "Epoch: 431/1000 Iteration: 3880 Validation loss: 0.057381 Validation acc: 0.978889\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.034579 Train acc: 0.991667\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.030019 Train acc: 0.986667\n",
      "Epoch: 432/1000 Iteration: 3890 Validation loss: 0.057887 Validation acc: 0.977222\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.041091 Train acc: 0.976667\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.047186 Train acc: 0.980000\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.058504 Validation acc: 0.977778\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.027633 Train acc: 0.991667\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.052776 Train acc: 0.976667\n",
      "Epoch: 434/1000 Iteration: 3910 Validation loss: 0.057502 Validation acc: 0.980556\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.036098 Train acc: 0.985000\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.042504 Train acc: 0.981667\n",
      "Epoch: 435/1000 Iteration: 3920 Validation loss: 0.056786 Validation acc: 0.980000\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.036360 Train acc: 0.986667\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.035094 Train acc: 0.993333\n",
      "Epoch: 436/1000 Iteration: 3930 Validation loss: 0.056570 Validation acc: 0.981111\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.029099 Train acc: 0.988333\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.037765 Train acc: 0.985000\n",
      "Epoch: 437/1000 Iteration: 3940 Validation loss: 0.056850 Validation acc: 0.978889\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.056429 Train acc: 0.966667\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.024883 Train acc: 0.990000\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.057304 Validation acc: 0.978889\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.049677 Train acc: 0.980000\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.035830 Train acc: 0.985000\n",
      "Epoch: 439/1000 Iteration: 3960 Validation loss: 0.057618 Validation acc: 0.978889\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.040988 Train acc: 0.983333\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.034105 Train acc: 0.985000\n",
      "Epoch: 441/1000 Iteration: 3970 Validation loss: 0.057521 Validation acc: 0.979445\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.036918 Train acc: 0.990000\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.025593 Train acc: 0.988333\n",
      "Epoch: 442/1000 Iteration: 3980 Validation loss: 0.057573 Validation acc: 0.979445\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.033863 Train acc: 0.983333\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.047060 Train acc: 0.975000\n",
      "Epoch: 443/1000 Iteration: 3990 Validation loss: 0.057718 Validation acc: 0.979445\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.025467 Train acc: 0.993333\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.056854 Train acc: 0.973333\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.058008 Validation acc: 0.979445\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.035096 Train acc: 0.981667\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.042660 Train acc: 0.975000\n",
      "Epoch: 445/1000 Iteration: 4010 Validation loss: 0.057349 Validation acc: 0.979445\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.038234 Train acc: 0.986667\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.035832 Train acc: 0.990000\n",
      "Epoch: 446/1000 Iteration: 4020 Validation loss: 0.057795 Validation acc: 0.978889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.031606 Train acc: 0.988333\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.039378 Train acc: 0.983333\n",
      "Epoch: 447/1000 Iteration: 4030 Validation loss: 0.057490 Validation acc: 0.978889\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.049821 Train acc: 0.975000\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.022760 Train acc: 0.991667\n",
      "Epoch: 448/1000 Iteration: 4040 Validation loss: 0.057081 Validation acc: 0.980556\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.052467 Train acc: 0.975000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.032659 Train acc: 0.988333\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.056926 Validation acc: 0.980000\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.041220 Train acc: 0.981667\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.037897 Train acc: 0.985000\n",
      "Epoch: 451/1000 Iteration: 4060 Validation loss: 0.056965 Validation acc: 0.979445\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.033102 Train acc: 0.990000\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.028009 Train acc: 0.980000\n",
      "Epoch: 452/1000 Iteration: 4070 Validation loss: 0.057463 Validation acc: 0.981111\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.037224 Train acc: 0.980000\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.048752 Train acc: 0.981667\n",
      "Epoch: 453/1000 Iteration: 4080 Validation loss: 0.058125 Validation acc: 0.980000\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.023853 Train acc: 0.993333\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.049798 Train acc: 0.976667\n",
      "Epoch: 454/1000 Iteration: 4090 Validation loss: 0.057549 Validation acc: 0.980556\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.035105 Train acc: 0.983333\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.040051 Train acc: 0.983333\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.056176 Validation acc: 0.981667\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.035217 Train acc: 0.988333\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.032355 Train acc: 0.995000\n",
      "Epoch: 456/1000 Iteration: 4110 Validation loss: 0.056457 Validation acc: 0.981111\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.029523 Train acc: 0.988333\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.034647 Train acc: 0.990000\n",
      "Epoch: 457/1000 Iteration: 4120 Validation loss: 0.057408 Validation acc: 0.980556\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.046793 Train acc: 0.976667\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.021559 Train acc: 0.993333\n",
      "Epoch: 458/1000 Iteration: 4130 Validation loss: 0.057561 Validation acc: 0.978889\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.049180 Train acc: 0.980000\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.032016 Train acc: 0.986667\n",
      "Epoch: 459/1000 Iteration: 4140 Validation loss: 0.056860 Validation acc: 0.979444\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.036713 Train acc: 0.986667\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.036797 Train acc: 0.981667\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.057094 Validation acc: 0.980000\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.034109 Train acc: 0.993333\n",
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.033975 Train acc: 0.985000\n",
      "Epoch: 462/1000 Iteration: 4160 Validation loss: 0.057681 Validation acc: 0.980556\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.029438 Train acc: 0.991667\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.045919 Train acc: 0.980000\n",
      "Epoch: 463/1000 Iteration: 4170 Validation loss: 0.057232 Validation acc: 0.978889\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.025029 Train acc: 0.991667\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.050426 Train acc: 0.981667\n",
      "Epoch: 464/1000 Iteration: 4180 Validation loss: 0.057990 Validation acc: 0.980000\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.031883 Train acc: 0.988333\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.040215 Train acc: 0.980000\n",
      "Epoch: 465/1000 Iteration: 4190 Validation loss: 0.059244 Validation acc: 0.978333\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.032966 Train acc: 0.991667\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.034410 Train acc: 0.988333\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.057526 Validation acc: 0.980000\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.030265 Train acc: 0.988333\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.030011 Train acc: 0.993333\n",
      "Epoch: 467/1000 Iteration: 4210 Validation loss: 0.056602 Validation acc: 0.978889\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.044049 Train acc: 0.978333\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.027196 Train acc: 0.991667\n",
      "Epoch: 468/1000 Iteration: 4220 Validation loss: 0.056886 Validation acc: 0.979445\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.050085 Train acc: 0.981667\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.029750 Train acc: 0.985000\n",
      "Epoch: 469/1000 Iteration: 4230 Validation loss: 0.056593 Validation acc: 0.980000\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.034703 Train acc: 0.985000\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.031193 Train acc: 0.985000\n",
      "Epoch: 471/1000 Iteration: 4240 Validation loss: 0.056353 Validation acc: 0.980000\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.034642 Train acc: 0.990000\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.025448 Train acc: 0.991667\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.058317 Validation acc: 0.979444\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.034052 Train acc: 0.986667\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.046114 Train acc: 0.976667\n",
      "Epoch: 473/1000 Iteration: 4260 Validation loss: 0.060271 Validation acc: 0.980556\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.018384 Train acc: 0.995000\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.044727 Train acc: 0.980000\n",
      "Epoch: 474/1000 Iteration: 4270 Validation loss: 0.059927 Validation acc: 0.980000\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.030233 Train acc: 0.986667\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.037481 Train acc: 0.983333\n",
      "Epoch: 475/1000 Iteration: 4280 Validation loss: 0.057935 Validation acc: 0.981111\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.032967 Train acc: 0.988333\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.035137 Train acc: 0.986667\n",
      "Epoch: 476/1000 Iteration: 4290 Validation loss: 0.054815 Validation acc: 0.981667\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.028321 Train acc: 0.986667\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.030182 Train acc: 0.988333\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.053972 Validation acc: 0.981667\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.045275 Train acc: 0.981667\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.023292 Train acc: 0.995000\n",
      "Epoch: 478/1000 Iteration: 4310 Validation loss: 0.053804 Validation acc: 0.981667\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.046521 Train acc: 0.978333\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.028031 Train acc: 0.990000\n",
      "Epoch: 479/1000 Iteration: 4320 Validation loss: 0.054149 Validation acc: 0.982778\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.037620 Train acc: 0.981667\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.035142 Train acc: 0.985000\n",
      "Epoch: 481/1000 Iteration: 4330 Validation loss: 0.054938 Validation acc: 0.978889\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.031875 Train acc: 0.990000\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.026891 Train acc: 0.991667\n",
      "Epoch: 482/1000 Iteration: 4340 Validation loss: 0.055393 Validation acc: 0.981111\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.029995 Train acc: 0.993333\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.043345 Train acc: 0.981667\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.055990 Validation acc: 0.981111\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.023432 Train acc: 0.993333\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.044098 Train acc: 0.981667\n",
      "Epoch: 484/1000 Iteration: 4360 Validation loss: 0.055335 Validation acc: 0.981667\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.032253 Train acc: 0.988333\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.034714 Train acc: 0.986667\n",
      "Epoch: 485/1000 Iteration: 4370 Validation loss: 0.055453 Validation acc: 0.980556\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.031671 Train acc: 0.986667\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.032400 Train acc: 0.988333\n",
      "Epoch: 486/1000 Iteration: 4380 Validation loss: 0.055733 Validation acc: 0.981111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.027761 Train acc: 0.990000\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.029468 Train acc: 0.985000\n",
      "Epoch: 487/1000 Iteration: 4390 Validation loss: 0.055158 Validation acc: 0.981667\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.043690 Train acc: 0.976667\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.020130 Train acc: 0.993333\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.054787 Validation acc: 0.981667\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.044229 Train acc: 0.983333\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.030340 Train acc: 0.988333\n",
      "Epoch: 489/1000 Iteration: 4410 Validation loss: 0.055774 Validation acc: 0.981111\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.032311 Train acc: 0.986667\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.031589 Train acc: 0.985000\n",
      "Epoch: 491/1000 Iteration: 4420 Validation loss: 0.056235 Validation acc: 0.979445\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.031997 Train acc: 0.988333\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.022541 Train acc: 0.991667\n",
      "Epoch: 492/1000 Iteration: 4430 Validation loss: 0.055577 Validation acc: 0.980556\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.029148 Train acc: 0.986667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.040947 Train acc: 0.978333\n",
      "Epoch: 493/1000 Iteration: 4440 Validation loss: 0.056219 Validation acc: 0.981667\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.020476 Train acc: 0.993333\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.044413 Train acc: 0.983333\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.057116 Validation acc: 0.982778\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.030760 Train acc: 0.986667\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.034751 Train acc: 0.981667\n",
      "Epoch: 495/1000 Iteration: 4460 Validation loss: 0.056510 Validation acc: 0.981667\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.030255 Train acc: 0.991667\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.032648 Train acc: 0.990000\n",
      "Epoch: 496/1000 Iteration: 4470 Validation loss: 0.054933 Validation acc: 0.981111\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.028301 Train acc: 0.988333\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.029126 Train acc: 0.995000\n",
      "Epoch: 497/1000 Iteration: 4480 Validation loss: 0.054064 Validation acc: 0.981667\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.044758 Train acc: 0.980000\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.019414 Train acc: 0.993333\n",
      "Epoch: 498/1000 Iteration: 4490 Validation loss: 0.054665 Validation acc: 0.981111\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.042645 Train acc: 0.983333\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.029934 Train acc: 0.993333\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.055195 Validation acc: 0.981111\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.034396 Train acc: 0.988333\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.032014 Train acc: 0.986667\n",
      "Epoch: 501/1000 Iteration: 4510 Validation loss: 0.055470 Validation acc: 0.980556\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.029115 Train acc: 0.993333\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.026543 Train acc: 0.990000\n",
      "Epoch: 502/1000 Iteration: 4520 Validation loss: 0.056343 Validation acc: 0.981111\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.027349 Train acc: 0.993333\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.043627 Train acc: 0.978333\n",
      "Epoch: 503/1000 Iteration: 4530 Validation loss: 0.053477 Validation acc: 0.982222\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.018515 Train acc: 0.993333\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.044121 Train acc: 0.985000\n",
      "Epoch: 504/1000 Iteration: 4540 Validation loss: 0.056760 Validation acc: 0.981667\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.030013 Train acc: 0.988333\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.035626 Train acc: 0.981667\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.057918 Validation acc: 0.981111\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.028510 Train acc: 0.990000\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.030866 Train acc: 0.990000\n",
      "Epoch: 506/1000 Iteration: 4560 Validation loss: 0.057178 Validation acc: 0.981111\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.031832 Train acc: 0.985000\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.029184 Train acc: 0.990000\n",
      "Epoch: 507/1000 Iteration: 4570 Validation loss: 0.056641 Validation acc: 0.980556\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.042977 Train acc: 0.981667\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.020004 Train acc: 0.993333\n",
      "Epoch: 508/1000 Iteration: 4580 Validation loss: 0.056215 Validation acc: 0.981667\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.044606 Train acc: 0.985000\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.029430 Train acc: 0.986667\n",
      "Epoch: 509/1000 Iteration: 4590 Validation loss: 0.056120 Validation acc: 0.980556\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.035292 Train acc: 0.983333\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.028497 Train acc: 0.991667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.056100 Validation acc: 0.978889\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.033096 Train acc: 0.991667\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.023896 Train acc: 0.990000\n",
      "Epoch: 512/1000 Iteration: 4610 Validation loss: 0.055623 Validation acc: 0.980556\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.028281 Train acc: 0.985000\n",
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.043405 Train acc: 0.980000\n",
      "Epoch: 513/1000 Iteration: 4620 Validation loss: 0.055985 Validation acc: 0.981667\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.021633 Train acc: 0.991667\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.043527 Train acc: 0.983333\n",
      "Epoch: 514/1000 Iteration: 4630 Validation loss: 0.056367 Validation acc: 0.980000\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.029892 Train acc: 0.990000\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.033652 Train acc: 0.985000\n",
      "Epoch: 515/1000 Iteration: 4640 Validation loss: 0.055471 Validation acc: 0.982222\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.031461 Train acc: 0.988333\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.030399 Train acc: 0.991667\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.054599 Validation acc: 0.982778\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.027217 Train acc: 0.990000\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.028029 Train acc: 0.991667\n",
      "Epoch: 517/1000 Iteration: 4660 Validation loss: 0.054364 Validation acc: 0.982222\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.039581 Train acc: 0.980000\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.019534 Train acc: 0.993333\n",
      "Epoch: 518/1000 Iteration: 4670 Validation loss: 0.053748 Validation acc: 0.982778\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.038945 Train acc: 0.988333\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.026605 Train acc: 0.991667\n",
      "Epoch: 519/1000 Iteration: 4680 Validation loss: 0.053375 Validation acc: 0.982222\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.030230 Train acc: 0.985000\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.029954 Train acc: 0.991667\n",
      "Epoch: 521/1000 Iteration: 4690 Validation loss: 0.053062 Validation acc: 0.982778\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.029447 Train acc: 0.993333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.025478 Train acc: 0.988333\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.053587 Validation acc: 0.982778\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.027664 Train acc: 0.996667\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.038764 Train acc: 0.981667\n",
      "Epoch: 523/1000 Iteration: 4710 Validation loss: 0.054577 Validation acc: 0.981667\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.018660 Train acc: 0.995000\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.037403 Train acc: 0.990000\n",
      "Epoch: 524/1000 Iteration: 4720 Validation loss: 0.054839 Validation acc: 0.982778\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.024969 Train acc: 0.990000\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.032521 Train acc: 0.988333\n",
      "Epoch: 525/1000 Iteration: 4730 Validation loss: 0.054524 Validation acc: 0.982778\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.029080 Train acc: 0.991667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.025345 Train acc: 0.998333\n",
      "Epoch: 526/1000 Iteration: 4740 Validation loss: 0.054050 Validation acc: 0.983333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.024428 Train acc: 0.986667\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.028160 Train acc: 0.988333\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.054823 Validation acc: 0.982222\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.037067 Train acc: 0.983333\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.021953 Train acc: 0.991667\n",
      "Epoch: 528/1000 Iteration: 4760 Validation loss: 0.055261 Validation acc: 0.982222\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.037177 Train acc: 0.988333\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.028290 Train acc: 0.985000\n",
      "Epoch: 529/1000 Iteration: 4770 Validation loss: 0.052943 Validation acc: 0.982222\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.034444 Train acc: 0.981667\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.029954 Train acc: 0.986667\n",
      "Epoch: 531/1000 Iteration: 4780 Validation loss: 0.052809 Validation acc: 0.982222\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.030560 Train acc: 0.990000\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.023685 Train acc: 0.990000\n",
      "Epoch: 532/1000 Iteration: 4790 Validation loss: 0.053529 Validation acc: 0.982222\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.023775 Train acc: 0.993333\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.035125 Train acc: 0.986667\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.054124 Validation acc: 0.981667\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.018626 Train acc: 0.996667\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.037719 Train acc: 0.986667\n",
      "Epoch: 534/1000 Iteration: 4810 Validation loss: 0.053964 Validation acc: 0.982222\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.022558 Train acc: 0.993333\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.030681 Train acc: 0.986667\n",
      "Epoch: 535/1000 Iteration: 4820 Validation loss: 0.054309 Validation acc: 0.982222\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.026470 Train acc: 0.991667\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.030168 Train acc: 0.988333\n",
      "Epoch: 536/1000 Iteration: 4830 Validation loss: 0.054095 Validation acc: 0.981667\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.026257 Train acc: 0.988333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.021510 Train acc: 0.995000\n",
      "Epoch: 537/1000 Iteration: 4840 Validation loss: 0.053296 Validation acc: 0.983333\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.036345 Train acc: 0.988333\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.018946 Train acc: 0.993333\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.054427 Validation acc: 0.981667\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.042814 Train acc: 0.986667\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.024770 Train acc: 0.991667\n",
      "Epoch: 539/1000 Iteration: 4860 Validation loss: 0.055240 Validation acc: 0.981667\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.029074 Train acc: 0.988333\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.024091 Train acc: 0.995000\n",
      "Epoch: 541/1000 Iteration: 4870 Validation loss: 0.054164 Validation acc: 0.983333\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.028521 Train acc: 0.991667\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.023481 Train acc: 0.990000\n",
      "Epoch: 542/1000 Iteration: 4880 Validation loss: 0.055217 Validation acc: 0.981667\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.025819 Train acc: 0.993333\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.036196 Train acc: 0.981667\n",
      "Epoch: 543/1000 Iteration: 4890 Validation loss: 0.058120 Validation acc: 0.980000\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.021389 Train acc: 0.991667\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.040957 Train acc: 0.985000\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.056215 Validation acc: 0.981667\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc2d64f0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpKhpCAiIhn/DwAGYABzepTRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbde98f828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.930417\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
