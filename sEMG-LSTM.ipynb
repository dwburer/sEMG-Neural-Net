{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sEMG LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.semg_utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"C:\\\\Users\\\\paperspace\\\\sEMG-Neural-Net\\\\sEMG\\\\Database 2\\\\male_day_1\\\\\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"C:\\\\Users\\\\paperspace\\\\sEMG-Neural-Net\\\\sEMG\\\\Database 2\\\\male_day_2\\\\\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 6         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 20       # Batch size\n",
    "seq_len = 2500          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 2\n",
    "n_channels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable logits/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-122075a43949>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# We only need the last output tensor to pass into a classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'logits'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Cost function and optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 215\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m                                     \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                                     trainable=True)\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m       self.bias = self.add_variable('bias',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable)\u001b[0m\n\u001b[0;32m    372\u001b[0m                                    \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                                    trainable=trainable and self.trainable)\n\u001b[0m\u001b[0;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexisting_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m           use_resource=use_resource)\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[0;32m    662\u001b[0m                          \u001b[1;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 664\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable logits/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 0.716147 Train acc: 0.550000\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 0.733120 Train acc: 0.450000\n",
      "Epoch: 2/1000 Iteration: 15 Train loss: 0.679358 Train acc: 0.450000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 0.792559 Train acc: 0.250000\n",
      "Epoch: 3/1000 Iteration: 25 Train loss: 0.732091 Train acc: 0.550000\n",
      "Epoch: 3/1000 Iteration: 25 Validation loss: 0.718019 Validation acc: 0.425000\n",
      "Epoch: 4/1000 Iteration: 30 Train loss: 0.694964 Train acc: 0.600000\n",
      "Epoch: 4/1000 Iteration: 35 Train loss: 0.707198 Train acc: 0.400000\n",
      "Epoch: 5/1000 Iteration: 40 Train loss: 0.749710 Train acc: 0.500000\n",
      "Epoch: 6/1000 Iteration: 45 Train loss: 0.689637 Train acc: 0.600000\n",
      "Epoch: 7/1000 Iteration: 50 Train loss: 0.693615 Train acc: 0.500000\n",
      "Epoch: 7/1000 Iteration: 50 Validation loss: 0.716840 Validation acc: 0.400000\n",
      "Epoch: 7/1000 Iteration: 55 Train loss: 0.753729 Train acc: 0.400000\n",
      "Epoch: 8/1000 Iteration: 60 Train loss: 0.739387 Train acc: 0.450000\n",
      "Epoch: 9/1000 Iteration: 65 Train loss: 0.702573 Train acc: 0.450000\n",
      "Epoch: 9/1000 Iteration: 70 Train loss: 0.680866 Train acc: 0.450000\n",
      "Epoch: 10/1000 Iteration: 75 Train loss: 0.754980 Train acc: 0.400000\n",
      "Epoch: 10/1000 Iteration: 75 Validation loss: 0.716159 Validation acc: 0.400000\n",
      "Epoch: 11/1000 Iteration: 80 Train loss: 0.692136 Train acc: 0.400000\n",
      "Epoch: 12/1000 Iteration: 85 Train loss: 0.724159 Train acc: 0.450000\n",
      "Epoch: 12/1000 Iteration: 90 Train loss: 0.760610 Train acc: 0.350000\n",
      "Epoch: 13/1000 Iteration: 95 Train loss: 0.714450 Train acc: 0.400000\n",
      "Epoch: 14/1000 Iteration: 100 Train loss: 0.684117 Train acc: 0.550000\n",
      "Epoch: 14/1000 Iteration: 100 Validation loss: 0.715053 Validation acc: 0.400000\n",
      "Epoch: 14/1000 Iteration: 105 Train loss: 0.727845 Train acc: 0.350000\n",
      "Epoch: 15/1000 Iteration: 110 Train loss: 0.699185 Train acc: 0.600000\n",
      "Epoch: 16/1000 Iteration: 115 Train loss: 0.711957 Train acc: 0.450000\n",
      "Epoch: 17/1000 Iteration: 120 Train loss: 0.701931 Train acc: 0.550000\n",
      "Epoch: 17/1000 Iteration: 125 Train loss: 0.700716 Train acc: 0.450000\n",
      "Epoch: 17/1000 Iteration: 125 Validation loss: 0.713971 Validation acc: 0.425000\n",
      "Epoch: 18/1000 Iteration: 130 Train loss: 0.711598 Train acc: 0.650000\n",
      "Epoch: 19/1000 Iteration: 135 Train loss: 0.698649 Train acc: 0.600000\n",
      "Epoch: 19/1000 Iteration: 140 Train loss: 0.707704 Train acc: 0.350000\n",
      "Epoch: 20/1000 Iteration: 145 Train loss: 0.722805 Train acc: 0.700000\n",
      "Epoch: 21/1000 Iteration: 150 Train loss: 0.728676 Train acc: 0.450000\n",
      "Epoch: 21/1000 Iteration: 150 Validation loss: 0.712890 Validation acc: 0.425000\n",
      "Epoch: 22/1000 Iteration: 155 Train loss: 0.696054 Train acc: 0.450000\n",
      "Epoch: 22/1000 Iteration: 160 Train loss: 0.726792 Train acc: 0.250000\n",
      "Epoch: 23/1000 Iteration: 165 Train loss: 0.742321 Train acc: 0.400000\n",
      "Epoch: 24/1000 Iteration: 170 Train loss: 0.657803 Train acc: 0.650000\n",
      "Epoch: 24/1000 Iteration: 175 Train loss: 0.702410 Train acc: 0.400000\n",
      "Epoch: 24/1000 Iteration: 175 Validation loss: 0.712020 Validation acc: 0.425000\n",
      "Epoch: 25/1000 Iteration: 180 Train loss: 0.708721 Train acc: 0.550000\n",
      "Epoch: 26/1000 Iteration: 185 Train loss: 0.701086 Train acc: 0.500000\n",
      "Epoch: 27/1000 Iteration: 190 Train loss: 0.692701 Train acc: 0.350000\n",
      "Epoch: 27/1000 Iteration: 195 Train loss: 0.711236 Train acc: 0.450000\n",
      "Epoch: 28/1000 Iteration: 200 Train loss: 0.718098 Train acc: 0.500000\n",
      "Epoch: 28/1000 Iteration: 200 Validation loss: 0.711149 Validation acc: 0.425000\n",
      "Epoch: 29/1000 Iteration: 205 Train loss: 0.702210 Train acc: 0.500000\n",
      "Epoch: 29/1000 Iteration: 210 Train loss: 0.711778 Train acc: 0.350000\n",
      "Epoch: 30/1000 Iteration: 215 Train loss: 0.685939 Train acc: 0.600000\n",
      "Epoch: 31/1000 Iteration: 220 Train loss: 0.710114 Train acc: 0.350000\n",
      "Epoch: 32/1000 Iteration: 225 Train loss: 0.654495 Train acc: 0.600000\n",
      "Epoch: 32/1000 Iteration: 225 Validation loss: 0.710419 Validation acc: 0.425000\n",
      "Epoch: 32/1000 Iteration: 230 Train loss: 0.725525 Train acc: 0.400000\n",
      "Epoch: 33/1000 Iteration: 235 Train loss: 0.756529 Train acc: 0.300000\n",
      "Epoch: 34/1000 Iteration: 240 Train loss: 0.686085 Train acc: 0.500000\n",
      "Epoch: 34/1000 Iteration: 245 Train loss: 0.711973 Train acc: 0.550000\n",
      "Epoch: 35/1000 Iteration: 250 Train loss: 0.705887 Train acc: 0.600000\n",
      "Epoch: 35/1000 Iteration: 250 Validation loss: 0.709518 Validation acc: 0.425000\n",
      "Epoch: 36/1000 Iteration: 255 Train loss: 0.721686 Train acc: 0.400000\n",
      "Epoch: 37/1000 Iteration: 260 Train loss: 0.694485 Train acc: 0.600000\n",
      "Epoch: 37/1000 Iteration: 265 Train loss: 0.704568 Train acc: 0.400000\n",
      "Epoch: 38/1000 Iteration: 270 Train loss: 0.706231 Train acc: 0.500000\n",
      "Epoch: 39/1000 Iteration: 275 Train loss: 0.707273 Train acc: 0.350000\n",
      "Epoch: 39/1000 Iteration: 275 Validation loss: 0.708793 Validation acc: 0.425000\n",
      "Epoch: 39/1000 Iteration: 280 Train loss: 0.722099 Train acc: 0.400000\n",
      "Epoch: 40/1000 Iteration: 285 Train loss: 0.709188 Train acc: 0.400000\n",
      "Epoch: 41/1000 Iteration: 290 Train loss: 0.714980 Train acc: 0.400000\n",
      "Epoch: 42/1000 Iteration: 295 Train loss: 0.692260 Train acc: 0.600000\n",
      "Epoch: 42/1000 Iteration: 300 Train loss: 0.702796 Train acc: 0.450000\n",
      "Epoch: 42/1000 Iteration: 300 Validation loss: 0.708214 Validation acc: 0.425000\n",
      "Epoch: 43/1000 Iteration: 305 Train loss: 0.715109 Train acc: 0.250000\n",
      "Epoch: 44/1000 Iteration: 310 Train loss: 0.698208 Train acc: 0.400000\n",
      "Epoch: 44/1000 Iteration: 315 Train loss: 0.689970 Train acc: 0.650000\n",
      "Epoch: 45/1000 Iteration: 320 Train loss: 0.706839 Train acc: 0.400000\n",
      "Epoch: 46/1000 Iteration: 325 Train loss: 0.714323 Train acc: 0.400000\n",
      "Epoch: 46/1000 Iteration: 325 Validation loss: 0.707734 Validation acc: 0.425000\n",
      "Epoch: 47/1000 Iteration: 330 Train loss: 0.703956 Train acc: 0.600000\n",
      "Epoch: 47/1000 Iteration: 335 Train loss: 0.673785 Train acc: 0.550000\n",
      "Epoch: 48/1000 Iteration: 340 Train loss: 0.711417 Train acc: 0.500000\n",
      "Epoch: 49/1000 Iteration: 345 Train loss: 0.683512 Train acc: 0.550000\n",
      "Epoch: 49/1000 Iteration: 350 Train loss: 0.688813 Train acc: 0.450000\n",
      "Epoch: 49/1000 Iteration: 350 Validation loss: 0.707230 Validation acc: 0.425000\n",
      "Epoch: 50/1000 Iteration: 355 Train loss: 0.713066 Train acc: 0.350000\n",
      "Epoch: 51/1000 Iteration: 360 Train loss: 0.719449 Train acc: 0.450000\n",
      "Epoch: 52/1000 Iteration: 365 Train loss: 0.701709 Train acc: 0.500000\n",
      "Epoch: 52/1000 Iteration: 370 Train loss: 0.706483 Train acc: 0.500000\n",
      "Epoch: 53/1000 Iteration: 375 Train loss: 0.709816 Train acc: 0.300000\n",
      "Epoch: 53/1000 Iteration: 375 Validation loss: 0.706852 Validation acc: 0.425000\n",
      "Epoch: 54/1000 Iteration: 380 Train loss: 0.687499 Train acc: 0.550000\n",
      "Epoch: 54/1000 Iteration: 385 Train loss: 0.712113 Train acc: 0.400000\n",
      "Epoch: 55/1000 Iteration: 390 Train loss: 0.693331 Train acc: 0.450000\n",
      "Epoch: 56/1000 Iteration: 395 Train loss: 0.736665 Train acc: 0.400000\n",
      "Epoch: 57/1000 Iteration: 400 Train loss: 0.709071 Train acc: 0.300000\n",
      "Epoch: 57/1000 Iteration: 400 Validation loss: 0.706299 Validation acc: 0.425000\n",
      "Epoch: 57/1000 Iteration: 405 Train loss: 0.709046 Train acc: 0.450000\n",
      "Epoch: 58/1000 Iteration: 410 Train loss: 0.714671 Train acc: 0.450000\n",
      "Epoch: 59/1000 Iteration: 415 Train loss: 0.681299 Train acc: 0.550000\n",
      "Epoch: 59/1000 Iteration: 420 Train loss: 0.715445 Train acc: 0.500000\n",
      "Epoch: 60/1000 Iteration: 425 Train loss: 0.699194 Train acc: 0.500000\n",
      "Epoch: 60/1000 Iteration: 425 Validation loss: 0.705882 Validation acc: 0.425000\n",
      "Epoch: 61/1000 Iteration: 430 Train loss: 0.710455 Train acc: 0.350000\n",
      "Epoch: 62/1000 Iteration: 435 Train loss: 0.682047 Train acc: 0.450000\n",
      "Epoch: 62/1000 Iteration: 440 Train loss: 0.721075 Train acc: 0.400000\n",
      "Epoch: 63/1000 Iteration: 445 Train loss: 0.695669 Train acc: 0.550000\n",
      "Epoch: 64/1000 Iteration: 450 Train loss: 0.706180 Train acc: 0.450000\n",
      "Epoch: 64/1000 Iteration: 450 Validation loss: 0.705567 Validation acc: 0.425000\n",
      "Epoch: 64/1000 Iteration: 455 Train loss: 0.696027 Train acc: 0.500000\n",
      "Epoch: 65/1000 Iteration: 460 Train loss: 0.733849 Train acc: 0.400000\n",
      "Epoch: 66/1000 Iteration: 465 Train loss: 0.699583 Train acc: 0.450000\n",
      "Epoch: 67/1000 Iteration: 470 Train loss: 0.684823 Train acc: 0.550000\n",
      "Epoch: 67/1000 Iteration: 475 Train loss: 0.731405 Train acc: 0.500000\n",
      "Epoch: 67/1000 Iteration: 475 Validation loss: 0.705171 Validation acc: 0.425000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/1000 Iteration: 480 Train loss: 0.708209 Train acc: 0.450000\n",
      "Epoch: 69/1000 Iteration: 485 Train loss: 0.681497 Train acc: 0.550000\n",
      "Epoch: 69/1000 Iteration: 490 Train loss: 0.722801 Train acc: 0.400000\n",
      "Epoch: 70/1000 Iteration: 495 Train loss: 0.685894 Train acc: 0.650000\n",
      "Epoch: 71/1000 Iteration: 500 Train loss: 0.714080 Train acc: 0.350000\n",
      "Epoch: 71/1000 Iteration: 500 Validation loss: 0.704584 Validation acc: 0.425000\n",
      "Epoch: 72/1000 Iteration: 505 Train loss: 0.683300 Train acc: 0.600000\n",
      "Epoch: 72/1000 Iteration: 510 Train loss: 0.702109 Train acc: 0.450000\n",
      "Epoch: 73/1000 Iteration: 515 Train loss: 0.704882 Train acc: 0.500000\n",
      "Epoch: 74/1000 Iteration: 520 Train loss: 0.698540 Train acc: 0.450000\n",
      "Epoch: 74/1000 Iteration: 525 Train loss: 0.675245 Train acc: 0.700000\n",
      "Epoch: 74/1000 Iteration: 525 Validation loss: 0.704101 Validation acc: 0.425000\n",
      "Epoch: 75/1000 Iteration: 530 Train loss: 0.696998 Train acc: 0.450000\n",
      "Epoch: 76/1000 Iteration: 535 Train loss: 0.699729 Train acc: 0.500000\n",
      "Epoch: 77/1000 Iteration: 540 Train loss: 0.689836 Train acc: 0.550000\n",
      "Epoch: 77/1000 Iteration: 545 Train loss: 0.715965 Train acc: 0.400000\n",
      "Epoch: 78/1000 Iteration: 550 Train loss: 0.714273 Train acc: 0.350000\n",
      "Epoch: 78/1000 Iteration: 550 Validation loss: 0.703623 Validation acc: 0.425000\n",
      "Epoch: 79/1000 Iteration: 555 Train loss: 0.692806 Train acc: 0.400000\n",
      "Epoch: 79/1000 Iteration: 560 Train loss: 0.696700 Train acc: 0.600000\n",
      "Epoch: 80/1000 Iteration: 565 Train loss: 0.687449 Train acc: 0.600000\n",
      "Epoch: 81/1000 Iteration: 570 Train loss: 0.694686 Train acc: 0.450000\n",
      "Epoch: 82/1000 Iteration: 575 Train loss: 0.686069 Train acc: 0.450000\n",
      "Epoch: 82/1000 Iteration: 575 Validation loss: 0.703269 Validation acc: 0.425000\n",
      "Epoch: 82/1000 Iteration: 580 Train loss: 0.727818 Train acc: 0.500000\n",
      "Epoch: 83/1000 Iteration: 585 Train loss: 0.677883 Train acc: 0.600000\n",
      "Epoch: 84/1000 Iteration: 590 Train loss: 0.712153 Train acc: 0.350000\n",
      "Epoch: 84/1000 Iteration: 595 Train loss: 0.708763 Train acc: 0.500000\n",
      "Epoch: 85/1000 Iteration: 600 Train loss: 0.711408 Train acc: 0.400000\n",
      "Epoch: 85/1000 Iteration: 600 Validation loss: 0.702809 Validation acc: 0.425000\n",
      "Epoch: 86/1000 Iteration: 605 Train loss: 0.687771 Train acc: 0.550000\n",
      "Epoch: 87/1000 Iteration: 610 Train loss: 0.699858 Train acc: 0.300000\n",
      "Epoch: 87/1000 Iteration: 615 Train loss: 0.705575 Train acc: 0.450000\n",
      "Epoch: 88/1000 Iteration: 620 Train loss: 0.702403 Train acc: 0.350000\n",
      "Epoch: 89/1000 Iteration: 625 Train loss: 0.681600 Train acc: 0.650000\n",
      "Epoch: 89/1000 Iteration: 625 Validation loss: 0.702529 Validation acc: 0.425000\n",
      "Epoch: 89/1000 Iteration: 630 Train loss: 0.693658 Train acc: 0.400000\n",
      "Epoch: 90/1000 Iteration: 635 Train loss: 0.707080 Train acc: 0.450000\n",
      "Epoch: 91/1000 Iteration: 640 Train loss: 0.706772 Train acc: 0.500000\n",
      "Epoch: 92/1000 Iteration: 645 Train loss: 0.668926 Train acc: 0.700000\n",
      "Epoch: 92/1000 Iteration: 650 Train loss: 0.718191 Train acc: 0.300000\n",
      "Epoch: 92/1000 Iteration: 650 Validation loss: 0.702272 Validation acc: 0.450000\n",
      "Epoch: 93/1000 Iteration: 655 Train loss: 0.707933 Train acc: 0.400000\n",
      "Epoch: 94/1000 Iteration: 660 Train loss: 0.679636 Train acc: 0.650000\n",
      "Epoch: 94/1000 Iteration: 665 Train loss: 0.692402 Train acc: 0.650000\n",
      "Epoch: 95/1000 Iteration: 670 Train loss: 0.702569 Train acc: 0.350000\n",
      "Epoch: 96/1000 Iteration: 675 Train loss: 0.706731 Train acc: 0.450000\n",
      "Epoch: 96/1000 Iteration: 675 Validation loss: 0.701978 Validation acc: 0.450000\n",
      "Epoch: 97/1000 Iteration: 680 Train loss: 0.700263 Train acc: 0.600000\n",
      "Epoch: 97/1000 Iteration: 685 Train loss: 0.727432 Train acc: 0.400000\n",
      "Epoch: 98/1000 Iteration: 690 Train loss: 0.689806 Train acc: 0.500000\n",
      "Epoch: 99/1000 Iteration: 695 Train loss: 0.708687 Train acc: 0.400000\n",
      "Epoch: 99/1000 Iteration: 700 Train loss: 0.683916 Train acc: 0.700000\n",
      "Epoch: 99/1000 Iteration: 700 Validation loss: 0.701595 Validation acc: 0.425000\n",
      "Epoch: 100/1000 Iteration: 705 Train loss: 0.697397 Train acc: 0.450000\n",
      "Epoch: 101/1000 Iteration: 710 Train loss: 0.662426 Train acc: 0.550000\n",
      "Epoch: 102/1000 Iteration: 715 Train loss: 0.698932 Train acc: 0.400000\n",
      "Epoch: 102/1000 Iteration: 720 Train loss: 0.693921 Train acc: 0.450000\n",
      "Epoch: 103/1000 Iteration: 725 Train loss: 0.693558 Train acc: 0.500000\n",
      "Epoch: 103/1000 Iteration: 725 Validation loss: 0.701330 Validation acc: 0.425000\n",
      "Epoch: 104/1000 Iteration: 730 Train loss: 0.709471 Train acc: 0.350000\n",
      "Epoch: 104/1000 Iteration: 735 Train loss: 0.667474 Train acc: 0.700000\n",
      "Epoch: 105/1000 Iteration: 740 Train loss: 0.690374 Train acc: 0.650000\n",
      "Epoch: 106/1000 Iteration: 745 Train loss: 0.695008 Train acc: 0.500000\n",
      "Epoch: 107/1000 Iteration: 750 Train loss: 0.694102 Train acc: 0.500000\n",
      "Epoch: 107/1000 Iteration: 750 Validation loss: 0.701274 Validation acc: 0.425000\n",
      "Epoch: 107/1000 Iteration: 755 Train loss: 0.705227 Train acc: 0.550000\n",
      "Epoch: 108/1000 Iteration: 760 Train loss: 0.713957 Train acc: 0.400000\n",
      "Epoch: 109/1000 Iteration: 765 Train loss: 0.667346 Train acc: 0.700000\n",
      "Epoch: 109/1000 Iteration: 770 Train loss: 0.689754 Train acc: 0.500000\n",
      "Epoch: 110/1000 Iteration: 775 Train loss: 0.686091 Train acc: 0.650000\n",
      "Epoch: 110/1000 Iteration: 775 Validation loss: 0.701081 Validation acc: 0.425000\n",
      "Epoch: 111/1000 Iteration: 780 Train loss: 0.694258 Train acc: 0.550000\n",
      "Epoch: 112/1000 Iteration: 785 Train loss: 0.690144 Train acc: 0.450000\n",
      "Epoch: 112/1000 Iteration: 790 Train loss: 0.704687 Train acc: 0.400000\n",
      "Epoch: 113/1000 Iteration: 795 Train loss: 0.685742 Train acc: 0.550000\n",
      "Epoch: 114/1000 Iteration: 800 Train loss: 0.690437 Train acc: 0.400000\n",
      "Epoch: 114/1000 Iteration: 800 Validation loss: 0.700752 Validation acc: 0.425000\n",
      "Epoch: 114/1000 Iteration: 805 Train loss: 0.681885 Train acc: 0.600000\n",
      "Epoch: 115/1000 Iteration: 810 Train loss: 0.702702 Train acc: 0.500000\n",
      "Epoch: 116/1000 Iteration: 815 Train loss: 0.697265 Train acc: 0.500000\n",
      "Epoch: 117/1000 Iteration: 820 Train loss: 0.694225 Train acc: 0.300000\n",
      "Epoch: 117/1000 Iteration: 825 Train loss: 0.704270 Train acc: 0.450000\n",
      "Epoch: 117/1000 Iteration: 825 Validation loss: 0.700548 Validation acc: 0.425000\n",
      "Epoch: 118/1000 Iteration: 830 Train loss: 0.701703 Train acc: 0.600000\n",
      "Epoch: 119/1000 Iteration: 835 Train loss: 0.701284 Train acc: 0.350000\n",
      "Epoch: 119/1000 Iteration: 840 Train loss: 0.677770 Train acc: 0.600000\n",
      "Epoch: 120/1000 Iteration: 845 Train loss: 0.700746 Train acc: 0.500000\n",
      "Epoch: 121/1000 Iteration: 850 Train loss: 0.713092 Train acc: 0.350000\n",
      "Epoch: 121/1000 Iteration: 850 Validation loss: 0.700330 Validation acc: 0.425000\n",
      "Epoch: 122/1000 Iteration: 855 Train loss: 0.711035 Train acc: 0.350000\n",
      "Epoch: 122/1000 Iteration: 860 Train loss: 0.709180 Train acc: 0.400000\n",
      "Epoch: 123/1000 Iteration: 865 Train loss: 0.682404 Train acc: 0.550000\n",
      "Epoch: 124/1000 Iteration: 870 Train loss: 0.670990 Train acc: 0.700000\n",
      "Epoch: 124/1000 Iteration: 875 Train loss: 0.692080 Train acc: 0.500000\n",
      "Epoch: 124/1000 Iteration: 875 Validation loss: 0.700205 Validation acc: 0.425000\n",
      "Epoch: 125/1000 Iteration: 880 Train loss: 0.673071 Train acc: 0.600000\n",
      "Epoch: 126/1000 Iteration: 885 Train loss: 0.707253 Train acc: 0.400000\n",
      "Epoch: 127/1000 Iteration: 890 Train loss: 0.683663 Train acc: 0.450000\n",
      "Epoch: 127/1000 Iteration: 895 Train loss: 0.691869 Train acc: 0.600000\n",
      "Epoch: 128/1000 Iteration: 900 Train loss: 0.718078 Train acc: 0.350000\n",
      "Epoch: 128/1000 Iteration: 900 Validation loss: 0.699974 Validation acc: 0.450000\n",
      "Epoch: 129/1000 Iteration: 905 Train loss: 0.686663 Train acc: 0.450000\n",
      "Epoch: 129/1000 Iteration: 910 Train loss: 0.672203 Train acc: 0.600000\n",
      "Epoch: 130/1000 Iteration: 915 Train loss: 0.682819 Train acc: 0.650000\n",
      "Epoch: 131/1000 Iteration: 920 Train loss: 0.706672 Train acc: 0.400000\n",
      "Epoch: 132/1000 Iteration: 925 Train loss: 0.682637 Train acc: 0.600000\n",
      "Epoch: 132/1000 Iteration: 925 Validation loss: 0.699809 Validation acc: 0.450000\n",
      "Epoch: 132/1000 Iteration: 930 Train loss: 0.690072 Train acc: 0.300000\n",
      "Epoch: 133/1000 Iteration: 935 Train loss: 0.727011 Train acc: 0.400000\n",
      "Epoch: 134/1000 Iteration: 940 Train loss: 0.697091 Train acc: 0.500000\n",
      "Epoch: 134/1000 Iteration: 945 Train loss: 0.688099 Train acc: 0.600000\n",
      "Epoch: 135/1000 Iteration: 950 Train loss: 0.715823 Train acc: 0.300000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/1000 Iteration: 950 Validation loss: 0.699782 Validation acc: 0.450000\n",
      "Epoch: 136/1000 Iteration: 955 Train loss: 0.700150 Train acc: 0.400000\n",
      "Epoch: 137/1000 Iteration: 960 Train loss: 0.699360 Train acc: 0.450000\n",
      "Epoch: 137/1000 Iteration: 965 Train loss: 0.688077 Train acc: 0.500000\n",
      "Epoch: 138/1000 Iteration: 970 Train loss: 0.716549 Train acc: 0.400000\n",
      "Epoch: 139/1000 Iteration: 975 Train loss: 0.681008 Train acc: 0.450000\n",
      "Epoch: 139/1000 Iteration: 975 Validation loss: 0.699667 Validation acc: 0.450000\n",
      "Epoch: 139/1000 Iteration: 980 Train loss: 0.674527 Train acc: 0.600000\n",
      "Epoch: 140/1000 Iteration: 985 Train loss: 0.693092 Train acc: 0.500000\n",
      "Epoch: 141/1000 Iteration: 990 Train loss: 0.694081 Train acc: 0.500000\n",
      "Epoch: 142/1000 Iteration: 995 Train loss: 0.693383 Train acc: 0.450000\n",
      "Epoch: 142/1000 Iteration: 1000 Train loss: 0.696748 Train acc: 0.450000\n",
      "Epoch: 142/1000 Iteration: 1000 Validation loss: 0.699494 Validation acc: 0.450000\n",
      "Epoch: 143/1000 Iteration: 1005 Train loss: 0.707315 Train acc: 0.250000\n",
      "Epoch: 144/1000 Iteration: 1010 Train loss: 0.700724 Train acc: 0.400000\n",
      "Epoch: 144/1000 Iteration: 1015 Train loss: 0.679567 Train acc: 0.550000\n",
      "Epoch: 145/1000 Iteration: 1020 Train loss: 0.708679 Train acc: 0.500000\n",
      "Epoch: 146/1000 Iteration: 1025 Train loss: 0.711147 Train acc: 0.300000\n",
      "Epoch: 146/1000 Iteration: 1025 Validation loss: 0.699401 Validation acc: 0.450000\n",
      "Epoch: 147/1000 Iteration: 1030 Train loss: 0.686462 Train acc: 0.600000\n",
      "Epoch: 147/1000 Iteration: 1035 Train loss: 0.715171 Train acc: 0.450000\n",
      "Epoch: 148/1000 Iteration: 1040 Train loss: 0.701388 Train acc: 0.500000\n",
      "Epoch: 149/1000 Iteration: 1045 Train loss: 0.706295 Train acc: 0.350000\n",
      "Epoch: 149/1000 Iteration: 1050 Train loss: 0.706660 Train acc: 0.400000\n",
      "Epoch: 149/1000 Iteration: 1050 Validation loss: 0.699211 Validation acc: 0.425000\n",
      "Epoch: 150/1000 Iteration: 1055 Train loss: 0.684062 Train acc: 0.600000\n",
      "Epoch: 151/1000 Iteration: 1060 Train loss: 0.708388 Train acc: 0.300000\n",
      "Epoch: 152/1000 Iteration: 1065 Train loss: 0.694556 Train acc: 0.500000\n",
      "Epoch: 152/1000 Iteration: 1070 Train loss: 0.683012 Train acc: 0.700000\n",
      "Epoch: 153/1000 Iteration: 1075 Train loss: 0.689322 Train acc: 0.500000\n",
      "Epoch: 153/1000 Iteration: 1075 Validation loss: 0.699007 Validation acc: 0.425000\n",
      "Epoch: 154/1000 Iteration: 1080 Train loss: 0.704744 Train acc: 0.500000\n",
      "Epoch: 154/1000 Iteration: 1085 Train loss: 0.688090 Train acc: 0.600000\n",
      "Epoch: 155/1000 Iteration: 1090 Train loss: 0.694207 Train acc: 0.350000\n",
      "Epoch: 156/1000 Iteration: 1095 Train loss: 0.698378 Train acc: 0.550000\n",
      "Epoch: 157/1000 Iteration: 1100 Train loss: 0.686665 Train acc: 0.550000\n",
      "Epoch: 157/1000 Iteration: 1100 Validation loss: 0.698807 Validation acc: 0.450000\n",
      "Epoch: 157/1000 Iteration: 1105 Train loss: 0.701767 Train acc: 0.400000\n",
      "Epoch: 158/1000 Iteration: 1110 Train loss: 0.712010 Train acc: 0.250000\n",
      "Epoch: 159/1000 Iteration: 1115 Train loss: 0.684224 Train acc: 0.600000\n",
      "Epoch: 159/1000 Iteration: 1120 Train loss: 0.694870 Train acc: 0.350000\n",
      "Epoch: 160/1000 Iteration: 1125 Train loss: 0.706845 Train acc: 0.550000\n",
      "Epoch: 160/1000 Iteration: 1125 Validation loss: 0.698574 Validation acc: 0.450000\n",
      "Epoch: 161/1000 Iteration: 1130 Train loss: 0.697371 Train acc: 0.450000\n",
      "Epoch: 162/1000 Iteration: 1135 Train loss: 0.697210 Train acc: 0.550000\n",
      "Epoch: 162/1000 Iteration: 1140 Train loss: 0.710706 Train acc: 0.300000\n",
      "Epoch: 163/1000 Iteration: 1145 Train loss: 0.694784 Train acc: 0.450000\n",
      "Epoch: 164/1000 Iteration: 1150 Train loss: 0.684813 Train acc: 0.350000\n",
      "Epoch: 164/1000 Iteration: 1150 Validation loss: 0.698416 Validation acc: 0.425000\n",
      "Epoch: 164/1000 Iteration: 1155 Train loss: 0.673007 Train acc: 0.650000\n",
      "Epoch: 165/1000 Iteration: 1160 Train loss: 0.717027 Train acc: 0.400000\n",
      "Epoch: 166/1000 Iteration: 1165 Train loss: 0.690353 Train acc: 0.600000\n",
      "Epoch: 167/1000 Iteration: 1170 Train loss: 0.708806 Train acc: 0.550000\n",
      "Epoch: 167/1000 Iteration: 1175 Train loss: 0.718160 Train acc: 0.300000\n",
      "Epoch: 167/1000 Iteration: 1175 Validation loss: 0.698373 Validation acc: 0.425000\n",
      "Epoch: 168/1000 Iteration: 1180 Train loss: 0.692524 Train acc: 0.450000\n",
      "Epoch: 169/1000 Iteration: 1185 Train loss: 0.697819 Train acc: 0.350000\n",
      "Epoch: 169/1000 Iteration: 1190 Train loss: 0.679757 Train acc: 0.550000\n",
      "Epoch: 170/1000 Iteration: 1195 Train loss: 0.690539 Train acc: 0.500000\n",
      "Epoch: 171/1000 Iteration: 1200 Train loss: 0.687125 Train acc: 0.500000\n",
      "Epoch: 171/1000 Iteration: 1200 Validation loss: 0.698270 Validation acc: 0.425000\n",
      "Epoch: 172/1000 Iteration: 1205 Train loss: 0.671723 Train acc: 0.550000\n",
      "Epoch: 172/1000 Iteration: 1210 Train loss: 0.707823 Train acc: 0.450000\n",
      "Epoch: 173/1000 Iteration: 1215 Train loss: 0.694066 Train acc: 0.500000\n",
      "Epoch: 174/1000 Iteration: 1220 Train loss: 0.682590 Train acc: 0.650000\n",
      "Epoch: 174/1000 Iteration: 1225 Train loss: 0.706608 Train acc: 0.550000\n",
      "Epoch: 174/1000 Iteration: 1225 Validation loss: 0.698095 Validation acc: 0.425000\n",
      "Epoch: 175/1000 Iteration: 1230 Train loss: 0.699476 Train acc: 0.400000\n",
      "Epoch: 176/1000 Iteration: 1235 Train loss: 0.689902 Train acc: 0.450000\n",
      "Epoch: 177/1000 Iteration: 1240 Train loss: 0.684511 Train acc: 0.550000\n",
      "Epoch: 177/1000 Iteration: 1245 Train loss: 0.688038 Train acc: 0.450000\n",
      "Epoch: 178/1000 Iteration: 1250 Train loss: 0.685287 Train acc: 0.600000\n",
      "Epoch: 178/1000 Iteration: 1250 Validation loss: 0.697890 Validation acc: 0.450000\n",
      "Epoch: 179/1000 Iteration: 1255 Train loss: 0.691594 Train acc: 0.550000\n",
      "Epoch: 179/1000 Iteration: 1260 Train loss: 0.700145 Train acc: 0.500000\n",
      "Epoch: 180/1000 Iteration: 1265 Train loss: 0.707390 Train acc: 0.500000\n",
      "Epoch: 181/1000 Iteration: 1270 Train loss: 0.695956 Train acc: 0.450000\n",
      "Epoch: 182/1000 Iteration: 1275 Train loss: 0.678302 Train acc: 0.500000\n",
      "Epoch: 182/1000 Iteration: 1275 Validation loss: 0.697680 Validation acc: 0.475000\n",
      "Epoch: 182/1000 Iteration: 1280 Train loss: 0.690007 Train acc: 0.450000\n",
      "Epoch: 183/1000 Iteration: 1285 Train loss: 0.702643 Train acc: 0.350000\n",
      "Epoch: 184/1000 Iteration: 1290 Train loss: 0.689674 Train acc: 0.500000\n",
      "Epoch: 184/1000 Iteration: 1295 Train loss: 0.706925 Train acc: 0.500000\n",
      "Epoch: 185/1000 Iteration: 1300 Train loss: 0.702865 Train acc: 0.400000\n",
      "Epoch: 185/1000 Iteration: 1300 Validation loss: 0.697588 Validation acc: 0.475000\n",
      "Epoch: 186/1000 Iteration: 1305 Train loss: 0.702008 Train acc: 0.450000\n",
      "Epoch: 187/1000 Iteration: 1310 Train loss: 0.688948 Train acc: 0.450000\n",
      "Epoch: 187/1000 Iteration: 1315 Train loss: 0.696790 Train acc: 0.450000\n",
      "Epoch: 188/1000 Iteration: 1320 Train loss: 0.676520 Train acc: 0.550000\n",
      "Epoch: 189/1000 Iteration: 1325 Train loss: 0.692051 Train acc: 0.450000\n",
      "Epoch: 189/1000 Iteration: 1325 Validation loss: 0.697475 Validation acc: 0.475000\n",
      "Epoch: 189/1000 Iteration: 1330 Train loss: 0.677615 Train acc: 0.600000\n",
      "Epoch: 190/1000 Iteration: 1335 Train loss: 0.685315 Train acc: 0.550000\n",
      "Epoch: 191/1000 Iteration: 1340 Train loss: 0.704294 Train acc: 0.400000\n",
      "Epoch: 192/1000 Iteration: 1345 Train loss: 0.681810 Train acc: 0.550000\n",
      "Epoch: 192/1000 Iteration: 1350 Train loss: 0.684568 Train acc: 0.750000\n",
      "Epoch: 192/1000 Iteration: 1350 Validation loss: 0.697338 Validation acc: 0.475000\n",
      "Epoch: 193/1000 Iteration: 1355 Train loss: 0.685545 Train acc: 0.550000\n",
      "Epoch: 194/1000 Iteration: 1360 Train loss: 0.688037 Train acc: 0.500000\n",
      "Epoch: 194/1000 Iteration: 1365 Train loss: 0.688219 Train acc: 0.650000\n",
      "Epoch: 195/1000 Iteration: 1370 Train loss: 0.711141 Train acc: 0.200000\n",
      "Epoch: 196/1000 Iteration: 1375 Train loss: 0.701596 Train acc: 0.350000\n",
      "Epoch: 196/1000 Iteration: 1375 Validation loss: 0.697104 Validation acc: 0.475000\n",
      "Epoch: 197/1000 Iteration: 1380 Train loss: 0.688470 Train acc: 0.450000\n",
      "Epoch: 197/1000 Iteration: 1385 Train loss: 0.699359 Train acc: 0.400000\n",
      "Epoch: 198/1000 Iteration: 1390 Train loss: 0.705863 Train acc: 0.350000\n",
      "Epoch: 199/1000 Iteration: 1395 Train loss: 0.693926 Train acc: 0.550000\n",
      "Epoch: 199/1000 Iteration: 1400 Train loss: 0.688449 Train acc: 0.450000\n",
      "Epoch: 199/1000 Iteration: 1400 Validation loss: 0.696926 Validation acc: 0.475000\n",
      "Epoch: 200/1000 Iteration: 1405 Train loss: 0.703542 Train acc: 0.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201/1000 Iteration: 1410 Train loss: 0.693089 Train acc: 0.400000\n",
      "Epoch: 202/1000 Iteration: 1415 Train loss: 0.707275 Train acc: 0.350000\n",
      "Epoch: 202/1000 Iteration: 1420 Train loss: 0.693438 Train acc: 0.400000\n",
      "Epoch: 203/1000 Iteration: 1425 Train loss: 0.707612 Train acc: 0.350000\n",
      "Epoch: 203/1000 Iteration: 1425 Validation loss: 0.696744 Validation acc: 0.475000\n",
      "Epoch: 204/1000 Iteration: 1430 Train loss: 0.682524 Train acc: 0.500000\n",
      "Epoch: 204/1000 Iteration: 1435 Train loss: 0.693409 Train acc: 0.650000\n",
      "Epoch: 205/1000 Iteration: 1440 Train loss: 0.689101 Train acc: 0.500000\n",
      "Epoch: 206/1000 Iteration: 1445 Train loss: 0.688284 Train acc: 0.550000\n",
      "Epoch: 207/1000 Iteration: 1450 Train loss: 0.709278 Train acc: 0.450000\n",
      "Epoch: 207/1000 Iteration: 1450 Validation loss: 0.696606 Validation acc: 0.475000\n",
      "Epoch: 207/1000 Iteration: 1455 Train loss: 0.699318 Train acc: 0.350000\n",
      "Epoch: 208/1000 Iteration: 1460 Train loss: 0.682468 Train acc: 0.600000\n",
      "Epoch: 209/1000 Iteration: 1465 Train loss: 0.683129 Train acc: 0.650000\n",
      "Epoch: 209/1000 Iteration: 1470 Train loss: 0.687673 Train acc: 0.500000\n",
      "Epoch: 210/1000 Iteration: 1475 Train loss: 0.708806 Train acc: 0.350000\n",
      "Epoch: 210/1000 Iteration: 1475 Validation loss: 0.696571 Validation acc: 0.475000\n",
      "Epoch: 211/1000 Iteration: 1480 Train loss: 0.679976 Train acc: 0.650000\n",
      "Epoch: 212/1000 Iteration: 1485 Train loss: 0.697576 Train acc: 0.350000\n",
      "Epoch: 212/1000 Iteration: 1490 Train loss: 0.696647 Train acc: 0.400000\n",
      "Epoch: 213/1000 Iteration: 1495 Train loss: 0.703375 Train acc: 0.400000\n",
      "Epoch: 214/1000 Iteration: 1500 Train loss: 0.690235 Train acc: 0.500000\n",
      "Epoch: 214/1000 Iteration: 1500 Validation loss: 0.696506 Validation acc: 0.475000\n",
      "Epoch: 214/1000 Iteration: 1505 Train loss: 0.686741 Train acc: 0.600000\n",
      "Epoch: 215/1000 Iteration: 1510 Train loss: 0.705414 Train acc: 0.400000\n",
      "Epoch: 216/1000 Iteration: 1515 Train loss: 0.701022 Train acc: 0.550000\n",
      "Epoch: 217/1000 Iteration: 1520 Train loss: 0.698824 Train acc: 0.500000\n",
      "Epoch: 217/1000 Iteration: 1525 Train loss: 0.689835 Train acc: 0.500000\n",
      "Epoch: 217/1000 Iteration: 1525 Validation loss: 0.696328 Validation acc: 0.475000\n",
      "Epoch: 218/1000 Iteration: 1530 Train loss: 0.688996 Train acc: 0.700000\n",
      "Epoch: 219/1000 Iteration: 1535 Train loss: 0.693140 Train acc: 0.500000\n",
      "Epoch: 219/1000 Iteration: 1540 Train loss: 0.692346 Train acc: 0.450000\n",
      "Epoch: 220/1000 Iteration: 1545 Train loss: 0.695240 Train acc: 0.400000\n",
      "Epoch: 221/1000 Iteration: 1550 Train loss: 0.700336 Train acc: 0.450000\n",
      "Epoch: 221/1000 Iteration: 1550 Validation loss: 0.696196 Validation acc: 0.475000\n",
      "Epoch: 222/1000 Iteration: 1555 Train loss: 0.709833 Train acc: 0.400000\n",
      "Epoch: 222/1000 Iteration: 1560 Train loss: 0.672731 Train acc: 0.650000\n",
      "Epoch: 223/1000 Iteration: 1565 Train loss: 0.698691 Train acc: 0.550000\n",
      "Epoch: 224/1000 Iteration: 1570 Train loss: 0.672085 Train acc: 0.650000\n",
      "Epoch: 224/1000 Iteration: 1575 Train loss: 0.692128 Train acc: 0.600000\n",
      "Epoch: 224/1000 Iteration: 1575 Validation loss: 0.696087 Validation acc: 0.475000\n",
      "Epoch: 225/1000 Iteration: 1580 Train loss: 0.699048 Train acc: 0.450000\n",
      "Epoch: 226/1000 Iteration: 1585 Train loss: 0.709023 Train acc: 0.450000\n",
      "Epoch: 227/1000 Iteration: 1590 Train loss: 0.694418 Train acc: 0.550000\n",
      "Epoch: 227/1000 Iteration: 1595 Train loss: 0.694080 Train acc: 0.550000\n",
      "Epoch: 228/1000 Iteration: 1600 Train loss: 0.709841 Train acc: 0.350000\n",
      "Epoch: 228/1000 Iteration: 1600 Validation loss: 0.695950 Validation acc: 0.475000\n",
      "Epoch: 229/1000 Iteration: 1605 Train loss: 0.691302 Train acc: 0.450000\n",
      "Epoch: 229/1000 Iteration: 1610 Train loss: 0.672543 Train acc: 0.850000\n",
      "Epoch: 230/1000 Iteration: 1615 Train loss: 0.691917 Train acc: 0.550000\n",
      "Epoch: 231/1000 Iteration: 1620 Train loss: 0.700002 Train acc: 0.350000\n",
      "Epoch: 232/1000 Iteration: 1625 Train loss: 0.701012 Train acc: 0.500000\n",
      "Epoch: 232/1000 Iteration: 1625 Validation loss: 0.695903 Validation acc: 0.475000\n",
      "Epoch: 232/1000 Iteration: 1630 Train loss: 0.686325 Train acc: 0.600000\n",
      "Epoch: 233/1000 Iteration: 1635 Train loss: 0.672603 Train acc: 0.600000\n",
      "Epoch: 234/1000 Iteration: 1640 Train loss: 0.674454 Train acc: 0.600000\n",
      "Epoch: 234/1000 Iteration: 1645 Train loss: 0.668045 Train acc: 0.700000\n",
      "Epoch: 235/1000 Iteration: 1650 Train loss: 0.700274 Train acc: 0.550000\n",
      "Epoch: 235/1000 Iteration: 1650 Validation loss: 0.695794 Validation acc: 0.475000\n",
      "Epoch: 236/1000 Iteration: 1655 Train loss: 0.683856 Train acc: 0.600000\n",
      "Epoch: 237/1000 Iteration: 1660 Train loss: 0.706577 Train acc: 0.400000\n",
      "Epoch: 237/1000 Iteration: 1665 Train loss: 0.685599 Train acc: 0.750000\n",
      "Epoch: 238/1000 Iteration: 1670 Train loss: 0.689854 Train acc: 0.450000\n",
      "Epoch: 239/1000 Iteration: 1675 Train loss: 0.699536 Train acc: 0.450000\n",
      "Epoch: 239/1000 Iteration: 1675 Validation loss: 0.695699 Validation acc: 0.475000\n",
      "Epoch: 239/1000 Iteration: 1680 Train loss: 0.679614 Train acc: 0.700000\n",
      "Epoch: 240/1000 Iteration: 1685 Train loss: 0.689453 Train acc: 0.450000\n",
      "Epoch: 241/1000 Iteration: 1690 Train loss: 0.694640 Train acc: 0.550000\n",
      "Epoch: 242/1000 Iteration: 1695 Train loss: 0.717175 Train acc: 0.200000\n",
      "Epoch: 242/1000 Iteration: 1700 Train loss: 0.686924 Train acc: 0.600000\n",
      "Epoch: 242/1000 Iteration: 1700 Validation loss: 0.695660 Validation acc: 0.475000\n",
      "Epoch: 243/1000 Iteration: 1705 Train loss: 0.707055 Train acc: 0.400000\n",
      "Epoch: 244/1000 Iteration: 1710 Train loss: 0.693833 Train acc: 0.500000\n",
      "Epoch: 244/1000 Iteration: 1715 Train loss: 0.688666 Train acc: 0.600000\n",
      "Epoch: 245/1000 Iteration: 1720 Train loss: 0.703996 Train acc: 0.400000\n",
      "Epoch: 246/1000 Iteration: 1725 Train loss: 0.659968 Train acc: 0.650000\n",
      "Epoch: 246/1000 Iteration: 1725 Validation loss: 0.695534 Validation acc: 0.475000\n",
      "Epoch: 247/1000 Iteration: 1730 Train loss: 0.681831 Train acc: 0.600000\n",
      "Epoch: 247/1000 Iteration: 1735 Train loss: 0.676450 Train acc: 0.650000\n",
      "Epoch: 248/1000 Iteration: 1740 Train loss: 0.719214 Train acc: 0.150000\n",
      "Epoch: 249/1000 Iteration: 1745 Train loss: 0.696336 Train acc: 0.350000\n",
      "Epoch: 249/1000 Iteration: 1750 Train loss: 0.691970 Train acc: 0.550000\n",
      "Epoch: 249/1000 Iteration: 1750 Validation loss: 0.695465 Validation acc: 0.475000\n",
      "Epoch: 250/1000 Iteration: 1755 Train loss: 0.693377 Train acc: 0.600000\n",
      "Epoch: 251/1000 Iteration: 1760 Train loss: 0.696472 Train acc: 0.400000\n",
      "Epoch: 252/1000 Iteration: 1765 Train loss: 0.694646 Train acc: 0.450000\n",
      "Epoch: 252/1000 Iteration: 1770 Train loss: 0.689526 Train acc: 0.600000\n",
      "Epoch: 253/1000 Iteration: 1775 Train loss: 0.683309 Train acc: 0.500000\n",
      "Epoch: 253/1000 Iteration: 1775 Validation loss: 0.695322 Validation acc: 0.475000\n",
      "Epoch: 254/1000 Iteration: 1780 Train loss: 0.675165 Train acc: 0.600000\n",
      "Epoch: 254/1000 Iteration: 1785 Train loss: 0.695061 Train acc: 0.500000\n",
      "Epoch: 255/1000 Iteration: 1790 Train loss: 0.690870 Train acc: 0.350000\n",
      "Epoch: 256/1000 Iteration: 1795 Train loss: 0.694086 Train acc: 0.450000\n",
      "Epoch: 257/1000 Iteration: 1800 Train loss: 0.696670 Train acc: 0.550000\n",
      "Epoch: 257/1000 Iteration: 1800 Validation loss: 0.695163 Validation acc: 0.475000\n",
      "Epoch: 257/1000 Iteration: 1805 Train loss: 0.703670 Train acc: 0.450000\n",
      "Epoch: 258/1000 Iteration: 1810 Train loss: 0.685541 Train acc: 0.450000\n",
      "Epoch: 259/1000 Iteration: 1815 Train loss: 0.693208 Train acc: 0.550000\n",
      "Epoch: 259/1000 Iteration: 1820 Train loss: 0.683383 Train acc: 0.550000\n",
      "Epoch: 260/1000 Iteration: 1825 Train loss: 0.700585 Train acc: 0.500000\n",
      "Epoch: 260/1000 Iteration: 1825 Validation loss: 0.695057 Validation acc: 0.475000\n",
      "Epoch: 261/1000 Iteration: 1830 Train loss: 0.706231 Train acc: 0.350000\n",
      "Epoch: 262/1000 Iteration: 1835 Train loss: 0.692787 Train acc: 0.600000\n",
      "Epoch: 262/1000 Iteration: 1840 Train loss: 0.678717 Train acc: 0.700000\n",
      "Epoch: 263/1000 Iteration: 1845 Train loss: 0.683438 Train acc: 0.550000\n",
      "Epoch: 264/1000 Iteration: 1850 Train loss: 0.711173 Train acc: 0.350000\n",
      "Epoch: 264/1000 Iteration: 1850 Validation loss: 0.694905 Validation acc: 0.500000\n",
      "Epoch: 264/1000 Iteration: 1855 Train loss: 0.682795 Train acc: 0.600000\n",
      "Epoch: 265/1000 Iteration: 1860 Train loss: 0.697653 Train acc: 0.550000\n",
      "Epoch: 266/1000 Iteration: 1865 Train loss: 0.695089 Train acc: 0.550000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 267/1000 Iteration: 1870 Train loss: 0.693783 Train acc: 0.500000\n",
      "Epoch: 267/1000 Iteration: 1875 Train loss: 0.673538 Train acc: 0.800000\n",
      "Epoch: 267/1000 Iteration: 1875 Validation loss: 0.694715 Validation acc: 0.500000\n",
      "Epoch: 268/1000 Iteration: 1880 Train loss: 0.691842 Train acc: 0.400000\n",
      "Epoch: 269/1000 Iteration: 1885 Train loss: 0.690246 Train acc: 0.550000\n",
      "Epoch: 269/1000 Iteration: 1890 Train loss: 0.694257 Train acc: 0.500000\n",
      "Epoch: 270/1000 Iteration: 1895 Train loss: 0.682200 Train acc: 0.700000\n",
      "Epoch: 271/1000 Iteration: 1900 Train loss: 0.684597 Train acc: 0.600000\n",
      "Epoch: 271/1000 Iteration: 1900 Validation loss: 0.694593 Validation acc: 0.500000\n",
      "Epoch: 272/1000 Iteration: 1905 Train loss: 0.684942 Train acc: 0.700000\n",
      "Epoch: 272/1000 Iteration: 1910 Train loss: 0.674472 Train acc: 0.700000\n",
      "Epoch: 273/1000 Iteration: 1915 Train loss: 0.685603 Train acc: 0.600000\n",
      "Epoch: 274/1000 Iteration: 1920 Train loss: 0.679908 Train acc: 0.500000\n",
      "Epoch: 274/1000 Iteration: 1925 Train loss: 0.691934 Train acc: 0.550000\n",
      "Epoch: 274/1000 Iteration: 1925 Validation loss: 0.694398 Validation acc: 0.500000\n",
      "Epoch: 275/1000 Iteration: 1930 Train loss: 0.682642 Train acc: 0.600000\n",
      "Epoch: 276/1000 Iteration: 1935 Train loss: 0.702840 Train acc: 0.400000\n",
      "Epoch: 277/1000 Iteration: 1940 Train loss: 0.708598 Train acc: 0.450000\n",
      "Epoch: 277/1000 Iteration: 1945 Train loss: 0.669962 Train acc: 0.750000\n",
      "Epoch: 278/1000 Iteration: 1950 Train loss: 0.707762 Train acc: 0.500000\n",
      "Epoch: 278/1000 Iteration: 1950 Validation loss: 0.694233 Validation acc: 0.500000\n",
      "Epoch: 279/1000 Iteration: 1955 Train loss: 0.674036 Train acc: 0.650000\n",
      "Epoch: 279/1000 Iteration: 1960 Train loss: 0.693543 Train acc: 0.450000\n",
      "Epoch: 280/1000 Iteration: 1965 Train loss: 0.677692 Train acc: 0.550000\n",
      "Epoch: 281/1000 Iteration: 1970 Train loss: 0.695211 Train acc: 0.550000\n",
      "Epoch: 282/1000 Iteration: 1975 Train loss: 0.728733 Train acc: 0.250000\n",
      "Epoch: 282/1000 Iteration: 1975 Validation loss: 0.694067 Validation acc: 0.500000\n",
      "Epoch: 282/1000 Iteration: 1980 Train loss: 0.692278 Train acc: 0.550000\n",
      "Epoch: 283/1000 Iteration: 1985 Train loss: 0.702153 Train acc: 0.450000\n",
      "Epoch: 284/1000 Iteration: 1990 Train loss: 0.696119 Train acc: 0.600000\n",
      "Epoch: 284/1000 Iteration: 1995 Train loss: 0.706472 Train acc: 0.550000\n",
      "Epoch: 285/1000 Iteration: 2000 Train loss: 0.687699 Train acc: 0.450000\n",
      "Epoch: 285/1000 Iteration: 2000 Validation loss: 0.693947 Validation acc: 0.500000\n",
      "Epoch: 286/1000 Iteration: 2005 Train loss: 0.691524 Train acc: 0.600000\n",
      "Epoch: 287/1000 Iteration: 2010 Train loss: 0.702441 Train acc: 0.400000\n",
      "Epoch: 287/1000 Iteration: 2015 Train loss: 0.660813 Train acc: 0.800000\n",
      "Epoch: 288/1000 Iteration: 2020 Train loss: 0.687946 Train acc: 0.400000\n",
      "Epoch: 289/1000 Iteration: 2025 Train loss: 0.688388 Train acc: 0.450000\n",
      "Epoch: 289/1000 Iteration: 2025 Validation loss: 0.693823 Validation acc: 0.500000\n",
      "Epoch: 289/1000 Iteration: 2030 Train loss: 0.682107 Train acc: 0.700000\n",
      "Epoch: 290/1000 Iteration: 2035 Train loss: 0.699024 Train acc: 0.500000\n",
      "Epoch: 291/1000 Iteration: 2040 Train loss: 0.670037 Train acc: 0.700000\n",
      "Epoch: 292/1000 Iteration: 2045 Train loss: 0.699268 Train acc: 0.350000\n",
      "Epoch: 292/1000 Iteration: 2050 Train loss: 0.685235 Train acc: 0.550000\n",
      "Epoch: 292/1000 Iteration: 2050 Validation loss: 0.693707 Validation acc: 0.500000\n",
      "Epoch: 293/1000 Iteration: 2055 Train loss: 0.697999 Train acc: 0.500000\n",
      "Epoch: 294/1000 Iteration: 2060 Train loss: 0.679663 Train acc: 0.650000\n",
      "Epoch: 294/1000 Iteration: 2065 Train loss: 0.688505 Train acc: 0.700000\n",
      "Epoch: 295/1000 Iteration: 2070 Train loss: 0.696342 Train acc: 0.400000\n",
      "Epoch: 296/1000 Iteration: 2075 Train loss: 0.698773 Train acc: 0.450000\n",
      "Epoch: 296/1000 Iteration: 2075 Validation loss: 0.693490 Validation acc: 0.525000\n",
      "Epoch: 297/1000 Iteration: 2080 Train loss: 0.688225 Train acc: 0.600000\n",
      "Epoch: 297/1000 Iteration: 2085 Train loss: 0.677502 Train acc: 0.600000\n",
      "Epoch: 298/1000 Iteration: 2090 Train loss: 0.697056 Train acc: 0.300000\n",
      "Epoch: 299/1000 Iteration: 2095 Train loss: 0.688642 Train acc: 0.550000\n",
      "Epoch: 299/1000 Iteration: 2100 Train loss: 0.695833 Train acc: 0.500000\n",
      "Epoch: 299/1000 Iteration: 2100 Validation loss: 0.693404 Validation acc: 0.525000\n",
      "Epoch: 300/1000 Iteration: 2105 Train loss: 0.711918 Train acc: 0.350000\n",
      "Epoch: 301/1000 Iteration: 2110 Train loss: 0.705899 Train acc: 0.350000\n",
      "Epoch: 302/1000 Iteration: 2115 Train loss: 0.678659 Train acc: 0.650000\n",
      "Epoch: 302/1000 Iteration: 2120 Train loss: 0.683693 Train acc: 0.500000\n",
      "Epoch: 303/1000 Iteration: 2125 Train loss: 0.699096 Train acc: 0.350000\n",
      "Epoch: 303/1000 Iteration: 2125 Validation loss: 0.693315 Validation acc: 0.525000\n",
      "Epoch: 304/1000 Iteration: 2130 Train loss: 0.677836 Train acc: 0.650000\n",
      "Epoch: 304/1000 Iteration: 2135 Train loss: 0.686365 Train acc: 0.650000\n",
      "Epoch: 305/1000 Iteration: 2140 Train loss: 0.697748 Train acc: 0.450000\n",
      "Epoch: 306/1000 Iteration: 2145 Train loss: 0.679045 Train acc: 0.600000\n",
      "Epoch: 307/1000 Iteration: 2150 Train loss: 0.715668 Train acc: 0.400000\n",
      "Epoch: 307/1000 Iteration: 2150 Validation loss: 0.693187 Validation acc: 0.525000\n",
      "Epoch: 307/1000 Iteration: 2155 Train loss: 0.684924 Train acc: 0.700000\n",
      "Epoch: 308/1000 Iteration: 2160 Train loss: 0.703115 Train acc: 0.350000\n",
      "Epoch: 309/1000 Iteration: 2165 Train loss: 0.682370 Train acc: 0.500000\n",
      "Epoch: 309/1000 Iteration: 2170 Train loss: 0.690834 Train acc: 0.400000\n",
      "Epoch: 310/1000 Iteration: 2175 Train loss: 0.724581 Train acc: 0.350000\n",
      "Epoch: 310/1000 Iteration: 2175 Validation loss: 0.693038 Validation acc: 0.525000\n",
      "Epoch: 311/1000 Iteration: 2180 Train loss: 0.683628 Train acc: 0.700000\n",
      "Epoch: 312/1000 Iteration: 2185 Train loss: 0.690607 Train acc: 0.500000\n",
      "Epoch: 312/1000 Iteration: 2190 Train loss: 0.694266 Train acc: 0.550000\n",
      "Epoch: 313/1000 Iteration: 2195 Train loss: 0.699026 Train acc: 0.500000\n",
      "Epoch: 314/1000 Iteration: 2200 Train loss: 0.679893 Train acc: 0.600000\n",
      "Epoch: 314/1000 Iteration: 2200 Validation loss: 0.692853 Validation acc: 0.525000\n",
      "Epoch: 314/1000 Iteration: 2205 Train loss: 0.698995 Train acc: 0.500000\n",
      "Epoch: 315/1000 Iteration: 2210 Train loss: 0.706498 Train acc: 0.350000\n",
      "Epoch: 316/1000 Iteration: 2215 Train loss: 0.684376 Train acc: 0.450000\n",
      "Epoch: 317/1000 Iteration: 2220 Train loss: 0.693836 Train acc: 0.450000\n",
      "Epoch: 317/1000 Iteration: 2225 Train loss: 0.679468 Train acc: 0.600000\n",
      "Epoch: 317/1000 Iteration: 2225 Validation loss: 0.692793 Validation acc: 0.500000\n",
      "Epoch: 318/1000 Iteration: 2230 Train loss: 0.680651 Train acc: 0.600000\n",
      "Epoch: 319/1000 Iteration: 2235 Train loss: 0.698902 Train acc: 0.450000\n",
      "Epoch: 319/1000 Iteration: 2240 Train loss: 0.693736 Train acc: 0.450000\n",
      "Epoch: 320/1000 Iteration: 2245 Train loss: 0.707111 Train acc: 0.400000\n",
      "Epoch: 321/1000 Iteration: 2250 Train loss: 0.687196 Train acc: 0.600000\n",
      "Epoch: 321/1000 Iteration: 2250 Validation loss: 0.692805 Validation acc: 0.500000\n",
      "Epoch: 322/1000 Iteration: 2255 Train loss: 0.695297 Train acc: 0.450000\n",
      "Epoch: 322/1000 Iteration: 2260 Train loss: 0.696360 Train acc: 0.500000\n",
      "Epoch: 323/1000 Iteration: 2265 Train loss: 0.685066 Train acc: 0.450000\n",
      "Epoch: 324/1000 Iteration: 2270 Train loss: 0.696950 Train acc: 0.450000\n",
      "Epoch: 324/1000 Iteration: 2275 Train loss: 0.680433 Train acc: 0.600000\n",
      "Epoch: 324/1000 Iteration: 2275 Validation loss: 0.692637 Validation acc: 0.500000\n",
      "Epoch: 325/1000 Iteration: 2280 Train loss: 0.700843 Train acc: 0.300000\n",
      "Epoch: 326/1000 Iteration: 2285 Train loss: 0.686914 Train acc: 0.550000\n",
      "Epoch: 327/1000 Iteration: 2290 Train loss: 0.701145 Train acc: 0.400000\n",
      "Epoch: 327/1000 Iteration: 2295 Train loss: 0.653093 Train acc: 0.850000\n",
      "Epoch: 328/1000 Iteration: 2300 Train loss: 0.679712 Train acc: 0.550000\n",
      "Epoch: 328/1000 Iteration: 2300 Validation loss: 0.692430 Validation acc: 0.500000\n",
      "Epoch: 329/1000 Iteration: 2305 Train loss: 0.688565 Train acc: 0.450000\n",
      "Epoch: 329/1000 Iteration: 2310 Train loss: 0.682854 Train acc: 0.500000\n",
      "Epoch: 330/1000 Iteration: 2315 Train loss: 0.706691 Train acc: 0.450000\n",
      "Epoch: 331/1000 Iteration: 2320 Train loss: 0.700188 Train acc: 0.550000\n",
      "Epoch: 332/1000 Iteration: 2325 Train loss: 0.694855 Train acc: 0.550000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 332/1000 Iteration: 2325 Validation loss: 0.692324 Validation acc: 0.500000\n",
      "Epoch: 332/1000 Iteration: 2330 Train loss: 0.674215 Train acc: 0.700000\n",
      "Epoch: 333/1000 Iteration: 2335 Train loss: 0.692628 Train acc: 0.500000\n",
      "Epoch: 334/1000 Iteration: 2340 Train loss: 0.691856 Train acc: 0.500000\n",
      "Epoch: 334/1000 Iteration: 2345 Train loss: 0.681853 Train acc: 0.550000\n",
      "Epoch: 335/1000 Iteration: 2350 Train loss: 0.682452 Train acc: 0.600000\n",
      "Epoch: 335/1000 Iteration: 2350 Validation loss: 0.692224 Validation acc: 0.500000\n",
      "Epoch: 336/1000 Iteration: 2355 Train loss: 0.686079 Train acc: 0.500000\n",
      "Epoch: 337/1000 Iteration: 2360 Train loss: 0.692598 Train acc: 0.600000\n",
      "Epoch: 337/1000 Iteration: 2365 Train loss: 0.691970 Train acc: 0.450000\n",
      "Epoch: 338/1000 Iteration: 2370 Train loss: 0.685947 Train acc: 0.500000\n",
      "Epoch: 339/1000 Iteration: 2375 Train loss: 0.690764 Train acc: 0.550000\n",
      "Epoch: 339/1000 Iteration: 2375 Validation loss: 0.692082 Validation acc: 0.500000\n",
      "Epoch: 339/1000 Iteration: 2380 Train loss: 0.678758 Train acc: 0.650000\n",
      "Epoch: 340/1000 Iteration: 2385 Train loss: 0.684631 Train acc: 0.550000\n",
      "Epoch: 341/1000 Iteration: 2390 Train loss: 0.683626 Train acc: 0.500000\n",
      "Epoch: 342/1000 Iteration: 2395 Train loss: 0.701366 Train acc: 0.350000\n",
      "Epoch: 342/1000 Iteration: 2400 Train loss: 0.683844 Train acc: 0.550000\n",
      "Epoch: 342/1000 Iteration: 2400 Validation loss: 0.691852 Validation acc: 0.525000\n",
      "Epoch: 343/1000 Iteration: 2405 Train loss: 0.709143 Train acc: 0.350000\n",
      "Epoch: 344/1000 Iteration: 2410 Train loss: 0.670202 Train acc: 0.700000\n",
      "Epoch: 344/1000 Iteration: 2415 Train loss: 0.676371 Train acc: 0.550000\n",
      "Epoch: 345/1000 Iteration: 2420 Train loss: 0.675619 Train acc: 0.750000\n",
      "Epoch: 346/1000 Iteration: 2425 Train loss: 0.696569 Train acc: 0.450000\n",
      "Epoch: 346/1000 Iteration: 2425 Validation loss: 0.691673 Validation acc: 0.525000\n",
      "Epoch: 347/1000 Iteration: 2430 Train loss: 0.707577 Train acc: 0.450000\n",
      "Epoch: 347/1000 Iteration: 2435 Train loss: 0.686041 Train acc: 0.400000\n",
      "Epoch: 348/1000 Iteration: 2440 Train loss: 0.702489 Train acc: 0.400000\n",
      "Epoch: 349/1000 Iteration: 2445 Train loss: 0.681418 Train acc: 0.650000\n",
      "Epoch: 349/1000 Iteration: 2450 Train loss: 0.704671 Train acc: 0.500000\n",
      "Epoch: 349/1000 Iteration: 2450 Validation loss: 0.691429 Validation acc: 0.525000\n",
      "Epoch: 350/1000 Iteration: 2455 Train loss: 0.687392 Train acc: 0.600000\n",
      "Epoch: 351/1000 Iteration: 2460 Train loss: 0.679791 Train acc: 0.600000\n",
      "Epoch: 352/1000 Iteration: 2465 Train loss: 0.695166 Train acc: 0.400000\n",
      "Epoch: 352/1000 Iteration: 2470 Train loss: 0.671262 Train acc: 0.550000\n",
      "Epoch: 353/1000 Iteration: 2475 Train loss: 0.698663 Train acc: 0.450000\n",
      "Epoch: 353/1000 Iteration: 2475 Validation loss: 0.691195 Validation acc: 0.525000\n",
      "Epoch: 354/1000 Iteration: 2480 Train loss: 0.696670 Train acc: 0.500000\n",
      "Epoch: 354/1000 Iteration: 2485 Train loss: 0.691785 Train acc: 0.550000\n",
      "Epoch: 355/1000 Iteration: 2490 Train loss: 0.690088 Train acc: 0.500000\n",
      "Epoch: 356/1000 Iteration: 2495 Train loss: 0.690352 Train acc: 0.500000\n",
      "Epoch: 357/1000 Iteration: 2500 Train loss: 0.683057 Train acc: 0.600000\n",
      "Epoch: 357/1000 Iteration: 2500 Validation loss: 0.690953 Validation acc: 0.575000\n",
      "Epoch: 357/1000 Iteration: 2505 Train loss: 0.663072 Train acc: 0.750000\n",
      "Epoch: 358/1000 Iteration: 2510 Train loss: 0.689009 Train acc: 0.350000\n",
      "Epoch: 359/1000 Iteration: 2515 Train loss: 0.689037 Train acc: 0.550000\n",
      "Epoch: 359/1000 Iteration: 2520 Train loss: 0.673211 Train acc: 0.550000\n",
      "Epoch: 360/1000 Iteration: 2525 Train loss: 0.696399 Train acc: 0.400000\n",
      "Epoch: 360/1000 Iteration: 2525 Validation loss: 0.690712 Validation acc: 0.550000\n",
      "Epoch: 361/1000 Iteration: 2530 Train loss: 0.709906 Train acc: 0.350000\n",
      "Epoch: 362/1000 Iteration: 2535 Train loss: 0.682659 Train acc: 0.500000\n",
      "Epoch: 362/1000 Iteration: 2540 Train loss: 0.682419 Train acc: 0.650000\n",
      "Epoch: 363/1000 Iteration: 2545 Train loss: 0.712159 Train acc: 0.450000\n",
      "Epoch: 364/1000 Iteration: 2550 Train loss: 0.693709 Train acc: 0.550000\n",
      "Epoch: 364/1000 Iteration: 2550 Validation loss: 0.690360 Validation acc: 0.575000\n",
      "Epoch: 364/1000 Iteration: 2555 Train loss: 0.695487 Train acc: 0.450000\n",
      "Epoch: 365/1000 Iteration: 2560 Train loss: 0.685009 Train acc: 0.600000\n",
      "Epoch: 366/1000 Iteration: 2565 Train loss: 0.678215 Train acc: 0.700000\n",
      "Epoch: 367/1000 Iteration: 2570 Train loss: 0.688255 Train acc: 0.550000\n",
      "Epoch: 367/1000 Iteration: 2575 Train loss: 0.669716 Train acc: 0.650000\n",
      "Epoch: 367/1000 Iteration: 2575 Validation loss: 0.690060 Validation acc: 0.575000\n",
      "Epoch: 368/1000 Iteration: 2580 Train loss: 0.701198 Train acc: 0.300000\n",
      "Epoch: 369/1000 Iteration: 2585 Train loss: 0.697566 Train acc: 0.600000\n",
      "Epoch: 369/1000 Iteration: 2590 Train loss: 0.686623 Train acc: 0.400000\n",
      "Epoch: 370/1000 Iteration: 2595 Train loss: 0.686246 Train acc: 0.500000\n",
      "Epoch: 371/1000 Iteration: 2600 Train loss: 0.699160 Train acc: 0.450000\n",
      "Epoch: 371/1000 Iteration: 2600 Validation loss: 0.689880 Validation acc: 0.575000\n",
      "Epoch: 372/1000 Iteration: 2605 Train loss: 0.687770 Train acc: 0.550000\n",
      "Epoch: 372/1000 Iteration: 2610 Train loss: 0.670435 Train acc: 0.650000\n",
      "Epoch: 373/1000 Iteration: 2615 Train loss: 0.684964 Train acc: 0.400000\n",
      "Epoch: 374/1000 Iteration: 2620 Train loss: 0.690696 Train acc: 0.450000\n",
      "Epoch: 374/1000 Iteration: 2625 Train loss: 0.700282 Train acc: 0.450000\n",
      "Epoch: 374/1000 Iteration: 2625 Validation loss: 0.689523 Validation acc: 0.575000\n",
      "Epoch: 375/1000 Iteration: 2630 Train loss: 0.693143 Train acc: 0.500000\n",
      "Epoch: 376/1000 Iteration: 2635 Train loss: 0.663322 Train acc: 0.600000\n",
      "Epoch: 377/1000 Iteration: 2640 Train loss: 0.702330 Train acc: 0.450000\n",
      "Epoch: 377/1000 Iteration: 2645 Train loss: 0.656053 Train acc: 0.750000\n",
      "Epoch: 378/1000 Iteration: 2650 Train loss: 0.703248 Train acc: 0.350000\n",
      "Epoch: 378/1000 Iteration: 2650 Validation loss: 0.689049 Validation acc: 0.575000\n",
      "Epoch: 379/1000 Iteration: 2655 Train loss: 0.698569 Train acc: 0.400000\n",
      "Epoch: 379/1000 Iteration: 2660 Train loss: 0.685827 Train acc: 0.550000\n",
      "Epoch: 380/1000 Iteration: 2665 Train loss: 0.692380 Train acc: 0.350000\n",
      "Epoch: 381/1000 Iteration: 2670 Train loss: 0.689615 Train acc: 0.500000\n",
      "Epoch: 382/1000 Iteration: 2675 Train loss: 0.693303 Train acc: 0.500000\n",
      "Epoch: 382/1000 Iteration: 2675 Validation loss: 0.688593 Validation acc: 0.575000\n",
      "Epoch: 382/1000 Iteration: 2680 Train loss: 0.682567 Train acc: 0.700000\n",
      "Epoch: 383/1000 Iteration: 2685 Train loss: 0.702086 Train acc: 0.550000\n",
      "Epoch: 384/1000 Iteration: 2690 Train loss: 0.673142 Train acc: 0.600000\n",
      "Epoch: 384/1000 Iteration: 2695 Train loss: 0.695195 Train acc: 0.550000\n",
      "Epoch: 385/1000 Iteration: 2700 Train loss: 0.704775 Train acc: 0.450000\n",
      "Epoch: 385/1000 Iteration: 2700 Validation loss: 0.688251 Validation acc: 0.600000\n",
      "Epoch: 386/1000 Iteration: 2705 Train loss: 0.696709 Train acc: 0.450000\n",
      "Epoch: 387/1000 Iteration: 2710 Train loss: 0.702719 Train acc: 0.600000\n",
      "Epoch: 387/1000 Iteration: 2715 Train loss: 0.665357 Train acc: 0.750000\n",
      "Epoch: 388/1000 Iteration: 2720 Train loss: 0.684752 Train acc: 0.550000\n",
      "Epoch: 389/1000 Iteration: 2725 Train loss: 0.698749 Train acc: 0.400000\n",
      "Epoch: 389/1000 Iteration: 2725 Validation loss: 0.688057 Validation acc: 0.600000\n",
      "Epoch: 389/1000 Iteration: 2730 Train loss: 0.659673 Train acc: 0.650000\n",
      "Epoch: 390/1000 Iteration: 2735 Train loss: 0.680749 Train acc: 0.550000\n",
      "Epoch: 391/1000 Iteration: 2740 Train loss: 0.704806 Train acc: 0.600000\n",
      "Epoch: 392/1000 Iteration: 2745 Train loss: 0.685061 Train acc: 0.500000\n",
      "Epoch: 392/1000 Iteration: 2750 Train loss: 0.660689 Train acc: 0.650000\n",
      "Epoch: 392/1000 Iteration: 2750 Validation loss: 0.687710 Validation acc: 0.600000\n",
      "Epoch: 393/1000 Iteration: 2755 Train loss: 0.677818 Train acc: 0.600000\n",
      "Epoch: 394/1000 Iteration: 2760 Train loss: 0.692410 Train acc: 0.550000\n",
      "Epoch: 394/1000 Iteration: 2765 Train loss: 0.703974 Train acc: 0.400000\n",
      "Epoch: 395/1000 Iteration: 2770 Train loss: 0.674904 Train acc: 0.550000\n",
      "Epoch: 396/1000 Iteration: 2775 Train loss: 0.691284 Train acc: 0.700000\n",
      "Epoch: 396/1000 Iteration: 2775 Validation loss: 0.687417 Validation acc: 0.600000\n",
      "Epoch: 397/1000 Iteration: 2780 Train loss: 0.699603 Train acc: 0.400000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 397/1000 Iteration: 2785 Train loss: 0.662205 Train acc: 0.650000\n",
      "Epoch: 398/1000 Iteration: 2790 Train loss: 0.690825 Train acc: 0.500000\n",
      "Epoch: 399/1000 Iteration: 2795 Train loss: 0.690818 Train acc: 0.550000\n",
      "Epoch: 399/1000 Iteration: 2800 Train loss: 0.684739 Train acc: 0.550000\n",
      "Epoch: 399/1000 Iteration: 2800 Validation loss: 0.687092 Validation acc: 0.600000\n",
      "Epoch: 400/1000 Iteration: 2805 Train loss: 0.683950 Train acc: 0.500000\n",
      "Epoch: 401/1000 Iteration: 2810 Train loss: 0.693148 Train acc: 0.500000\n",
      "Epoch: 402/1000 Iteration: 2815 Train loss: 0.693591 Train acc: 0.400000\n",
      "Epoch: 402/1000 Iteration: 2820 Train loss: 0.660709 Train acc: 0.800000\n",
      "Epoch: 403/1000 Iteration: 2825 Train loss: 0.683631 Train acc: 0.600000\n",
      "Epoch: 403/1000 Iteration: 2825 Validation loss: 0.686739 Validation acc: 0.600000\n",
      "Epoch: 404/1000 Iteration: 2830 Train loss: 0.681328 Train acc: 0.550000\n",
      "Epoch: 404/1000 Iteration: 2835 Train loss: 0.656857 Train acc: 0.800000\n",
      "Epoch: 405/1000 Iteration: 2840 Train loss: 0.694141 Train acc: 0.400000\n",
      "Epoch: 406/1000 Iteration: 2845 Train loss: 0.701078 Train acc: 0.400000\n",
      "Epoch: 407/1000 Iteration: 2850 Train loss: 0.685077 Train acc: 0.650000\n",
      "Epoch: 407/1000 Iteration: 2850 Validation loss: 0.686233 Validation acc: 0.600000\n",
      "Epoch: 407/1000 Iteration: 2855 Train loss: 0.653714 Train acc: 0.900000\n",
      "Epoch: 408/1000 Iteration: 2860 Train loss: 0.656415 Train acc: 0.700000\n",
      "Epoch: 409/1000 Iteration: 2865 Train loss: 0.704438 Train acc: 0.500000\n",
      "Epoch: 409/1000 Iteration: 2870 Train loss: 0.702709 Train acc: 0.500000\n",
      "Epoch: 410/1000 Iteration: 2875 Train loss: 0.685621 Train acc: 0.600000\n",
      "Epoch: 410/1000 Iteration: 2875 Validation loss: 0.685778 Validation acc: 0.600000\n",
      "Epoch: 411/1000 Iteration: 2880 Train loss: 0.685287 Train acc: 0.550000\n",
      "Epoch: 412/1000 Iteration: 2885 Train loss: 0.694111 Train acc: 0.500000\n",
      "Epoch: 412/1000 Iteration: 2890 Train loss: 0.681364 Train acc: 0.500000\n",
      "Epoch: 413/1000 Iteration: 2895 Train loss: 0.664117 Train acc: 0.600000\n",
      "Epoch: 414/1000 Iteration: 2900 Train loss: 0.688811 Train acc: 0.400000\n",
      "Epoch: 414/1000 Iteration: 2900 Validation loss: 0.685308 Validation acc: 0.600000\n",
      "Epoch: 414/1000 Iteration: 2905 Train loss: 0.690448 Train acc: 0.400000\n",
      "Epoch: 415/1000 Iteration: 2910 Train loss: 0.695135 Train acc: 0.600000\n",
      "Epoch: 416/1000 Iteration: 2915 Train loss: 0.693439 Train acc: 0.400000\n",
      "Epoch: 417/1000 Iteration: 2920 Train loss: 0.675891 Train acc: 0.550000\n",
      "Epoch: 417/1000 Iteration: 2925 Train loss: 0.659052 Train acc: 0.700000\n",
      "Epoch: 417/1000 Iteration: 2925 Validation loss: 0.684635 Validation acc: 0.600000\n",
      "Epoch: 418/1000 Iteration: 2930 Train loss: 0.673796 Train acc: 0.550000\n",
      "Epoch: 419/1000 Iteration: 2935 Train loss: 0.702578 Train acc: 0.500000\n",
      "Epoch: 419/1000 Iteration: 2940 Train loss: 0.692329 Train acc: 0.550000\n",
      "Epoch: 420/1000 Iteration: 2945 Train loss: 0.677090 Train acc: 0.750000\n",
      "Epoch: 421/1000 Iteration: 2950 Train loss: 0.689723 Train acc: 0.450000\n",
      "Epoch: 421/1000 Iteration: 2950 Validation loss: 0.684111 Validation acc: 0.600000\n",
      "Epoch: 422/1000 Iteration: 2955 Train loss: 0.696278 Train acc: 0.500000\n",
      "Epoch: 422/1000 Iteration: 2960 Train loss: 0.653832 Train acc: 0.700000\n",
      "Epoch: 423/1000 Iteration: 2965 Train loss: 0.674658 Train acc: 0.600000\n",
      "Epoch: 424/1000 Iteration: 2970 Train loss: 0.668391 Train acc: 0.600000\n",
      "Epoch: 424/1000 Iteration: 2975 Train loss: 0.682302 Train acc: 0.600000\n",
      "Epoch: 424/1000 Iteration: 2975 Validation loss: 0.683460 Validation acc: 0.575000\n",
      "Epoch: 425/1000 Iteration: 2980 Train loss: 0.682185 Train acc: 0.600000\n",
      "Epoch: 426/1000 Iteration: 2985 Train loss: 0.689262 Train acc: 0.600000\n",
      "Epoch: 427/1000 Iteration: 2990 Train loss: 0.710841 Train acc: 0.350000\n",
      "Epoch: 427/1000 Iteration: 2995 Train loss: 0.668243 Train acc: 0.700000\n",
      "Epoch: 428/1000 Iteration: 3000 Train loss: 0.693853 Train acc: 0.500000\n",
      "Epoch: 428/1000 Iteration: 3000 Validation loss: 0.682851 Validation acc: 0.575000\n",
      "Epoch: 429/1000 Iteration: 3005 Train loss: 0.659778 Train acc: 0.850000\n",
      "Epoch: 429/1000 Iteration: 3010 Train loss: 0.663263 Train acc: 0.600000\n",
      "Epoch: 430/1000 Iteration: 3015 Train loss: 0.672267 Train acc: 0.550000\n",
      "Epoch: 431/1000 Iteration: 3020 Train loss: 0.698956 Train acc: 0.550000\n",
      "Epoch: 432/1000 Iteration: 3025 Train loss: 0.666367 Train acc: 0.650000\n",
      "Epoch: 432/1000 Iteration: 3025 Validation loss: 0.682239 Validation acc: 0.600000\n",
      "Epoch: 432/1000 Iteration: 3030 Train loss: 0.649403 Train acc: 0.700000\n",
      "Epoch: 433/1000 Iteration: 3035 Train loss: 0.691318 Train acc: 0.450000\n",
      "Epoch: 434/1000 Iteration: 3040 Train loss: 0.675406 Train acc: 0.500000\n",
      "Epoch: 434/1000 Iteration: 3045 Train loss: 0.699779 Train acc: 0.600000\n",
      "Epoch: 435/1000 Iteration: 3050 Train loss: 0.682930 Train acc: 0.650000\n",
      "Epoch: 435/1000 Iteration: 3050 Validation loss: 0.681407 Validation acc: 0.575000\n",
      "Epoch: 436/1000 Iteration: 3055 Train loss: 0.681299 Train acc: 0.550000\n",
      "Epoch: 437/1000 Iteration: 3060 Train loss: 0.673136 Train acc: 0.450000\n",
      "Epoch: 437/1000 Iteration: 3065 Train loss: 0.651823 Train acc: 0.800000\n",
      "Epoch: 438/1000 Iteration: 3070 Train loss: 0.682755 Train acc: 0.550000\n",
      "Epoch: 439/1000 Iteration: 3075 Train loss: 0.666057 Train acc: 0.650000\n",
      "Epoch: 439/1000 Iteration: 3075 Validation loss: 0.680573 Validation acc: 0.575000\n",
      "Epoch: 439/1000 Iteration: 3080 Train loss: 0.668355 Train acc: 0.600000\n",
      "Epoch: 440/1000 Iteration: 3085 Train loss: 0.667121 Train acc: 0.500000\n",
      "Epoch: 441/1000 Iteration: 3090 Train loss: 0.676406 Train acc: 0.450000\n",
      "Epoch: 442/1000 Iteration: 3095 Train loss: 0.692392 Train acc: 0.450000\n",
      "Epoch: 442/1000 Iteration: 3100 Train loss: 0.662028 Train acc: 0.650000\n",
      "Epoch: 442/1000 Iteration: 3100 Validation loss: 0.679304 Validation acc: 0.575000\n",
      "Epoch: 443/1000 Iteration: 3105 Train loss: 0.700075 Train acc: 0.350000\n",
      "Epoch: 444/1000 Iteration: 3110 Train loss: 0.689185 Train acc: 0.500000\n",
      "Epoch: 444/1000 Iteration: 3115 Train loss: 0.699312 Train acc: 0.500000\n",
      "Epoch: 445/1000 Iteration: 3120 Train loss: 0.675376 Train acc: 0.500000\n",
      "Epoch: 446/1000 Iteration: 3125 Train loss: 0.672008 Train acc: 0.650000\n",
      "Epoch: 446/1000 Iteration: 3125 Validation loss: 0.678247 Validation acc: 0.625000\n",
      "Epoch: 447/1000 Iteration: 3130 Train loss: 0.679623 Train acc: 0.500000\n",
      "Epoch: 447/1000 Iteration: 3135 Train loss: 0.655935 Train acc: 0.700000\n",
      "Epoch: 448/1000 Iteration: 3140 Train loss: 0.679473 Train acc: 0.400000\n",
      "Epoch: 449/1000 Iteration: 3145 Train loss: 0.677227 Train acc: 0.450000\n",
      "Epoch: 449/1000 Iteration: 3150 Train loss: 0.690035 Train acc: 0.550000\n",
      "Epoch: 449/1000 Iteration: 3150 Validation loss: 0.677091 Validation acc: 0.650000\n",
      "Epoch: 450/1000 Iteration: 3155 Train loss: 0.691391 Train acc: 0.600000\n",
      "Epoch: 451/1000 Iteration: 3160 Train loss: 0.683002 Train acc: 0.650000\n",
      "Epoch: 452/1000 Iteration: 3165 Train loss: 0.692343 Train acc: 0.450000\n",
      "Epoch: 452/1000 Iteration: 3170 Train loss: 0.656254 Train acc: 0.700000\n",
      "Epoch: 453/1000 Iteration: 3175 Train loss: 0.678109 Train acc: 0.600000\n",
      "Epoch: 453/1000 Iteration: 3175 Validation loss: 0.676050 Validation acc: 0.675000\n",
      "Epoch: 454/1000 Iteration: 3180 Train loss: 0.689424 Train acc: 0.500000\n",
      "Epoch: 454/1000 Iteration: 3185 Train loss: 0.712599 Train acc: 0.300000\n",
      "Epoch: 455/1000 Iteration: 3190 Train loss: 0.690827 Train acc: 0.650000\n",
      "Epoch: 456/1000 Iteration: 3195 Train loss: 0.679462 Train acc: 0.650000\n",
      "Epoch: 457/1000 Iteration: 3200 Train loss: 0.660095 Train acc: 0.650000\n",
      "Epoch: 457/1000 Iteration: 3200 Validation loss: 0.675007 Validation acc: 0.675000\n",
      "Epoch: 457/1000 Iteration: 3205 Train loss: 0.658162 Train acc: 0.650000\n",
      "Epoch: 458/1000 Iteration: 3210 Train loss: 0.683865 Train acc: 0.550000\n",
      "Epoch: 459/1000 Iteration: 3215 Train loss: 0.673159 Train acc: 0.700000\n",
      "Epoch: 459/1000 Iteration: 3220 Train loss: 0.646902 Train acc: 0.650000\n",
      "Epoch: 460/1000 Iteration: 3225 Train loss: 0.680468 Train acc: 0.450000\n",
      "Epoch: 460/1000 Iteration: 3225 Validation loss: 0.673861 Validation acc: 0.675000\n",
      "Epoch: 461/1000 Iteration: 3230 Train loss: 0.690850 Train acc: 0.600000\n",
      "Epoch: 462/1000 Iteration: 3235 Train loss: 0.675312 Train acc: 0.550000\n",
      "Epoch: 462/1000 Iteration: 3240 Train loss: 0.632051 Train acc: 0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 463/1000 Iteration: 3245 Train loss: 0.670982 Train acc: 0.500000\n",
      "Epoch: 464/1000 Iteration: 3250 Train loss: 0.692167 Train acc: 0.600000\n",
      "Epoch: 464/1000 Iteration: 3250 Validation loss: 0.672830 Validation acc: 0.675000\n",
      "Epoch: 464/1000 Iteration: 3255 Train loss: 0.676871 Train acc: 0.450000\n",
      "Epoch: 465/1000 Iteration: 3260 Train loss: 0.671389 Train acc: 0.650000\n",
      "Epoch: 466/1000 Iteration: 3265 Train loss: 0.666281 Train acc: 0.600000\n",
      "Epoch: 467/1000 Iteration: 3270 Train loss: 0.702069 Train acc: 0.500000\n",
      "Epoch: 467/1000 Iteration: 3275 Train loss: 0.653293 Train acc: 0.650000\n",
      "Epoch: 467/1000 Iteration: 3275 Validation loss: 0.671390 Validation acc: 0.675000\n",
      "Epoch: 468/1000 Iteration: 3280 Train loss: 0.671312 Train acc: 0.550000\n",
      "Epoch: 469/1000 Iteration: 3285 Train loss: 0.673758 Train acc: 0.700000\n",
      "Epoch: 469/1000 Iteration: 3290 Train loss: 0.651549 Train acc: 0.650000\n",
      "Epoch: 470/1000 Iteration: 3295 Train loss: 0.677817 Train acc: 0.550000\n",
      "Epoch: 471/1000 Iteration: 3300 Train loss: 0.689534 Train acc: 0.550000\n",
      "Epoch: 471/1000 Iteration: 3300 Validation loss: 0.669667 Validation acc: 0.675000\n",
      "Epoch: 472/1000 Iteration: 3305 Train loss: 0.697516 Train acc: 0.550000\n",
      "Epoch: 472/1000 Iteration: 3310 Train loss: 0.650363 Train acc: 0.800000\n",
      "Epoch: 473/1000 Iteration: 3315 Train loss: 0.671546 Train acc: 0.650000\n",
      "Epoch: 474/1000 Iteration: 3320 Train loss: 0.682394 Train acc: 0.500000\n",
      "Epoch: 474/1000 Iteration: 3325 Train loss: 0.696014 Train acc: 0.550000\n",
      "Epoch: 474/1000 Iteration: 3325 Validation loss: 0.667730 Validation acc: 0.675000\n",
      "Epoch: 475/1000 Iteration: 3330 Train loss: 0.671425 Train acc: 0.650000\n",
      "Epoch: 476/1000 Iteration: 3335 Train loss: 0.666990 Train acc: 0.550000\n",
      "Epoch: 477/1000 Iteration: 3340 Train loss: 0.715985 Train acc: 0.500000\n",
      "Epoch: 477/1000 Iteration: 3345 Train loss: 0.668397 Train acc: 0.600000\n",
      "Epoch: 478/1000 Iteration: 3350 Train loss: 0.671018 Train acc: 0.500000\n",
      "Epoch: 478/1000 Iteration: 3350 Validation loss: 0.665898 Validation acc: 0.675000\n",
      "Epoch: 479/1000 Iteration: 3355 Train loss: 0.658065 Train acc: 0.700000\n",
      "Epoch: 479/1000 Iteration: 3360 Train loss: 0.677470 Train acc: 0.550000\n",
      "Epoch: 480/1000 Iteration: 3365 Train loss: 0.683147 Train acc: 0.500000\n",
      "Epoch: 481/1000 Iteration: 3370 Train loss: 0.699138 Train acc: 0.450000\n",
      "Epoch: 482/1000 Iteration: 3375 Train loss: 0.656217 Train acc: 0.650000\n",
      "Epoch: 482/1000 Iteration: 3375 Validation loss: 0.663292 Validation acc: 0.675000\n",
      "Epoch: 482/1000 Iteration: 3380 Train loss: 0.626119 Train acc: 0.550000\n",
      "Epoch: 483/1000 Iteration: 3385 Train loss: 0.670846 Train acc: 0.700000\n",
      "Epoch: 484/1000 Iteration: 3390 Train loss: 0.700542 Train acc: 0.450000\n",
      "Epoch: 484/1000 Iteration: 3395 Train loss: 0.693594 Train acc: 0.450000\n",
      "Epoch: 485/1000 Iteration: 3400 Train loss: 0.645720 Train acc: 0.650000\n",
      "Epoch: 485/1000 Iteration: 3400 Validation loss: 0.660833 Validation acc: 0.650000\n",
      "Epoch: 486/1000 Iteration: 3405 Train loss: 0.664411 Train acc: 0.600000\n",
      "Epoch: 487/1000 Iteration: 3410 Train loss: 0.670353 Train acc: 0.600000\n",
      "Epoch: 487/1000 Iteration: 3415 Train loss: 0.642519 Train acc: 0.700000\n",
      "Epoch: 488/1000 Iteration: 3420 Train loss: 0.681735 Train acc: 0.450000\n",
      "Epoch: 489/1000 Iteration: 3425 Train loss: 0.668624 Train acc: 0.550000\n",
      "Epoch: 489/1000 Iteration: 3425 Validation loss: 0.658758 Validation acc: 0.650000\n",
      "Epoch: 489/1000 Iteration: 3430 Train loss: 0.662426 Train acc: 0.500000\n",
      "Epoch: 490/1000 Iteration: 3435 Train loss: 0.682578 Train acc: 0.550000\n",
      "Epoch: 491/1000 Iteration: 3440 Train loss: 0.706215 Train acc: 0.450000\n",
      "Epoch: 492/1000 Iteration: 3445 Train loss: 0.700360 Train acc: 0.550000\n",
      "Epoch: 492/1000 Iteration: 3450 Train loss: 0.626382 Train acc: 0.750000\n",
      "Epoch: 492/1000 Iteration: 3450 Validation loss: 0.656569 Validation acc: 0.700000\n",
      "Epoch: 493/1000 Iteration: 3455 Train loss: 0.682159 Train acc: 0.600000\n",
      "Epoch: 494/1000 Iteration: 3460 Train loss: 0.709068 Train acc: 0.450000\n",
      "Epoch: 494/1000 Iteration: 3465 Train loss: 0.681258 Train acc: 0.650000\n",
      "Epoch: 495/1000 Iteration: 3470 Train loss: 0.683758 Train acc: 0.700000\n",
      "Epoch: 496/1000 Iteration: 3475 Train loss: 0.628181 Train acc: 0.600000\n",
      "Epoch: 496/1000 Iteration: 3475 Validation loss: 0.653784 Validation acc: 0.675000\n",
      "Epoch: 497/1000 Iteration: 3480 Train loss: 0.698708 Train acc: 0.500000\n",
      "Epoch: 497/1000 Iteration: 3485 Train loss: 0.630063 Train acc: 0.650000\n",
      "Epoch: 498/1000 Iteration: 3490 Train loss: 0.660330 Train acc: 0.550000\n",
      "Epoch: 499/1000 Iteration: 3495 Train loss: 0.656896 Train acc: 0.650000\n",
      "Epoch: 499/1000 Iteration: 3500 Train loss: 0.636498 Train acc: 0.700000\n",
      "Epoch: 499/1000 Iteration: 3500 Validation loss: 0.650622 Validation acc: 0.650000\n",
      "Epoch: 500/1000 Iteration: 3505 Train loss: 0.659358 Train acc: 0.450000\n",
      "Epoch: 501/1000 Iteration: 3510 Train loss: 0.642840 Train acc: 0.650000\n",
      "Epoch: 502/1000 Iteration: 3515 Train loss: 0.683570 Train acc: 0.600000\n",
      "Epoch: 502/1000 Iteration: 3520 Train loss: 0.601687 Train acc: 0.700000\n",
      "Epoch: 503/1000 Iteration: 3525 Train loss: 0.678993 Train acc: 0.450000\n",
      "Epoch: 503/1000 Iteration: 3525 Validation loss: 0.646941 Validation acc: 0.625000\n",
      "Epoch: 504/1000 Iteration: 3530 Train loss: 0.703868 Train acc: 0.550000\n",
      "Epoch: 504/1000 Iteration: 3535 Train loss: 0.651246 Train acc: 0.650000\n",
      "Epoch: 505/1000 Iteration: 3540 Train loss: 0.659963 Train acc: 0.700000\n",
      "Epoch: 506/1000 Iteration: 3545 Train loss: 0.661395 Train acc: 0.600000\n",
      "Epoch: 507/1000 Iteration: 3550 Train loss: 0.695464 Train acc: 0.550000\n",
      "Epoch: 507/1000 Iteration: 3550 Validation loss: 0.641756 Validation acc: 0.625000\n",
      "Epoch: 507/1000 Iteration: 3555 Train loss: 0.603637 Train acc: 0.800000\n",
      "Epoch: 508/1000 Iteration: 3560 Train loss: 0.690103 Train acc: 0.500000\n",
      "Epoch: 509/1000 Iteration: 3565 Train loss: 0.686833 Train acc: 0.500000\n",
      "Epoch: 509/1000 Iteration: 3570 Train loss: 0.614111 Train acc: 0.650000\n",
      "Epoch: 510/1000 Iteration: 3575 Train loss: 0.661015 Train acc: 0.750000\n",
      "Epoch: 510/1000 Iteration: 3575 Validation loss: 0.636255 Validation acc: 0.625000\n",
      "Epoch: 511/1000 Iteration: 3580 Train loss: 0.692017 Train acc: 0.650000\n",
      "Epoch: 512/1000 Iteration: 3585 Train loss: 0.658376 Train acc: 0.600000\n",
      "Epoch: 512/1000 Iteration: 3590 Train loss: 0.613577 Train acc: 0.750000\n",
      "Epoch: 513/1000 Iteration: 3595 Train loss: 0.684147 Train acc: 0.500000\n",
      "Epoch: 514/1000 Iteration: 3600 Train loss: 0.703595 Train acc: 0.550000\n",
      "Epoch: 514/1000 Iteration: 3600 Validation loss: 0.629203 Validation acc: 0.675000\n",
      "Epoch: 514/1000 Iteration: 3605 Train loss: 0.630952 Train acc: 0.550000\n",
      "Epoch: 515/1000 Iteration: 3610 Train loss: 0.640685 Train acc: 0.600000\n",
      "Epoch: 516/1000 Iteration: 3615 Train loss: 0.659280 Train acc: 0.650000\n",
      "Epoch: 517/1000 Iteration: 3620 Train loss: 0.598148 Train acc: 0.750000\n",
      "Epoch: 517/1000 Iteration: 3625 Train loss: 0.588681 Train acc: 0.750000\n",
      "Epoch: 517/1000 Iteration: 3625 Validation loss: 0.621057 Validation acc: 0.650000\n",
      "Epoch: 518/1000 Iteration: 3630 Train loss: 0.673654 Train acc: 0.700000\n",
      "Epoch: 519/1000 Iteration: 3635 Train loss: 0.701872 Train acc: 0.450000\n",
      "Epoch: 519/1000 Iteration: 3640 Train loss: 0.624247 Train acc: 0.600000\n",
      "Epoch: 520/1000 Iteration: 3645 Train loss: 0.629012 Train acc: 0.650000\n",
      "Epoch: 521/1000 Iteration: 3650 Train loss: 0.634203 Train acc: 0.550000\n",
      "Epoch: 521/1000 Iteration: 3650 Validation loss: 0.612746 Validation acc: 0.675000\n",
      "Epoch: 522/1000 Iteration: 3655 Train loss: 0.654913 Train acc: 0.650000\n",
      "Epoch: 522/1000 Iteration: 3660 Train loss: 0.608767 Train acc: 0.800000\n",
      "Epoch: 523/1000 Iteration: 3665 Train loss: 0.673624 Train acc: 0.500000\n",
      "Epoch: 524/1000 Iteration: 3670 Train loss: 0.679868 Train acc: 0.600000\n",
      "Epoch: 524/1000 Iteration: 3675 Train loss: 0.672187 Train acc: 0.700000\n",
      "Epoch: 524/1000 Iteration: 3675 Validation loss: 0.601833 Validation acc: 0.750000\n",
      "Epoch: 525/1000 Iteration: 3680 Train loss: 0.625213 Train acc: 0.700000\n",
      "Epoch: 526/1000 Iteration: 3685 Train loss: 0.643384 Train acc: 0.700000\n",
      "Epoch: 527/1000 Iteration: 3690 Train loss: 0.623514 Train acc: 0.650000\n",
      "Epoch: 527/1000 Iteration: 3695 Train loss: 0.644769 Train acc: 0.550000\n",
      "Epoch: 528/1000 Iteration: 3700 Train loss: 0.633877 Train acc: 0.700000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 528/1000 Iteration: 3700 Validation loss: 0.586234 Validation acc: 0.775000\n",
      "Epoch: 529/1000 Iteration: 3705 Train loss: 0.681452 Train acc: 0.500000\n",
      "Epoch: 529/1000 Iteration: 3710 Train loss: 0.587136 Train acc: 0.800000\n",
      "Epoch: 530/1000 Iteration: 3715 Train loss: 0.629235 Train acc: 0.700000\n",
      "Epoch: 531/1000 Iteration: 3720 Train loss: 0.570209 Train acc: 0.700000\n",
      "Epoch: 532/1000 Iteration: 3725 Train loss: 0.540114 Train acc: 0.750000\n",
      "Epoch: 532/1000 Iteration: 3725 Validation loss: 0.562434 Validation acc: 0.800000\n",
      "Epoch: 532/1000 Iteration: 3730 Train loss: 0.506902 Train acc: 0.800000\n",
      "Epoch: 533/1000 Iteration: 3735 Train loss: 0.619187 Train acc: 0.700000\n",
      "Epoch: 534/1000 Iteration: 3740 Train loss: 0.693072 Train acc: 0.550000\n",
      "Epoch: 534/1000 Iteration: 3745 Train loss: 0.591402 Train acc: 0.700000\n",
      "Epoch: 535/1000 Iteration: 3750 Train loss: 0.549504 Train acc: 0.750000\n",
      "Epoch: 535/1000 Iteration: 3750 Validation loss: 0.544998 Validation acc: 0.800000\n",
      "Epoch: 536/1000 Iteration: 3755 Train loss: 0.700508 Train acc: 0.650000\n",
      "Epoch: 537/1000 Iteration: 3760 Train loss: 0.535880 Train acc: 0.800000\n",
      "Epoch: 537/1000 Iteration: 3765 Train loss: 0.622123 Train acc: 0.650000\n",
      "Epoch: 538/1000 Iteration: 3770 Train loss: 0.542039 Train acc: 0.750000\n",
      "Epoch: 539/1000 Iteration: 3775 Train loss: 0.782529 Train acc: 0.550000\n",
      "Epoch: 539/1000 Iteration: 3775 Validation loss: 0.531378 Validation acc: 0.800000\n",
      "Epoch: 539/1000 Iteration: 3780 Train loss: 0.617476 Train acc: 0.800000\n",
      "Epoch: 540/1000 Iteration: 3785 Train loss: 0.591167 Train acc: 0.750000\n",
      "Epoch: 541/1000 Iteration: 3790 Train loss: 0.596206 Train acc: 0.650000\n",
      "Epoch: 542/1000 Iteration: 3795 Train loss: 0.468144 Train acc: 0.900000\n",
      "Epoch: 542/1000 Iteration: 3800 Train loss: 0.529035 Train acc: 0.700000\n",
      "Epoch: 542/1000 Iteration: 3800 Validation loss: 0.530994 Validation acc: 0.800000\n",
      "Epoch: 543/1000 Iteration: 3805 Train loss: 0.615111 Train acc: 0.700000\n",
      "Epoch: 544/1000 Iteration: 3810 Train loss: 0.755587 Train acc: 0.550000\n",
      "Epoch: 544/1000 Iteration: 3815 Train loss: 0.488678 Train acc: 0.800000\n",
      "Epoch: 545/1000 Iteration: 3820 Train loss: 0.595903 Train acc: 0.800000\n",
      "Epoch: 546/1000 Iteration: 3825 Train loss: 0.641434 Train acc: 0.650000\n",
      "Epoch: 546/1000 Iteration: 3825 Validation loss: 0.513413 Validation acc: 0.825000\n",
      "Epoch: 547/1000 Iteration: 3830 Train loss: 0.485391 Train acc: 0.850000\n",
      "Epoch: 547/1000 Iteration: 3835 Train loss: 0.513268 Train acc: 0.800000\n",
      "Epoch: 548/1000 Iteration: 3840 Train loss: 0.627117 Train acc: 0.750000\n",
      "Epoch: 549/1000 Iteration: 3845 Train loss: 0.784768 Train acc: 0.450000\n",
      "Epoch: 549/1000 Iteration: 3850 Train loss: 0.487080 Train acc: 0.800000\n",
      "Epoch: 549/1000 Iteration: 3850 Validation loss: 0.504943 Validation acc: 0.825000\n",
      "Epoch: 550/1000 Iteration: 3855 Train loss: 0.630390 Train acc: 0.650000\n",
      "Epoch: 551/1000 Iteration: 3860 Train loss: 0.532597 Train acc: 0.750000\n",
      "Epoch: 552/1000 Iteration: 3865 Train loss: 0.433497 Train acc: 0.900000\n",
      "Epoch: 552/1000 Iteration: 3870 Train loss: 0.557943 Train acc: 0.750000\n",
      "Epoch: 553/1000 Iteration: 3875 Train loss: 0.665236 Train acc: 0.650000\n",
      "Epoch: 553/1000 Iteration: 3875 Validation loss: 0.507917 Validation acc: 0.825000\n",
      "Epoch: 554/1000 Iteration: 3880 Train loss: 0.758241 Train acc: 0.600000\n",
      "Epoch: 554/1000 Iteration: 3885 Train loss: 0.560583 Train acc: 0.850000\n",
      "Epoch: 555/1000 Iteration: 3890 Train loss: 0.562396 Train acc: 0.750000\n",
      "Epoch: 556/1000 Iteration: 3895 Train loss: 0.590837 Train acc: 0.650000\n",
      "Epoch: 557/1000 Iteration: 3900 Train loss: 0.481387 Train acc: 0.800000\n",
      "Epoch: 557/1000 Iteration: 3900 Validation loss: 0.515166 Validation acc: 0.825000\n",
      "Epoch: 557/1000 Iteration: 3905 Train loss: 0.479707 Train acc: 0.900000\n",
      "Epoch: 558/1000 Iteration: 3910 Train loss: 0.567286 Train acc: 0.800000\n",
      "Epoch: 559/1000 Iteration: 3915 Train loss: 0.820083 Train acc: 0.450000\n",
      "Epoch: 559/1000 Iteration: 3920 Train loss: 0.514246 Train acc: 0.850000\n",
      "Epoch: 560/1000 Iteration: 3925 Train loss: 0.534750 Train acc: 0.750000\n",
      "Epoch: 560/1000 Iteration: 3925 Validation loss: 0.510068 Validation acc: 0.825000\n",
      "Epoch: 561/1000 Iteration: 3930 Train loss: 0.497919 Train acc: 0.650000\n",
      "Epoch: 562/1000 Iteration: 3935 Train loss: 0.507413 Train acc: 0.800000\n",
      "Epoch: 562/1000 Iteration: 3940 Train loss: 0.586109 Train acc: 0.750000\n",
      "Epoch: 563/1000 Iteration: 3945 Train loss: 0.717466 Train acc: 0.600000\n",
      "Epoch: 564/1000 Iteration: 3950 Train loss: 0.646685 Train acc: 0.600000\n",
      "Epoch: 564/1000 Iteration: 3950 Validation loss: 0.508465 Validation acc: 0.825000\n",
      "Epoch: 564/1000 Iteration: 3955 Train loss: 0.550580 Train acc: 0.700000\n",
      "Epoch: 565/1000 Iteration: 3960 Train loss: 0.527945 Train acc: 0.750000\n",
      "Epoch: 566/1000 Iteration: 3965 Train loss: 0.588182 Train acc: 0.650000\n",
      "Epoch: 567/1000 Iteration: 3970 Train loss: 0.442746 Train acc: 0.850000\n",
      "Epoch: 567/1000 Iteration: 3975 Train loss: 0.442575 Train acc: 0.900000\n",
      "Epoch: 567/1000 Iteration: 3975 Validation loss: 0.498936 Validation acc: 0.825000\n",
      "Epoch: 568/1000 Iteration: 3980 Train loss: 0.621251 Train acc: 0.750000\n",
      "Epoch: 569/1000 Iteration: 3985 Train loss: 0.770711 Train acc: 0.600000\n",
      "Epoch: 569/1000 Iteration: 3990 Train loss: 0.561291 Train acc: 0.750000\n",
      "Epoch: 570/1000 Iteration: 3995 Train loss: 0.556506 Train acc: 0.750000\n",
      "Epoch: 571/1000 Iteration: 4000 Train loss: 0.625898 Train acc: 0.700000\n",
      "Epoch: 571/1000 Iteration: 4000 Validation loss: 0.505782 Validation acc: 0.825000\n",
      "Epoch: 572/1000 Iteration: 4005 Train loss: 0.519110 Train acc: 0.950000\n",
      "Epoch: 572/1000 Iteration: 4010 Train loss: 0.468989 Train acc: 0.850000\n",
      "Epoch: 573/1000 Iteration: 4015 Train loss: 0.576288 Train acc: 0.800000\n",
      "Epoch: 574/1000 Iteration: 4020 Train loss: 0.768043 Train acc: 0.550000\n",
      "Epoch: 574/1000 Iteration: 4025 Train loss: 0.568029 Train acc: 0.650000\n",
      "Epoch: 574/1000 Iteration: 4025 Validation loss: 0.504567 Validation acc: 0.825000\n",
      "Epoch: 575/1000 Iteration: 4030 Train loss: 0.550520 Train acc: 0.800000\n",
      "Epoch: 576/1000 Iteration: 4035 Train loss: 0.528652 Train acc: 0.700000\n",
      "Epoch: 577/1000 Iteration: 4040 Train loss: 0.465047 Train acc: 0.900000\n",
      "Epoch: 577/1000 Iteration: 4045 Train loss: 0.540357 Train acc: 0.800000\n",
      "Epoch: 578/1000 Iteration: 4050 Train loss: 0.569608 Train acc: 0.800000\n",
      "Epoch: 578/1000 Iteration: 4050 Validation loss: 0.501725 Validation acc: 0.825000\n",
      "Epoch: 579/1000 Iteration: 4055 Train loss: 0.789022 Train acc: 0.550000\n",
      "Epoch: 579/1000 Iteration: 4060 Train loss: 0.557849 Train acc: 0.800000\n",
      "Epoch: 580/1000 Iteration: 4065 Train loss: 0.588555 Train acc: 0.700000\n",
      "Epoch: 581/1000 Iteration: 4070 Train loss: 0.567615 Train acc: 0.600000\n",
      "Epoch: 582/1000 Iteration: 4075 Train loss: 0.484229 Train acc: 0.850000\n",
      "Epoch: 582/1000 Iteration: 4075 Validation loss: 0.493307 Validation acc: 0.800000\n",
      "Epoch: 582/1000 Iteration: 4080 Train loss: 0.387612 Train acc: 0.900000\n",
      "Epoch: 583/1000 Iteration: 4085 Train loss: 0.614667 Train acc: 0.700000\n",
      "Epoch: 584/1000 Iteration: 4090 Train loss: 0.821833 Train acc: 0.450000\n",
      "Epoch: 584/1000 Iteration: 4095 Train loss: 0.435715 Train acc: 0.850000\n",
      "Epoch: 585/1000 Iteration: 4100 Train loss: 0.659252 Train acc: 0.750000\n",
      "Epoch: 585/1000 Iteration: 4100 Validation loss: 0.505028 Validation acc: 0.800000\n",
      "Epoch: 586/1000 Iteration: 4105 Train loss: 0.526348 Train acc: 0.600000\n",
      "Epoch: 587/1000 Iteration: 4110 Train loss: 0.501568 Train acc: 0.900000\n",
      "Epoch: 587/1000 Iteration: 4115 Train loss: 0.433805 Train acc: 0.800000\n",
      "Epoch: 588/1000 Iteration: 4120 Train loss: 0.543767 Train acc: 0.750000\n",
      "Epoch: 589/1000 Iteration: 4125 Train loss: 0.780005 Train acc: 0.600000\n",
      "Epoch: 589/1000 Iteration: 4125 Validation loss: 0.489906 Validation acc: 0.825000\n",
      "Epoch: 589/1000 Iteration: 4130 Train loss: 0.510358 Train acc: 0.750000\n",
      "Epoch: 590/1000 Iteration: 4135 Train loss: 0.619696 Train acc: 0.650000\n",
      "Epoch: 591/1000 Iteration: 4140 Train loss: 0.632406 Train acc: 0.700000\n",
      "Epoch: 592/1000 Iteration: 4145 Train loss: 0.450213 Train acc: 0.900000\n",
      "Epoch: 592/1000 Iteration: 4150 Train loss: 0.446990 Train acc: 0.850000\n",
      "Epoch: 592/1000 Iteration: 4150 Validation loss: 0.481807 Validation acc: 0.850000\n",
      "Epoch: 593/1000 Iteration: 4155 Train loss: 0.529871 Train acc: 0.800000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 594/1000 Iteration: 4160 Train loss: 0.788899 Train acc: 0.350000\n",
      "Epoch: 594/1000 Iteration: 4165 Train loss: 0.512258 Train acc: 0.850000\n",
      "Epoch: 595/1000 Iteration: 4170 Train loss: 0.587873 Train acc: 0.750000\n",
      "Epoch: 596/1000 Iteration: 4175 Train loss: 0.538414 Train acc: 0.750000\n",
      "Epoch: 596/1000 Iteration: 4175 Validation loss: 0.474812 Validation acc: 0.850000\n",
      "Epoch: 597/1000 Iteration: 4180 Train loss: 0.471319 Train acc: 0.850000\n",
      "Epoch: 597/1000 Iteration: 4185 Train loss: 0.453952 Train acc: 0.850000\n",
      "Epoch: 598/1000 Iteration: 4190 Train loss: 0.575558 Train acc: 0.650000\n",
      "Epoch: 599/1000 Iteration: 4195 Train loss: 0.903704 Train acc: 0.450000\n",
      "Epoch: 599/1000 Iteration: 4200 Train loss: 0.501221 Train acc: 0.850000\n",
      "Epoch: 599/1000 Iteration: 4200 Validation loss: 0.472715 Validation acc: 0.850000\n",
      "Epoch: 600/1000 Iteration: 4205 Train loss: 0.510979 Train acc: 0.750000\n",
      "Epoch: 601/1000 Iteration: 4210 Train loss: 0.735227 Train acc: 0.600000\n",
      "Epoch: 602/1000 Iteration: 4215 Train loss: 0.451472 Train acc: 0.850000\n",
      "Epoch: 602/1000 Iteration: 4220 Train loss: 0.427413 Train acc: 0.900000\n",
      "Epoch: 603/1000 Iteration: 4225 Train loss: 0.486675 Train acc: 0.800000\n",
      "Epoch: 603/1000 Iteration: 4225 Validation loss: 0.453299 Validation acc: 0.875000\n",
      "Epoch: 604/1000 Iteration: 4230 Train loss: 0.789139 Train acc: 0.450000\n",
      "Epoch: 604/1000 Iteration: 4235 Train loss: 0.439329 Train acc: 0.900000\n",
      "Epoch: 605/1000 Iteration: 4240 Train loss: 0.515498 Train acc: 0.700000\n",
      "Epoch: 606/1000 Iteration: 4245 Train loss: 0.636722 Train acc: 0.650000\n",
      "Epoch: 607/1000 Iteration: 4250 Train loss: 0.472941 Train acc: 0.900000\n",
      "Epoch: 607/1000 Iteration: 4250 Validation loss: 0.446253 Validation acc: 0.900000\n",
      "Epoch: 607/1000 Iteration: 4255 Train loss: 0.481120 Train acc: 0.800000\n",
      "Epoch: 608/1000 Iteration: 4260 Train loss: 0.545294 Train acc: 0.700000\n",
      "Epoch: 609/1000 Iteration: 4265 Train loss: 0.849336 Train acc: 0.500000\n",
      "Epoch: 609/1000 Iteration: 4270 Train loss: 0.492758 Train acc: 0.800000\n",
      "Epoch: 610/1000 Iteration: 4275 Train loss: 0.514816 Train acc: 0.800000\n",
      "Epoch: 610/1000 Iteration: 4275 Validation loss: 0.459750 Validation acc: 0.850000\n",
      "Epoch: 611/1000 Iteration: 4280 Train loss: 0.631074 Train acc: 0.700000\n",
      "Epoch: 612/1000 Iteration: 4285 Train loss: 0.452188 Train acc: 0.950000\n",
      "Epoch: 612/1000 Iteration: 4290 Train loss: 0.466727 Train acc: 0.900000\n",
      "Epoch: 613/1000 Iteration: 4295 Train loss: 0.480068 Train acc: 0.850000\n",
      "Epoch: 614/1000 Iteration: 4300 Train loss: 0.836053 Train acc: 0.450000\n",
      "Epoch: 614/1000 Iteration: 4300 Validation loss: 0.441096 Validation acc: 0.875000\n",
      "Epoch: 614/1000 Iteration: 4305 Train loss: 0.493930 Train acc: 0.800000\n",
      "Epoch: 615/1000 Iteration: 4310 Train loss: 0.455805 Train acc: 0.850000\n",
      "Epoch: 616/1000 Iteration: 4315 Train loss: 0.668862 Train acc: 0.650000\n",
      "Epoch: 617/1000 Iteration: 4320 Train loss: 0.486051 Train acc: 0.900000\n",
      "Epoch: 617/1000 Iteration: 4325 Train loss: 0.553859 Train acc: 0.850000\n",
      "Epoch: 617/1000 Iteration: 4325 Validation loss: 0.459218 Validation acc: 0.850000\n",
      "Epoch: 618/1000 Iteration: 4330 Train loss: 0.666259 Train acc: 0.650000\n",
      "Epoch: 619/1000 Iteration: 4335 Train loss: 0.849956 Train acc: 0.400000\n",
      "Epoch: 619/1000 Iteration: 4340 Train loss: 0.448209 Train acc: 0.850000\n",
      "Epoch: 620/1000 Iteration: 4345 Train loss: 0.534211 Train acc: 0.800000\n",
      "Epoch: 621/1000 Iteration: 4350 Train loss: 0.585272 Train acc: 0.750000\n",
      "Epoch: 621/1000 Iteration: 4350 Validation loss: 0.461280 Validation acc: 0.850000\n",
      "Epoch: 622/1000 Iteration: 4355 Train loss: 0.440444 Train acc: 0.800000\n",
      "Epoch: 622/1000 Iteration: 4360 Train loss: 0.491977 Train acc: 0.800000\n",
      "Epoch: 623/1000 Iteration: 4365 Train loss: 0.566150 Train acc: 0.750000\n",
      "Epoch: 624/1000 Iteration: 4370 Train loss: 0.820526 Train acc: 0.550000\n",
      "Epoch: 624/1000 Iteration: 4375 Train loss: 0.466513 Train acc: 0.900000\n",
      "Epoch: 624/1000 Iteration: 4375 Validation loss: 0.460573 Validation acc: 0.850000\n",
      "Epoch: 625/1000 Iteration: 4380 Train loss: 0.513377 Train acc: 0.750000\n",
      "Epoch: 626/1000 Iteration: 4385 Train loss: 0.683970 Train acc: 0.650000\n",
      "Epoch: 627/1000 Iteration: 4390 Train loss: 0.481253 Train acc: 0.900000\n",
      "Epoch: 627/1000 Iteration: 4395 Train loss: 0.444401 Train acc: 0.850000\n",
      "Epoch: 628/1000 Iteration: 4400 Train loss: 0.585986 Train acc: 0.750000\n",
      "Epoch: 628/1000 Iteration: 4400 Validation loss: 0.458685 Validation acc: 0.825000\n",
      "Epoch: 629/1000 Iteration: 4405 Train loss: 0.944605 Train acc: 0.450000\n",
      "Epoch: 629/1000 Iteration: 4410 Train loss: 0.410496 Train acc: 0.850000\n",
      "Epoch: 630/1000 Iteration: 4415 Train loss: 0.486626 Train acc: 0.800000\n",
      "Epoch: 631/1000 Iteration: 4420 Train loss: 0.621314 Train acc: 0.650000\n",
      "Epoch: 632/1000 Iteration: 4425 Train loss: 0.396275 Train acc: 0.950000\n",
      "Epoch: 632/1000 Iteration: 4425 Validation loss: 0.461758 Validation acc: 0.850000\n",
      "Epoch: 632/1000 Iteration: 4430 Train loss: 0.464246 Train acc: 0.850000\n",
      "Epoch: 633/1000 Iteration: 4435 Train loss: 0.570551 Train acc: 0.750000\n",
      "Epoch: 634/1000 Iteration: 4440 Train loss: 0.926938 Train acc: 0.400000\n",
      "Epoch: 634/1000 Iteration: 4445 Train loss: 0.411625 Train acc: 0.950000\n",
      "Epoch: 635/1000 Iteration: 4450 Train loss: 0.453552 Train acc: 0.850000\n",
      "Epoch: 635/1000 Iteration: 4450 Validation loss: 0.461953 Validation acc: 0.825000\n",
      "Epoch: 636/1000 Iteration: 4455 Train loss: 0.591920 Train acc: 0.700000\n",
      "Epoch: 637/1000 Iteration: 4460 Train loss: 0.475046 Train acc: 0.800000\n",
      "Epoch: 637/1000 Iteration: 4465 Train loss: 0.485764 Train acc: 0.800000\n",
      "Epoch: 638/1000 Iteration: 4470 Train loss: 0.555763 Train acc: 0.800000\n",
      "Epoch: 639/1000 Iteration: 4475 Train loss: 0.875567 Train acc: 0.500000\n",
      "Epoch: 639/1000 Iteration: 4475 Validation loss: 0.458552 Validation acc: 0.825000\n",
      "Epoch: 639/1000 Iteration: 4480 Train loss: 0.527610 Train acc: 0.800000\n",
      "Epoch: 640/1000 Iteration: 4485 Train loss: 0.498481 Train acc: 0.850000\n",
      "Epoch: 641/1000 Iteration: 4490 Train loss: 0.765759 Train acc: 0.650000\n",
      "Epoch: 642/1000 Iteration: 4495 Train loss: 0.419621 Train acc: 0.900000\n",
      "Epoch: 642/1000 Iteration: 4500 Train loss: 0.417247 Train acc: 0.800000\n",
      "Epoch: 642/1000 Iteration: 4500 Validation loss: 0.462530 Validation acc: 0.850000\n",
      "Epoch: 643/1000 Iteration: 4505 Train loss: 0.503501 Train acc: 0.750000\n",
      "Epoch: 644/1000 Iteration: 4510 Train loss: 0.961047 Train acc: 0.550000\n",
      "Epoch: 644/1000 Iteration: 4515 Train loss: 0.460798 Train acc: 0.850000\n",
      "Epoch: 645/1000 Iteration: 4520 Train loss: 0.524029 Train acc: 0.850000\n",
      "Epoch: 646/1000 Iteration: 4525 Train loss: 0.638552 Train acc: 0.650000\n",
      "Epoch: 646/1000 Iteration: 4525 Validation loss: 0.460630 Validation acc: 0.825000\n",
      "Epoch: 647/1000 Iteration: 4530 Train loss: 0.420316 Train acc: 0.900000\n",
      "Epoch: 647/1000 Iteration: 4535 Train loss: 0.562548 Train acc: 0.800000\n",
      "Epoch: 648/1000 Iteration: 4540 Train loss: 0.578638 Train acc: 0.750000\n",
      "Epoch: 649/1000 Iteration: 4545 Train loss: 0.691659 Train acc: 0.650000\n",
      "Epoch: 649/1000 Iteration: 4550 Train loss: 0.454708 Train acc: 0.950000\n",
      "Epoch: 649/1000 Iteration: 4550 Validation loss: 0.446183 Validation acc: 0.850000\n",
      "Epoch: 650/1000 Iteration: 4555 Train loss: 0.526387 Train acc: 0.750000\n",
      "Epoch: 651/1000 Iteration: 4560 Train loss: 0.630580 Train acc: 0.650000\n",
      "Epoch: 652/1000 Iteration: 4565 Train loss: 0.430413 Train acc: 0.900000\n",
      "Epoch: 652/1000 Iteration: 4570 Train loss: 0.429721 Train acc: 0.900000\n",
      "Epoch: 653/1000 Iteration: 4575 Train loss: 0.612341 Train acc: 0.750000\n",
      "Epoch: 653/1000 Iteration: 4575 Validation loss: 0.464315 Validation acc: 0.825000\n",
      "Epoch: 654/1000 Iteration: 4580 Train loss: 0.759780 Train acc: 0.450000\n",
      "Epoch: 654/1000 Iteration: 4585 Train loss: 0.395673 Train acc: 0.900000\n",
      "Epoch: 655/1000 Iteration: 4590 Train loss: 0.481494 Train acc: 0.850000\n",
      "Epoch: 656/1000 Iteration: 4595 Train loss: 0.581536 Train acc: 0.750000\n",
      "Epoch: 657/1000 Iteration: 4600 Train loss: 0.326759 Train acc: 0.900000\n",
      "Epoch: 657/1000 Iteration: 4600 Validation loss: 0.453004 Validation acc: 0.850000\n",
      "Epoch: 657/1000 Iteration: 4605 Train loss: 0.447026 Train acc: 0.850000\n",
      "Epoch: 658/1000 Iteration: 4610 Train loss: 0.514851 Train acc: 0.700000\n",
      "Epoch: 659/1000 Iteration: 4615 Train loss: 0.862360 Train acc: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 659/1000 Iteration: 4620 Train loss: 0.387891 Train acc: 0.900000\n",
      "Epoch: 660/1000 Iteration: 4625 Train loss: 0.604727 Train acc: 0.800000\n",
      "Epoch: 660/1000 Iteration: 4625 Validation loss: 0.463624 Validation acc: 0.825000\n",
      "Epoch: 661/1000 Iteration: 4630 Train loss: 0.552810 Train acc: 0.800000\n",
      "Epoch: 662/1000 Iteration: 4635 Train loss: 0.356652 Train acc: 0.950000\n",
      "Epoch: 662/1000 Iteration: 4640 Train loss: 0.418924 Train acc: 0.900000\n",
      "Epoch: 663/1000 Iteration: 4645 Train loss: 0.576648 Train acc: 0.750000\n",
      "Epoch: 664/1000 Iteration: 4650 Train loss: 0.818643 Train acc: 0.500000\n",
      "Epoch: 664/1000 Iteration: 4650 Validation loss: 0.453238 Validation acc: 0.850000\n",
      "Epoch: 664/1000 Iteration: 4655 Train loss: 0.455580 Train acc: 0.900000\n",
      "Epoch: 665/1000 Iteration: 4660 Train loss: 0.495930 Train acc: 0.850000\n",
      "Epoch: 666/1000 Iteration: 4665 Train loss: 0.707633 Train acc: 0.650000\n",
      "Epoch: 667/1000 Iteration: 4670 Train loss: 0.455787 Train acc: 0.800000\n",
      "Epoch: 667/1000 Iteration: 4675 Train loss: 0.519456 Train acc: 0.750000\n",
      "Epoch: 667/1000 Iteration: 4675 Validation loss: 0.460310 Validation acc: 0.850000\n",
      "Epoch: 668/1000 Iteration: 4680 Train loss: 0.693299 Train acc: 0.650000\n",
      "Epoch: 669/1000 Iteration: 4685 Train loss: 0.697375 Train acc: 0.500000\n",
      "Epoch: 669/1000 Iteration: 4690 Train loss: 0.513575 Train acc: 0.900000\n",
      "Epoch: 670/1000 Iteration: 4695 Train loss: 0.515842 Train acc: 0.850000\n",
      "Epoch: 671/1000 Iteration: 4700 Train loss: 0.609156 Train acc: 0.650000\n",
      "Epoch: 671/1000 Iteration: 4700 Validation loss: 0.454377 Validation acc: 0.850000\n",
      "Epoch: 672/1000 Iteration: 4705 Train loss: 0.381839 Train acc: 0.850000\n",
      "Epoch: 672/1000 Iteration: 4710 Train loss: 0.461227 Train acc: 0.850000\n",
      "Epoch: 673/1000 Iteration: 4715 Train loss: 0.599263 Train acc: 0.750000\n",
      "Epoch: 674/1000 Iteration: 4720 Train loss: 0.906890 Train acc: 0.500000\n",
      "Epoch: 674/1000 Iteration: 4725 Train loss: 0.411531 Train acc: 0.800000\n",
      "Epoch: 674/1000 Iteration: 4725 Validation loss: 0.464383 Validation acc: 0.825000\n",
      "Epoch: 675/1000 Iteration: 4730 Train loss: 0.514972 Train acc: 0.800000\n",
      "Epoch: 676/1000 Iteration: 4735 Train loss: 0.685544 Train acc: 0.650000\n",
      "Epoch: 677/1000 Iteration: 4740 Train loss: 0.293634 Train acc: 0.950000\n",
      "Epoch: 677/1000 Iteration: 4745 Train loss: 0.454729 Train acc: 0.800000\n",
      "Epoch: 678/1000 Iteration: 4750 Train loss: 0.606815 Train acc: 0.700000\n",
      "Epoch: 678/1000 Iteration: 4750 Validation loss: 0.463262 Validation acc: 0.825000\n",
      "Epoch: 679/1000 Iteration: 4755 Train loss: 0.774675 Train acc: 0.500000\n",
      "Epoch: 679/1000 Iteration: 4760 Train loss: 0.406572 Train acc: 0.900000\n",
      "Epoch: 680/1000 Iteration: 4765 Train loss: 0.454860 Train acc: 0.750000\n",
      "Epoch: 681/1000 Iteration: 4770 Train loss: 0.591158 Train acc: 0.750000\n",
      "Epoch: 682/1000 Iteration: 4775 Train loss: 0.343901 Train acc: 0.900000\n",
      "Epoch: 682/1000 Iteration: 4775 Validation loss: 0.473980 Validation acc: 0.800000\n",
      "Epoch: 682/1000 Iteration: 4780 Train loss: 0.450600 Train acc: 0.900000\n",
      "Epoch: 683/1000 Iteration: 4785 Train loss: 0.622605 Train acc: 0.800000\n",
      "Epoch: 684/1000 Iteration: 4790 Train loss: 0.793548 Train acc: 0.550000\n",
      "Epoch: 684/1000 Iteration: 4795 Train loss: 0.360672 Train acc: 0.950000\n",
      "Epoch: 685/1000 Iteration: 4800 Train loss: 0.529601 Train acc: 0.750000\n",
      "Epoch: 685/1000 Iteration: 4800 Validation loss: 0.477852 Validation acc: 0.800000\n",
      "Epoch: 686/1000 Iteration: 4805 Train loss: 0.673840 Train acc: 0.750000\n",
      "Epoch: 687/1000 Iteration: 4810 Train loss: 0.379379 Train acc: 0.900000\n",
      "Epoch: 687/1000 Iteration: 4815 Train loss: 0.490825 Train acc: 0.850000\n",
      "Epoch: 688/1000 Iteration: 4820 Train loss: 0.588202 Train acc: 0.800000\n",
      "Epoch: 689/1000 Iteration: 4825 Train loss: 0.848875 Train acc: 0.550000\n",
      "Epoch: 689/1000 Iteration: 4825 Validation loss: 0.479143 Validation acc: 0.800000\n",
      "Epoch: 689/1000 Iteration: 4830 Train loss: 0.477821 Train acc: 0.900000\n",
      "Epoch: 690/1000 Iteration: 4835 Train loss: 0.500744 Train acc: 0.850000\n",
      "Epoch: 691/1000 Iteration: 4840 Train loss: 0.513500 Train acc: 0.750000\n",
      "Epoch: 692/1000 Iteration: 4845 Train loss: 0.395707 Train acc: 0.850000\n",
      "Epoch: 692/1000 Iteration: 4850 Train loss: 0.578555 Train acc: 0.850000\n",
      "Epoch: 692/1000 Iteration: 4850 Validation loss: 0.479111 Validation acc: 0.800000\n",
      "Epoch: 693/1000 Iteration: 4855 Train loss: 0.728958 Train acc: 0.650000\n",
      "Epoch: 694/1000 Iteration: 4860 Train loss: 0.791636 Train acc: 0.550000\n",
      "Epoch: 694/1000 Iteration: 4865 Train loss: 0.396935 Train acc: 0.900000\n",
      "Epoch: 695/1000 Iteration: 4870 Train loss: 0.442254 Train acc: 0.800000\n",
      "Epoch: 696/1000 Iteration: 4875 Train loss: 0.600122 Train acc: 0.600000\n",
      "Epoch: 696/1000 Iteration: 4875 Validation loss: 0.478222 Validation acc: 0.800000\n",
      "Epoch: 697/1000 Iteration: 4880 Train loss: 0.375132 Train acc: 0.950000\n",
      "Epoch: 697/1000 Iteration: 4885 Train loss: 0.574623 Train acc: 0.800000\n",
      "Epoch: 698/1000 Iteration: 4890 Train loss: 0.661794 Train acc: 0.650000\n",
      "Epoch: 699/1000 Iteration: 4895 Train loss: 0.917806 Train acc: 0.500000\n",
      "Epoch: 699/1000 Iteration: 4900 Train loss: 0.370554 Train acc: 0.850000\n",
      "Epoch: 699/1000 Iteration: 4900 Validation loss: 0.477169 Validation acc: 0.800000\n",
      "Epoch: 700/1000 Iteration: 4905 Train loss: 0.585758 Train acc: 0.850000\n",
      "Epoch: 701/1000 Iteration: 4910 Train loss: 0.632437 Train acc: 0.650000\n",
      "Epoch: 702/1000 Iteration: 4915 Train loss: 0.372945 Train acc: 0.900000\n",
      "Epoch: 702/1000 Iteration: 4920 Train loss: 0.506586 Train acc: 0.850000\n",
      "Epoch: 703/1000 Iteration: 4925 Train loss: 0.525221 Train acc: 0.800000\n",
      "Epoch: 703/1000 Iteration: 4925 Validation loss: 0.466958 Validation acc: 0.825000\n",
      "Epoch: 704/1000 Iteration: 4930 Train loss: 0.864223 Train acc: 0.550000\n",
      "Epoch: 704/1000 Iteration: 4935 Train loss: 0.449675 Train acc: 0.850000\n",
      "Epoch: 705/1000 Iteration: 4940 Train loss: 0.481053 Train acc: 0.850000\n",
      "Epoch: 706/1000 Iteration: 4945 Train loss: 0.523214 Train acc: 0.700000\n",
      "Epoch: 707/1000 Iteration: 4950 Train loss: 0.394920 Train acc: 0.950000\n",
      "Epoch: 707/1000 Iteration: 4950 Validation loss: 0.478691 Validation acc: 0.800000\n",
      "Epoch: 707/1000 Iteration: 4955 Train loss: 0.664747 Train acc: 0.800000\n",
      "Epoch: 708/1000 Iteration: 4960 Train loss: 0.536302 Train acc: 0.750000\n",
      "Epoch: 709/1000 Iteration: 4965 Train loss: 0.837462 Train acc: 0.550000\n",
      "Epoch: 709/1000 Iteration: 4970 Train loss: 0.399209 Train acc: 1.000000\n",
      "Epoch: 710/1000 Iteration: 4975 Train loss: 0.474521 Train acc: 0.850000\n",
      "Epoch: 710/1000 Iteration: 4975 Validation loss: 0.476494 Validation acc: 0.800000\n",
      "Epoch: 711/1000 Iteration: 4980 Train loss: 0.600353 Train acc: 0.800000\n",
      "Epoch: 712/1000 Iteration: 4985 Train loss: 0.368453 Train acc: 0.950000\n",
      "Epoch: 712/1000 Iteration: 4990 Train loss: 0.567648 Train acc: 0.750000\n",
      "Epoch: 713/1000 Iteration: 4995 Train loss: 0.511315 Train acc: 0.750000\n",
      "Epoch: 714/1000 Iteration: 5000 Train loss: 0.746216 Train acc: 0.600000\n",
      "Epoch: 714/1000 Iteration: 5000 Validation loss: 0.465557 Validation acc: 0.825000\n",
      "Epoch: 714/1000 Iteration: 5005 Train loss: 0.407831 Train acc: 0.900000\n",
      "Epoch: 715/1000 Iteration: 5010 Train loss: 0.457800 Train acc: 0.850000\n",
      "Epoch: 716/1000 Iteration: 5015 Train loss: 0.726768 Train acc: 0.650000\n",
      "Epoch: 717/1000 Iteration: 5020 Train loss: 0.332981 Train acc: 0.950000\n",
      "Epoch: 717/1000 Iteration: 5025 Train loss: 0.640975 Train acc: 0.750000\n",
      "Epoch: 717/1000 Iteration: 5025 Validation loss: 0.454716 Validation acc: 0.825000\n",
      "Epoch: 718/1000 Iteration: 5030 Train loss: 0.549472 Train acc: 0.850000\n",
      "Epoch: 719/1000 Iteration: 5035 Train loss: 0.904824 Train acc: 0.450000\n",
      "Epoch: 719/1000 Iteration: 5040 Train loss: 0.418398 Train acc: 0.950000\n",
      "Epoch: 720/1000 Iteration: 5045 Train loss: 0.507880 Train acc: 0.850000\n",
      "Epoch: 721/1000 Iteration: 5050 Train loss: 0.532817 Train acc: 0.750000\n",
      "Epoch: 721/1000 Iteration: 5050 Validation loss: 0.479147 Validation acc: 0.800000\n",
      "Epoch: 722/1000 Iteration: 5055 Train loss: 0.406131 Train acc: 0.850000\n",
      "Epoch: 722/1000 Iteration: 5060 Train loss: 0.540444 Train acc: 0.800000\n",
      "Epoch: 723/1000 Iteration: 5065 Train loss: 0.493024 Train acc: 0.800000\n",
      "Epoch: 724/1000 Iteration: 5070 Train loss: 0.754957 Train acc: 0.600000\n",
      "Epoch: 724/1000 Iteration: 5075 Train loss: 0.347894 Train acc: 0.900000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 724/1000 Iteration: 5075 Validation loss: 0.478151 Validation acc: 0.800000\n",
      "Epoch: 725/1000 Iteration: 5080 Train loss: 0.519958 Train acc: 0.650000\n",
      "Epoch: 726/1000 Iteration: 5085 Train loss: 0.464320 Train acc: 0.700000\n",
      "Epoch: 727/1000 Iteration: 5090 Train loss: 0.424245 Train acc: 0.900000\n",
      "Epoch: 727/1000 Iteration: 5095 Train loss: 0.603920 Train acc: 0.800000\n",
      "Epoch: 728/1000 Iteration: 5100 Train loss: 0.576608 Train acc: 0.750000\n",
      "Epoch: 728/1000 Iteration: 5100 Validation loss: 0.461365 Validation acc: 0.825000\n",
      "Epoch: 729/1000 Iteration: 5105 Train loss: 0.909540 Train acc: 0.550000\n",
      "Epoch: 729/1000 Iteration: 5110 Train loss: 0.420695 Train acc: 0.900000\n",
      "Epoch: 730/1000 Iteration: 5115 Train loss: 0.436134 Train acc: 0.750000\n",
      "Epoch: 731/1000 Iteration: 5120 Train loss: 0.715492 Train acc: 0.650000\n",
      "Epoch: 732/1000 Iteration: 5125 Train loss: 0.417177 Train acc: 0.900000\n",
      "Epoch: 732/1000 Iteration: 5125 Validation loss: 0.461748 Validation acc: 0.825000\n",
      "Epoch: 732/1000 Iteration: 5130 Train loss: 0.460257 Train acc: 0.800000\n",
      "Epoch: 733/1000 Iteration: 5135 Train loss: 0.414369 Train acc: 0.850000\n",
      "Epoch: 734/1000 Iteration: 5140 Train loss: 0.708535 Train acc: 0.600000\n",
      "Epoch: 734/1000 Iteration: 5145 Train loss: 0.396123 Train acc: 0.900000\n",
      "Epoch: 735/1000 Iteration: 5150 Train loss: 0.476046 Train acc: 0.800000\n",
      "Epoch: 735/1000 Iteration: 5150 Validation loss: 0.459891 Validation acc: 0.825000\n",
      "Epoch: 736/1000 Iteration: 5155 Train loss: 0.419449 Train acc: 0.750000\n",
      "Epoch: 737/1000 Iteration: 5160 Train loss: 0.299871 Train acc: 0.900000\n",
      "Epoch: 737/1000 Iteration: 5165 Train loss: 0.524212 Train acc: 0.850000\n",
      "Epoch: 738/1000 Iteration: 5170 Train loss: 0.536309 Train acc: 0.850000\n",
      "Epoch: 739/1000 Iteration: 5175 Train loss: 0.795637 Train acc: 0.550000\n",
      "Epoch: 739/1000 Iteration: 5175 Validation loss: 0.471891 Validation acc: 0.800000\n",
      "Epoch: 739/1000 Iteration: 5180 Train loss: 0.429043 Train acc: 0.900000\n",
      "Epoch: 740/1000 Iteration: 5185 Train loss: 0.533206 Train acc: 0.750000\n",
      "Epoch: 741/1000 Iteration: 5190 Train loss: 0.592090 Train acc: 0.700000\n",
      "Epoch: 742/1000 Iteration: 5195 Train loss: 0.401468 Train acc: 0.900000\n",
      "Epoch: 742/1000 Iteration: 5200 Train loss: 0.489470 Train acc: 0.750000\n",
      "Epoch: 742/1000 Iteration: 5200 Validation loss: 0.468874 Validation acc: 0.800000\n",
      "Epoch: 743/1000 Iteration: 5205 Train loss: 0.543137 Train acc: 0.750000\n",
      "Epoch: 744/1000 Iteration: 5210 Train loss: 0.741371 Train acc: 0.600000\n",
      "Epoch: 744/1000 Iteration: 5215 Train loss: 0.475588 Train acc: 0.850000\n",
      "Epoch: 745/1000 Iteration: 5220 Train loss: 0.408307 Train acc: 0.800000\n",
      "Epoch: 746/1000 Iteration: 5225 Train loss: 0.530077 Train acc: 0.850000\n",
      "Epoch: 746/1000 Iteration: 5225 Validation loss: 0.465404 Validation acc: 0.825000\n",
      "Epoch: 747/1000 Iteration: 5230 Train loss: 0.329369 Train acc: 0.950000\n",
      "Epoch: 747/1000 Iteration: 5235 Train loss: 0.443224 Train acc: 0.800000\n",
      "Epoch: 748/1000 Iteration: 5240 Train loss: 0.495408 Train acc: 0.850000\n",
      "Epoch: 749/1000 Iteration: 5245 Train loss: 0.855772 Train acc: 0.550000\n",
      "Epoch: 749/1000 Iteration: 5250 Train loss: 0.464331 Train acc: 0.850000\n",
      "Epoch: 749/1000 Iteration: 5250 Validation loss: 0.465550 Validation acc: 0.800000\n",
      "Epoch: 750/1000 Iteration: 5255 Train loss: 0.534456 Train acc: 0.800000\n",
      "Epoch: 751/1000 Iteration: 5260 Train loss: 0.610347 Train acc: 0.650000\n",
      "Epoch: 752/1000 Iteration: 5265 Train loss: 0.324059 Train acc: 0.950000\n",
      "Epoch: 752/1000 Iteration: 5270 Train loss: 0.466355 Train acc: 0.800000\n",
      "Epoch: 753/1000 Iteration: 5275 Train loss: 0.433847 Train acc: 0.850000\n",
      "Epoch: 753/1000 Iteration: 5275 Validation loss: 0.457790 Validation acc: 0.825000\n",
      "Epoch: 754/1000 Iteration: 5280 Train loss: 0.759695 Train acc: 0.600000\n",
      "Epoch: 754/1000 Iteration: 5285 Train loss: 0.367501 Train acc: 0.900000\n",
      "Epoch: 755/1000 Iteration: 5290 Train loss: 0.492362 Train acc: 0.850000\n",
      "Epoch: 756/1000 Iteration: 5295 Train loss: 0.542784 Train acc: 0.800000\n",
      "Epoch: 757/1000 Iteration: 5300 Train loss: 0.431389 Train acc: 0.950000\n",
      "Epoch: 757/1000 Iteration: 5300 Validation loss: 0.456097 Validation acc: 0.825000\n",
      "Epoch: 757/1000 Iteration: 5305 Train loss: 0.609819 Train acc: 0.750000\n",
      "Epoch: 758/1000 Iteration: 5310 Train loss: 0.460896 Train acc: 0.850000\n",
      "Epoch: 759/1000 Iteration: 5315 Train loss: 0.752844 Train acc: 0.550000\n",
      "Epoch: 759/1000 Iteration: 5320 Train loss: 0.320301 Train acc: 0.950000\n",
      "Epoch: 760/1000 Iteration: 5325 Train loss: 0.497276 Train acc: 0.750000\n",
      "Epoch: 760/1000 Iteration: 5325 Validation loss: 0.460370 Validation acc: 0.825000\n",
      "Epoch: 761/1000 Iteration: 5330 Train loss: 0.511977 Train acc: 0.800000\n",
      "Epoch: 762/1000 Iteration: 5335 Train loss: 0.387868 Train acc: 0.950000\n",
      "Epoch: 762/1000 Iteration: 5340 Train loss: 0.621721 Train acc: 0.700000\n",
      "Epoch: 763/1000 Iteration: 5345 Train loss: 0.435236 Train acc: 0.800000\n",
      "Epoch: 764/1000 Iteration: 5350 Train loss: 0.869718 Train acc: 0.450000\n",
      "Epoch: 764/1000 Iteration: 5350 Validation loss: 0.455716 Validation acc: 0.825000\n",
      "Epoch: 764/1000 Iteration: 5355 Train loss: 0.387357 Train acc: 0.900000\n",
      "Epoch: 765/1000 Iteration: 5360 Train loss: 0.433102 Train acc: 0.800000\n",
      "Epoch: 766/1000 Iteration: 5365 Train loss: 0.648470 Train acc: 0.750000\n",
      "Epoch: 767/1000 Iteration: 5370 Train loss: 0.364671 Train acc: 0.900000\n",
      "Epoch: 767/1000 Iteration: 5375 Train loss: 0.530637 Train acc: 0.750000\n",
      "Epoch: 767/1000 Iteration: 5375 Validation loss: 0.460986 Validation acc: 0.825000\n",
      "Epoch: 768/1000 Iteration: 5380 Train loss: 0.487039 Train acc: 0.800000\n",
      "Epoch: 769/1000 Iteration: 5385 Train loss: 0.752770 Train acc: 0.600000\n",
      "Epoch: 769/1000 Iteration: 5390 Train loss: 0.394376 Train acc: 0.900000\n",
      "Epoch: 770/1000 Iteration: 5395 Train loss: 0.441671 Train acc: 0.850000\n",
      "Epoch: 771/1000 Iteration: 5400 Train loss: 0.523583 Train acc: 0.800000\n",
      "Epoch: 771/1000 Iteration: 5400 Validation loss: 0.460126 Validation acc: 0.825000\n",
      "Epoch: 772/1000 Iteration: 5405 Train loss: 0.331251 Train acc: 0.900000\n",
      "Epoch: 772/1000 Iteration: 5410 Train loss: 0.497262 Train acc: 0.800000\n",
      "Epoch: 773/1000 Iteration: 5415 Train loss: 0.370676 Train acc: 0.900000\n",
      "Epoch: 774/1000 Iteration: 5420 Train loss: 0.657011 Train acc: 0.600000\n",
      "Epoch: 774/1000 Iteration: 5425 Train loss: 0.474697 Train acc: 0.800000\n",
      "Epoch: 774/1000 Iteration: 5425 Validation loss: 0.453647 Validation acc: 0.825000\n",
      "Epoch: 775/1000 Iteration: 5430 Train loss: 0.548100 Train acc: 0.750000\n",
      "Epoch: 776/1000 Iteration: 5435 Train loss: 0.580083 Train acc: 0.750000\n",
      "Epoch: 777/1000 Iteration: 5440 Train loss: 0.409617 Train acc: 0.900000\n",
      "Epoch: 777/1000 Iteration: 5445 Train loss: 0.604509 Train acc: 0.800000\n",
      "Epoch: 778/1000 Iteration: 5450 Train loss: 0.455175 Train acc: 0.850000\n",
      "Epoch: 778/1000 Iteration: 5450 Validation loss: 0.457050 Validation acc: 0.825000\n",
      "Epoch: 779/1000 Iteration: 5455 Train loss: 0.706242 Train acc: 0.700000\n",
      "Epoch: 779/1000 Iteration: 5460 Train loss: 0.404466 Train acc: 0.900000\n",
      "Epoch: 780/1000 Iteration: 5465 Train loss: 0.495391 Train acc: 0.850000\n",
      "Epoch: 781/1000 Iteration: 5470 Train loss: 0.498054 Train acc: 0.850000\n",
      "Epoch: 782/1000 Iteration: 5475 Train loss: 0.449466 Train acc: 0.850000\n",
      "Epoch: 782/1000 Iteration: 5475 Validation loss: 0.455612 Validation acc: 0.825000\n",
      "Epoch: 782/1000 Iteration: 5480 Train loss: 0.541618 Train acc: 0.800000\n",
      "Epoch: 783/1000 Iteration: 5485 Train loss: 0.533040 Train acc: 0.850000\n",
      "Epoch: 784/1000 Iteration: 5490 Train loss: 0.689060 Train acc: 0.600000\n",
      "Epoch: 784/1000 Iteration: 5495 Train loss: 0.449405 Train acc: 0.900000\n",
      "Epoch: 785/1000 Iteration: 5500 Train loss: 0.437196 Train acc: 0.900000\n",
      "Epoch: 785/1000 Iteration: 5500 Validation loss: 0.448122 Validation acc: 0.825000\n",
      "Epoch: 786/1000 Iteration: 5505 Train loss: 0.572241 Train acc: 0.850000\n",
      "Epoch: 787/1000 Iteration: 5510 Train loss: 0.366199 Train acc: 0.950000\n",
      "Epoch: 787/1000 Iteration: 5515 Train loss: 0.600357 Train acc: 0.750000\n",
      "Epoch: 788/1000 Iteration: 5520 Train loss: 0.407261 Train acc: 0.850000\n",
      "Epoch: 789/1000 Iteration: 5525 Train loss: 0.809272 Train acc: 0.600000\n",
      "Epoch: 789/1000 Iteration: 5525 Validation loss: 0.441126 Validation acc: 0.850000\n",
      "Epoch: 789/1000 Iteration: 5530 Train loss: 0.384030 Train acc: 0.900000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 790/1000 Iteration: 5535 Train loss: 0.457806 Train acc: 0.850000\n",
      "Epoch: 791/1000 Iteration: 5540 Train loss: 0.562158 Train acc: 0.750000\n",
      "Epoch: 792/1000 Iteration: 5545 Train loss: 0.468510 Train acc: 0.800000\n",
      "Epoch: 792/1000 Iteration: 5550 Train loss: 0.546307 Train acc: 0.800000\n",
      "Epoch: 792/1000 Iteration: 5550 Validation loss: 0.457562 Validation acc: 0.825000\n",
      "Epoch: 793/1000 Iteration: 5555 Train loss: 0.583836 Train acc: 0.800000\n",
      "Epoch: 794/1000 Iteration: 5560 Train loss: 0.788820 Train acc: 0.600000\n",
      "Epoch: 794/1000 Iteration: 5565 Train loss: 0.452001 Train acc: 0.800000\n",
      "Epoch: 795/1000 Iteration: 5570 Train loss: 0.531718 Train acc: 0.850000\n",
      "Epoch: 796/1000 Iteration: 5575 Train loss: 0.567129 Train acc: 0.700000\n",
      "Epoch: 796/1000 Iteration: 5575 Validation loss: 0.452456 Validation acc: 0.825000\n",
      "Epoch: 797/1000 Iteration: 5580 Train loss: 0.356575 Train acc: 0.950000\n",
      "Epoch: 797/1000 Iteration: 5585 Train loss: 0.527129 Train acc: 0.800000\n",
      "Epoch: 798/1000 Iteration: 5590 Train loss: 0.470741 Train acc: 0.850000\n",
      "Epoch: 799/1000 Iteration: 5595 Train loss: 0.729305 Train acc: 0.650000\n",
      "Epoch: 799/1000 Iteration: 5600 Train loss: 0.489000 Train acc: 0.800000\n",
      "Epoch: 799/1000 Iteration: 5600 Validation loss: 0.484210 Validation acc: 0.800000\n",
      "Epoch: 800/1000 Iteration: 5605 Train loss: 0.496187 Train acc: 0.850000\n",
      "Epoch: 801/1000 Iteration: 5610 Train loss: 0.574237 Train acc: 0.750000\n",
      "Epoch: 802/1000 Iteration: 5615 Train loss: 0.406665 Train acc: 0.900000\n",
      "Epoch: 802/1000 Iteration: 5620 Train loss: 0.518680 Train acc: 0.800000\n",
      "Epoch: 803/1000 Iteration: 5625 Train loss: 0.569297 Train acc: 0.700000\n",
      "Epoch: 803/1000 Iteration: 5625 Validation loss: 0.451663 Validation acc: 0.825000\n",
      "Epoch: 804/1000 Iteration: 5630 Train loss: 0.852083 Train acc: 0.450000\n",
      "Epoch: 804/1000 Iteration: 5635 Train loss: 0.455871 Train acc: 0.850000\n",
      "Epoch: 805/1000 Iteration: 5640 Train loss: 0.498901 Train acc: 0.800000\n",
      "Epoch: 806/1000 Iteration: 5645 Train loss: 0.654037 Train acc: 0.750000\n",
      "Epoch: 807/1000 Iteration: 5650 Train loss: 0.414751 Train acc: 0.900000\n",
      "Epoch: 807/1000 Iteration: 5650 Validation loss: 0.434777 Validation acc: 0.850000\n",
      "Epoch: 807/1000 Iteration: 5655 Train loss: 0.600926 Train acc: 0.750000\n",
      "Epoch: 808/1000 Iteration: 5660 Train loss: 0.503392 Train acc: 0.800000\n",
      "Epoch: 809/1000 Iteration: 5665 Train loss: 0.608266 Train acc: 0.650000\n",
      "Epoch: 809/1000 Iteration: 5670 Train loss: 0.426616 Train acc: 0.900000\n",
      "Epoch: 810/1000 Iteration: 5675 Train loss: 0.371986 Train acc: 0.850000\n",
      "Epoch: 810/1000 Iteration: 5675 Validation loss: 0.464162 Validation acc: 0.825000\n",
      "Epoch: 811/1000 Iteration: 5680 Train loss: 0.577557 Train acc: 0.800000\n",
      "Epoch: 812/1000 Iteration: 5685 Train loss: 0.321758 Train acc: 0.950000\n",
      "Epoch: 812/1000 Iteration: 5690 Train loss: 0.640975 Train acc: 0.750000\n",
      "Epoch: 813/1000 Iteration: 5695 Train loss: 0.504538 Train acc: 0.750000\n",
      "Epoch: 814/1000 Iteration: 5700 Train loss: 0.714134 Train acc: 0.600000\n",
      "Epoch: 814/1000 Iteration: 5700 Validation loss: 0.437266 Validation acc: 0.850000\n",
      "Epoch: 814/1000 Iteration: 5705 Train loss: 0.560603 Train acc: 0.800000\n",
      "Epoch: 815/1000 Iteration: 5710 Train loss: 0.558263 Train acc: 0.800000\n",
      "Epoch: 816/1000 Iteration: 5715 Train loss: 0.427460 Train acc: 0.850000\n",
      "Epoch: 817/1000 Iteration: 5720 Train loss: 0.365368 Train acc: 0.950000\n",
      "Epoch: 817/1000 Iteration: 5725 Train loss: 0.523367 Train acc: 0.800000\n",
      "Epoch: 817/1000 Iteration: 5725 Validation loss: 0.457058 Validation acc: 0.825000\n",
      "Epoch: 818/1000 Iteration: 5730 Train loss: 0.459432 Train acc: 0.850000\n",
      "Epoch: 819/1000 Iteration: 5735 Train loss: 0.800457 Train acc: 0.550000\n",
      "Epoch: 819/1000 Iteration: 5740 Train loss: 0.426303 Train acc: 0.900000\n",
      "Epoch: 820/1000 Iteration: 5745 Train loss: 0.534618 Train acc: 0.850000\n",
      "Epoch: 821/1000 Iteration: 5750 Train loss: 0.402851 Train acc: 0.850000\n",
      "Epoch: 821/1000 Iteration: 5750 Validation loss: 0.447988 Validation acc: 0.825000\n",
      "Epoch: 822/1000 Iteration: 5755 Train loss: 0.395622 Train acc: 0.900000\n",
      "Epoch: 822/1000 Iteration: 5760 Train loss: 0.551339 Train acc: 0.800000\n",
      "Epoch: 823/1000 Iteration: 5765 Train loss: 0.412743 Train acc: 0.900000\n",
      "Epoch: 824/1000 Iteration: 5770 Train loss: 0.750307 Train acc: 0.550000\n",
      "Epoch: 824/1000 Iteration: 5775 Train loss: 0.381394 Train acc: 0.850000\n",
      "Epoch: 824/1000 Iteration: 5775 Validation loss: 0.433568 Validation acc: 0.850000\n",
      "Epoch: 825/1000 Iteration: 5780 Train loss: 0.512021 Train acc: 0.800000\n",
      "Epoch: 826/1000 Iteration: 5785 Train loss: 0.543824 Train acc: 0.750000\n",
      "Epoch: 827/1000 Iteration: 5790 Train loss: 0.403732 Train acc: 0.950000\n",
      "Epoch: 827/1000 Iteration: 5795 Train loss: 0.465082 Train acc: 0.800000\n",
      "Epoch: 828/1000 Iteration: 5800 Train loss: 0.537976 Train acc: 0.750000\n",
      "Epoch: 828/1000 Iteration: 5800 Validation loss: 0.459582 Validation acc: 0.825000\n",
      "Epoch: 829/1000 Iteration: 5805 Train loss: 0.648716 Train acc: 0.700000\n",
      "Epoch: 829/1000 Iteration: 5810 Train loss: 0.420630 Train acc: 0.800000\n",
      "Epoch: 830/1000 Iteration: 5815 Train loss: 0.434394 Train acc: 0.850000\n",
      "Epoch: 831/1000 Iteration: 5820 Train loss: 0.606192 Train acc: 0.700000\n",
      "Epoch: 832/1000 Iteration: 5825 Train loss: 0.386807 Train acc: 0.850000\n",
      "Epoch: 832/1000 Iteration: 5825 Validation loss: 0.456119 Validation acc: 0.825000\n",
      "Epoch: 832/1000 Iteration: 5830 Train loss: 0.467244 Train acc: 0.850000\n",
      "Epoch: 833/1000 Iteration: 5835 Train loss: 0.512890 Train acc: 0.800000\n",
      "Epoch: 834/1000 Iteration: 5840 Train loss: 0.684154 Train acc: 0.650000\n",
      "Epoch: 834/1000 Iteration: 5845 Train loss: 0.389875 Train acc: 0.850000\n",
      "Epoch: 835/1000 Iteration: 5850 Train loss: 0.500327 Train acc: 0.800000\n",
      "Epoch: 835/1000 Iteration: 5850 Validation loss: 0.446879 Validation acc: 0.825000\n",
      "Epoch: 836/1000 Iteration: 5855 Train loss: 0.578665 Train acc: 0.800000\n",
      "Epoch: 837/1000 Iteration: 5860 Train loss: 0.386844 Train acc: 0.950000\n",
      "Epoch: 837/1000 Iteration: 5865 Train loss: 0.442766 Train acc: 0.800000\n",
      "Epoch: 838/1000 Iteration: 5870 Train loss: 0.454111 Train acc: 0.800000\n",
      "Epoch: 839/1000 Iteration: 5875 Train loss: 0.652977 Train acc: 0.650000\n",
      "Epoch: 839/1000 Iteration: 5875 Validation loss: 0.444536 Validation acc: 0.850000\n",
      "Epoch: 839/1000 Iteration: 5880 Train loss: 0.470729 Train acc: 0.850000\n",
      "Epoch: 840/1000 Iteration: 5885 Train loss: 0.525248 Train acc: 0.800000\n",
      "Epoch: 841/1000 Iteration: 5890 Train loss: 0.632410 Train acc: 0.750000\n",
      "Epoch: 842/1000 Iteration: 5895 Train loss: 0.278385 Train acc: 0.950000\n",
      "Epoch: 842/1000 Iteration: 5900 Train loss: 0.584972 Train acc: 0.750000\n",
      "Epoch: 842/1000 Iteration: 5900 Validation loss: 0.454240 Validation acc: 0.825000\n",
      "Epoch: 843/1000 Iteration: 5905 Train loss: 0.468494 Train acc: 0.900000\n",
      "Epoch: 844/1000 Iteration: 5910 Train loss: 0.707907 Train acc: 0.600000\n",
      "Epoch: 844/1000 Iteration: 5915 Train loss: 0.437289 Train acc: 0.900000\n",
      "Epoch: 845/1000 Iteration: 5920 Train loss: 0.520012 Train acc: 0.850000\n",
      "Epoch: 846/1000 Iteration: 5925 Train loss: 0.505373 Train acc: 0.850000\n",
      "Epoch: 846/1000 Iteration: 5925 Validation loss: 0.444746 Validation acc: 0.825000\n",
      "Epoch: 847/1000 Iteration: 5930 Train loss: 0.395276 Train acc: 0.850000\n",
      "Epoch: 847/1000 Iteration: 5935 Train loss: 0.545310 Train acc: 0.800000\n",
      "Epoch: 848/1000 Iteration: 5940 Train loss: 0.518022 Train acc: 0.850000\n",
      "Epoch: 849/1000 Iteration: 5945 Train loss: 0.637430 Train acc: 0.650000\n",
      "Epoch: 849/1000 Iteration: 5950 Train loss: 0.454897 Train acc: 0.800000\n",
      "Epoch: 849/1000 Iteration: 5950 Validation loss: 0.458487 Validation acc: 0.825000\n",
      "Epoch: 850/1000 Iteration: 5955 Train loss: 0.421521 Train acc: 0.900000\n",
      "Epoch: 851/1000 Iteration: 5960 Train loss: 0.525033 Train acc: 0.850000\n",
      "Epoch: 852/1000 Iteration: 5965 Train loss: 0.350705 Train acc: 0.900000\n",
      "Epoch: 852/1000 Iteration: 5970 Train loss: 0.481017 Train acc: 0.800000\n",
      "Epoch: 853/1000 Iteration: 5975 Train loss: 0.479117 Train acc: 0.800000\n",
      "Epoch: 853/1000 Iteration: 5975 Validation loss: 0.482650 Validation acc: 0.800000\n",
      "Epoch: 854/1000 Iteration: 5980 Train loss: 0.701462 Train acc: 0.600000\n",
      "Epoch: 854/1000 Iteration: 5985 Train loss: 0.422417 Train acc: 0.900000\n",
      "Epoch: 855/1000 Iteration: 5990 Train loss: 0.462231 Train acc: 0.850000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 856/1000 Iteration: 5995 Train loss: 0.416121 Train acc: 0.800000\n",
      "Epoch: 857/1000 Iteration: 6000 Train loss: 0.305306 Train acc: 0.900000\n",
      "Epoch: 857/1000 Iteration: 6000 Validation loss: 0.429770 Validation acc: 0.850000\n",
      "Epoch: 857/1000 Iteration: 6005 Train loss: 0.680532 Train acc: 0.700000\n",
      "Epoch: 858/1000 Iteration: 6010 Train loss: 0.378238 Train acc: 0.850000\n",
      "Epoch: 859/1000 Iteration: 6015 Train loss: 0.701041 Train acc: 0.650000\n",
      "Epoch: 859/1000 Iteration: 6020 Train loss: 0.441603 Train acc: 0.850000\n",
      "Epoch: 860/1000 Iteration: 6025 Train loss: 0.354744 Train acc: 0.950000\n",
      "Epoch: 860/1000 Iteration: 6025 Validation loss: 0.446903 Validation acc: 0.825000\n",
      "Epoch: 861/1000 Iteration: 6030 Train loss: 0.577029 Train acc: 0.750000\n",
      "Epoch: 862/1000 Iteration: 6035 Train loss: 0.402092 Train acc: 0.900000\n",
      "Epoch: 862/1000 Iteration: 6040 Train loss: 0.561771 Train acc: 0.800000\n",
      "Epoch: 863/1000 Iteration: 6045 Train loss: 0.535768 Train acc: 0.800000\n",
      "Epoch: 864/1000 Iteration: 6050 Train loss: 0.757087 Train acc: 0.600000\n",
      "Epoch: 864/1000 Iteration: 6050 Validation loss: 0.432519 Validation acc: 0.850000\n",
      "Epoch: 864/1000 Iteration: 6055 Train loss: 0.471801 Train acc: 0.850000\n",
      "Epoch: 865/1000 Iteration: 6060 Train loss: 0.434328 Train acc: 0.850000\n",
      "Epoch: 866/1000 Iteration: 6065 Train loss: 0.654959 Train acc: 0.750000\n",
      "Epoch: 867/1000 Iteration: 6070 Train loss: 0.391636 Train acc: 0.900000\n",
      "Epoch: 867/1000 Iteration: 6075 Train loss: 0.564479 Train acc: 0.750000\n",
      "Epoch: 867/1000 Iteration: 6075 Validation loss: 0.432889 Validation acc: 0.850000\n",
      "Epoch: 868/1000 Iteration: 6080 Train loss: 0.539387 Train acc: 0.850000\n",
      "Epoch: 869/1000 Iteration: 6085 Train loss: 0.713827 Train acc: 0.650000\n",
      "Epoch: 869/1000 Iteration: 6090 Train loss: 0.495024 Train acc: 0.800000\n",
      "Epoch: 870/1000 Iteration: 6095 Train loss: 0.386536 Train acc: 0.850000\n",
      "Epoch: 871/1000 Iteration: 6100 Train loss: 0.621942 Train acc: 0.700000\n",
      "Epoch: 871/1000 Iteration: 6100 Validation loss: 0.431002 Validation acc: 0.850000\n",
      "Epoch: 872/1000 Iteration: 6105 Train loss: 0.400601 Train acc: 0.950000\n",
      "Epoch: 872/1000 Iteration: 6110 Train loss: 0.464003 Train acc: 0.800000\n",
      "Epoch: 873/1000 Iteration: 6115 Train loss: 0.474587 Train acc: 0.850000\n",
      "Epoch: 874/1000 Iteration: 6120 Train loss: 0.680771 Train acc: 0.650000\n",
      "Epoch: 874/1000 Iteration: 6125 Train loss: 0.481623 Train acc: 0.850000\n",
      "Epoch: 874/1000 Iteration: 6125 Validation loss: 0.433112 Validation acc: 0.850000\n",
      "Epoch: 875/1000 Iteration: 6130 Train loss: 0.578472 Train acc: 0.800000\n",
      "Epoch: 876/1000 Iteration: 6135 Train loss: 0.439341 Train acc: 0.850000\n",
      "Epoch: 877/1000 Iteration: 6140 Train loss: 0.284085 Train acc: 0.950000\n",
      "Epoch: 877/1000 Iteration: 6145 Train loss: 0.666218 Train acc: 0.800000\n",
      "Epoch: 878/1000 Iteration: 6150 Train loss: 0.522844 Train acc: 0.850000\n",
      "Epoch: 878/1000 Iteration: 6150 Validation loss: 0.433124 Validation acc: 0.850000\n",
      "Epoch: 879/1000 Iteration: 6155 Train loss: 0.776361 Train acc: 0.600000\n",
      "Epoch: 879/1000 Iteration: 6160 Train loss: 0.441431 Train acc: 0.800000\n",
      "Epoch: 880/1000 Iteration: 6165 Train loss: 0.419759 Train acc: 0.900000\n",
      "Epoch: 881/1000 Iteration: 6170 Train loss: 0.551797 Train acc: 0.750000\n",
      "Epoch: 882/1000 Iteration: 6175 Train loss: 0.371427 Train acc: 0.950000\n",
      "Epoch: 882/1000 Iteration: 6175 Validation loss: 0.440036 Validation acc: 0.850000\n",
      "Epoch: 882/1000 Iteration: 6180 Train loss: 0.635989 Train acc: 0.750000\n",
      "Epoch: 883/1000 Iteration: 6185 Train loss: 0.498794 Train acc: 0.900000\n",
      "Epoch: 884/1000 Iteration: 6190 Train loss: 0.670409 Train acc: 0.650000\n",
      "Epoch: 884/1000 Iteration: 6195 Train loss: 0.408646 Train acc: 0.900000\n",
      "Epoch: 885/1000 Iteration: 6200 Train loss: 0.443947 Train acc: 0.900000\n",
      "Epoch: 885/1000 Iteration: 6200 Validation loss: 0.447491 Validation acc: 0.825000\n",
      "Epoch: 886/1000 Iteration: 6205 Train loss: 0.528585 Train acc: 0.700000\n",
      "Epoch: 887/1000 Iteration: 6210 Train loss: 0.351820 Train acc: 0.950000\n",
      "Epoch: 887/1000 Iteration: 6215 Train loss: 0.576045 Train acc: 0.800000\n",
      "Epoch: 888/1000 Iteration: 6220 Train loss: 0.457702 Train acc: 0.850000\n",
      "Epoch: 889/1000 Iteration: 6225 Train loss: 0.637286 Train acc: 0.650000\n",
      "Epoch: 889/1000 Iteration: 6225 Validation loss: 0.431364 Validation acc: 0.850000\n",
      "Epoch: 889/1000 Iteration: 6230 Train loss: 0.344487 Train acc: 0.950000\n",
      "Epoch: 890/1000 Iteration: 6235 Train loss: 0.465810 Train acc: 0.900000\n",
      "Epoch: 891/1000 Iteration: 6240 Train loss: 0.502154 Train acc: 0.900000\n",
      "Epoch: 892/1000 Iteration: 6245 Train loss: 0.361105 Train acc: 0.850000\n",
      "Epoch: 892/1000 Iteration: 6250 Train loss: 0.526385 Train acc: 0.750000\n",
      "Epoch: 892/1000 Iteration: 6250 Validation loss: 0.482466 Validation acc: 0.800000\n",
      "Epoch: 893/1000 Iteration: 6255 Train loss: 0.522984 Train acc: 0.750000\n",
      "Epoch: 894/1000 Iteration: 6260 Train loss: 0.509091 Train acc: 0.700000\n",
      "Epoch: 894/1000 Iteration: 6265 Train loss: 0.436530 Train acc: 0.850000\n",
      "Epoch: 895/1000 Iteration: 6270 Train loss: 0.396724 Train acc: 0.900000\n",
      "Epoch: 896/1000 Iteration: 6275 Train loss: 0.443499 Train acc: 0.750000\n",
      "Epoch: 896/1000 Iteration: 6275 Validation loss: 0.430320 Validation acc: 0.850000\n",
      "Epoch: 897/1000 Iteration: 6280 Train loss: 0.356081 Train acc: 0.950000\n",
      "Epoch: 897/1000 Iteration: 6285 Train loss: 0.486266 Train acc: 0.800000\n",
      "Epoch: 898/1000 Iteration: 6290 Train loss: 0.426140 Train acc: 0.800000\n",
      "Epoch: 899/1000 Iteration: 6295 Train loss: 0.829977 Train acc: 0.650000\n",
      "Epoch: 899/1000 Iteration: 6300 Train loss: 0.308208 Train acc: 0.900000\n",
      "Epoch: 899/1000 Iteration: 6300 Validation loss: 0.476740 Validation acc: 0.800000\n",
      "Epoch: 900/1000 Iteration: 6305 Train loss: 0.467233 Train acc: 0.850000\n",
      "Epoch: 901/1000 Iteration: 6310 Train loss: 0.565419 Train acc: 0.750000\n",
      "Epoch: 902/1000 Iteration: 6315 Train loss: 0.353714 Train acc: 0.950000\n",
      "Epoch: 902/1000 Iteration: 6320 Train loss: 0.606196 Train acc: 0.700000\n",
      "Epoch: 903/1000 Iteration: 6325 Train loss: 0.454752 Train acc: 0.850000\n",
      "Epoch: 903/1000 Iteration: 6325 Validation loss: 0.429873 Validation acc: 0.850000\n",
      "Epoch: 904/1000 Iteration: 6330 Train loss: 0.828380 Train acc: 0.600000\n",
      "Epoch: 904/1000 Iteration: 6335 Train loss: 0.566418 Train acc: 0.800000\n",
      "Epoch: 905/1000 Iteration: 6340 Train loss: 0.488950 Train acc: 0.800000\n",
      "Epoch: 906/1000 Iteration: 6345 Train loss: 0.617879 Train acc: 0.750000\n",
      "Epoch: 907/1000 Iteration: 6350 Train loss: 0.451129 Train acc: 0.900000\n",
      "Epoch: 907/1000 Iteration: 6350 Validation loss: 0.431200 Validation acc: 0.850000\n",
      "Epoch: 907/1000 Iteration: 6355 Train loss: 0.580906 Train acc: 0.800000\n",
      "Epoch: 908/1000 Iteration: 6360 Train loss: 0.416311 Train acc: 0.850000\n",
      "Epoch: 909/1000 Iteration: 6365 Train loss: 0.821616 Train acc: 0.600000\n",
      "Epoch: 909/1000 Iteration: 6370 Train loss: 0.455465 Train acc: 0.950000\n",
      "Epoch: 910/1000 Iteration: 6375 Train loss: 0.477461 Train acc: 0.850000\n",
      "Epoch: 910/1000 Iteration: 6375 Validation loss: 0.440075 Validation acc: 0.850000\n",
      "Epoch: 911/1000 Iteration: 6380 Train loss: 0.471769 Train acc: 0.800000\n",
      "Epoch: 912/1000 Iteration: 6385 Train loss: 0.444755 Train acc: 0.850000\n",
      "Epoch: 912/1000 Iteration: 6390 Train loss: 0.551789 Train acc: 0.800000\n",
      "Epoch: 913/1000 Iteration: 6395 Train loss: 0.478677 Train acc: 0.850000\n",
      "Epoch: 914/1000 Iteration: 6400 Train loss: 0.635662 Train acc: 0.600000\n",
      "Epoch: 914/1000 Iteration: 6400 Validation loss: 0.435520 Validation acc: 0.850000\n",
      "Epoch: 914/1000 Iteration: 6405 Train loss: 0.418386 Train acc: 0.900000\n",
      "Epoch: 915/1000 Iteration: 6410 Train loss: 0.503489 Train acc: 0.800000\n",
      "Epoch: 916/1000 Iteration: 6415 Train loss: 0.467400 Train acc: 0.800000\n",
      "Epoch: 917/1000 Iteration: 6420 Train loss: 0.354212 Train acc: 0.900000\n",
      "Epoch: 917/1000 Iteration: 6425 Train loss: 0.418574 Train acc: 0.800000\n",
      "Epoch: 917/1000 Iteration: 6425 Validation loss: 0.447101 Validation acc: 0.825000\n",
      "Epoch: 918/1000 Iteration: 6430 Train loss: 0.539304 Train acc: 0.850000\n",
      "Epoch: 919/1000 Iteration: 6435 Train loss: 0.652997 Train acc: 0.600000\n",
      "Epoch: 919/1000 Iteration: 6440 Train loss: 0.409737 Train acc: 0.850000\n",
      "Epoch: 920/1000 Iteration: 6445 Train loss: 0.405801 Train acc: 0.850000\n",
      "Epoch: 921/1000 Iteration: 6450 Train loss: 0.367226 Train acc: 0.900000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 921/1000 Iteration: 6450 Validation loss: 0.440712 Validation acc: 0.850000\n",
      "Epoch: 922/1000 Iteration: 6455 Train loss: 0.340420 Train acc: 0.900000\n",
      "Epoch: 922/1000 Iteration: 6460 Train loss: 0.568042 Train acc: 0.750000\n",
      "Epoch: 923/1000 Iteration: 6465 Train loss: 0.413691 Train acc: 0.800000\n",
      "Epoch: 924/1000 Iteration: 6470 Train loss: 0.646679 Train acc: 0.650000\n",
      "Epoch: 924/1000 Iteration: 6475 Train loss: 0.490583 Train acc: 0.800000\n",
      "Epoch: 924/1000 Iteration: 6475 Validation loss: 0.450438 Validation acc: 0.825000\n",
      "Epoch: 925/1000 Iteration: 6480 Train loss: 0.408504 Train acc: 0.850000\n",
      "Epoch: 926/1000 Iteration: 6485 Train loss: 0.489137 Train acc: 0.850000\n",
      "Epoch: 927/1000 Iteration: 6490 Train loss: 0.373611 Train acc: 0.850000\n",
      "Epoch: 927/1000 Iteration: 6495 Train loss: 0.657671 Train acc: 0.750000\n",
      "Epoch: 928/1000 Iteration: 6500 Train loss: 0.401690 Train acc: 0.850000\n",
      "Epoch: 928/1000 Iteration: 6500 Validation loss: 0.482987 Validation acc: 0.800000\n",
      "Epoch: 929/1000 Iteration: 6505 Train loss: 0.526836 Train acc: 0.750000\n",
      "Epoch: 929/1000 Iteration: 6510 Train loss: 0.483384 Train acc: 0.850000\n",
      "Epoch: 930/1000 Iteration: 6515 Train loss: 0.546731 Train acc: 0.800000\n",
      "Epoch: 931/1000 Iteration: 6520 Train loss: 0.449342 Train acc: 0.900000\n",
      "Epoch: 932/1000 Iteration: 6525 Train loss: 0.488747 Train acc: 0.900000\n",
      "Epoch: 932/1000 Iteration: 6525 Validation loss: 0.458019 Validation acc: 0.825000\n",
      "Epoch: 932/1000 Iteration: 6530 Train loss: 0.558047 Train acc: 0.800000\n",
      "Epoch: 933/1000 Iteration: 6535 Train loss: 0.419569 Train acc: 0.850000\n",
      "Epoch: 934/1000 Iteration: 6540 Train loss: 0.674774 Train acc: 0.650000\n",
      "Epoch: 934/1000 Iteration: 6545 Train loss: 0.423673 Train acc: 0.900000\n",
      "Epoch: 935/1000 Iteration: 6550 Train loss: 0.523432 Train acc: 0.850000\n",
      "Epoch: 935/1000 Iteration: 6550 Validation loss: 0.512347 Validation acc: 0.775000\n",
      "Epoch: 936/1000 Iteration: 6555 Train loss: 0.345221 Train acc: 0.900000\n",
      "Epoch: 937/1000 Iteration: 6560 Train loss: 0.356926 Train acc: 0.850000\n",
      "Epoch: 937/1000 Iteration: 6565 Train loss: 0.606576 Train acc: 0.700000\n",
      "Epoch: 938/1000 Iteration: 6570 Train loss: 0.401610 Train acc: 0.850000\n",
      "Epoch: 939/1000 Iteration: 6575 Train loss: 0.733006 Train acc: 0.700000\n",
      "Epoch: 939/1000 Iteration: 6575 Validation loss: 0.459206 Validation acc: 0.825000\n",
      "Epoch: 939/1000 Iteration: 6580 Train loss: 0.421808 Train acc: 0.850000\n",
      "Epoch: 940/1000 Iteration: 6585 Train loss: 0.389500 Train acc: 0.900000\n",
      "Epoch: 941/1000 Iteration: 6590 Train loss: 0.386945 Train acc: 0.850000\n",
      "Epoch: 942/1000 Iteration: 6595 Train loss: 0.340181 Train acc: 0.900000\n",
      "Epoch: 942/1000 Iteration: 6600 Train loss: 0.640033 Train acc: 0.800000\n",
      "Epoch: 942/1000 Iteration: 6600 Validation loss: 0.457040 Validation acc: 0.825000\n",
      "Epoch: 943/1000 Iteration: 6605 Train loss: 0.593271 Train acc: 0.800000\n",
      "Epoch: 944/1000 Iteration: 6610 Train loss: 0.760679 Train acc: 0.700000\n",
      "Epoch: 944/1000 Iteration: 6615 Train loss: 0.325837 Train acc: 0.900000\n",
      "Epoch: 945/1000 Iteration: 6620 Train loss: 0.445717 Train acc: 0.850000\n",
      "Epoch: 946/1000 Iteration: 6625 Train loss: 0.399174 Train acc: 0.900000\n",
      "Epoch: 946/1000 Iteration: 6625 Validation loss: 0.511805 Validation acc: 0.775000\n",
      "Epoch: 947/1000 Iteration: 6630 Train loss: 0.447432 Train acc: 0.900000\n",
      "Epoch: 947/1000 Iteration: 6635 Train loss: 0.505061 Train acc: 0.800000\n",
      "Epoch: 948/1000 Iteration: 6640 Train loss: 0.377046 Train acc: 0.900000\n",
      "Epoch: 949/1000 Iteration: 6645 Train loss: 0.587068 Train acc: 0.750000\n",
      "Epoch: 949/1000 Iteration: 6650 Train loss: 0.375875 Train acc: 0.950000\n",
      "Epoch: 949/1000 Iteration: 6650 Validation loss: 0.456560 Validation acc: 0.825000\n",
      "Epoch: 950/1000 Iteration: 6655 Train loss: 0.325479 Train acc: 0.900000\n",
      "Epoch: 951/1000 Iteration: 6660 Train loss: 0.359167 Train acc: 0.900000\n",
      "Epoch: 952/1000 Iteration: 6665 Train loss: 0.309144 Train acc: 0.900000\n",
      "Epoch: 952/1000 Iteration: 6670 Train loss: 0.449928 Train acc: 0.850000\n",
      "Epoch: 953/1000 Iteration: 6675 Train loss: 0.533242 Train acc: 0.800000\n",
      "Epoch: 953/1000 Iteration: 6675 Validation loss: 0.483821 Validation acc: 0.800000\n",
      "Epoch: 954/1000 Iteration: 6680 Train loss: 0.615292 Train acc: 0.700000\n",
      "Epoch: 954/1000 Iteration: 6685 Train loss: 0.405505 Train acc: 0.800000\n",
      "Epoch: 955/1000 Iteration: 6690 Train loss: 0.414562 Train acc: 0.850000\n",
      "Epoch: 956/1000 Iteration: 6695 Train loss: 0.449324 Train acc: 0.750000\n",
      "Epoch: 957/1000 Iteration: 6700 Train loss: 0.394784 Train acc: 0.850000\n",
      "Epoch: 957/1000 Iteration: 6700 Validation loss: 0.486225 Validation acc: 0.800000\n",
      "Epoch: 957/1000 Iteration: 6705 Train loss: 0.659166 Train acc: 0.750000\n",
      "Epoch: 958/1000 Iteration: 6710 Train loss: 0.381295 Train acc: 0.900000\n",
      "Epoch: 959/1000 Iteration: 6715 Train loss: 0.516514 Train acc: 0.750000\n",
      "Epoch: 959/1000 Iteration: 6720 Train loss: 0.495373 Train acc: 0.850000\n",
      "Epoch: 960/1000 Iteration: 6725 Train loss: 0.394537 Train acc: 0.900000\n",
      "Epoch: 960/1000 Iteration: 6725 Validation loss: 0.484274 Validation acc: 0.800000\n",
      "Epoch: 961/1000 Iteration: 6730 Train loss: 0.465088 Train acc: 0.850000\n",
      "Epoch: 962/1000 Iteration: 6735 Train loss: 0.401126 Train acc: 0.900000\n",
      "Epoch: 962/1000 Iteration: 6740 Train loss: 0.594983 Train acc: 0.700000\n",
      "Epoch: 963/1000 Iteration: 6745 Train loss: 0.479125 Train acc: 0.850000\n",
      "Epoch: 964/1000 Iteration: 6750 Train loss: 0.514231 Train acc: 0.800000\n",
      "Epoch: 964/1000 Iteration: 6750 Validation loss: 0.484327 Validation acc: 0.800000\n",
      "Epoch: 964/1000 Iteration: 6755 Train loss: 0.417268 Train acc: 0.900000\n",
      "Epoch: 965/1000 Iteration: 6760 Train loss: 0.352653 Train acc: 0.900000\n",
      "Epoch: 966/1000 Iteration: 6765 Train loss: 0.385991 Train acc: 0.900000\n",
      "Epoch: 967/1000 Iteration: 6770 Train loss: 0.424688 Train acc: 0.850000\n",
      "Epoch: 967/1000 Iteration: 6775 Train loss: 0.746090 Train acc: 0.700000\n",
      "Epoch: 967/1000 Iteration: 6775 Validation loss: 0.513700 Validation acc: 0.775000\n",
      "Epoch: 968/1000 Iteration: 6780 Train loss: 0.376044 Train acc: 0.800000\n",
      "Epoch: 969/1000 Iteration: 6785 Train loss: 0.527060 Train acc: 0.800000\n",
      "Epoch: 969/1000 Iteration: 6790 Train loss: 0.329437 Train acc: 0.950000\n",
      "Epoch: 970/1000 Iteration: 6795 Train loss: 0.441096 Train acc: 0.900000\n",
      "Epoch: 971/1000 Iteration: 6800 Train loss: 0.459446 Train acc: 0.800000\n",
      "Epoch: 971/1000 Iteration: 6800 Validation loss: 0.483813 Validation acc: 0.800000\n",
      "Epoch: 972/1000 Iteration: 6805 Train loss: 0.430799 Train acc: 0.900000\n",
      "Epoch: 972/1000 Iteration: 6810 Train loss: 0.624671 Train acc: 0.700000\n",
      "Epoch: 973/1000 Iteration: 6815 Train loss: 0.384449 Train acc: 0.900000\n",
      "Epoch: 974/1000 Iteration: 6820 Train loss: 0.565243 Train acc: 0.800000\n",
      "Epoch: 974/1000 Iteration: 6825 Train loss: 0.549536 Train acc: 0.750000\n",
      "Epoch: 974/1000 Iteration: 6825 Validation loss: 0.513200 Validation acc: 0.775000\n",
      "Epoch: 975/1000 Iteration: 6830 Train loss: 0.287801 Train acc: 0.900000\n",
      "Epoch: 976/1000 Iteration: 6835 Train loss: 0.420299 Train acc: 0.850000\n",
      "Epoch: 977/1000 Iteration: 6840 Train loss: 0.443209 Train acc: 0.850000\n",
      "Epoch: 977/1000 Iteration: 6845 Train loss: 0.587261 Train acc: 0.750000\n",
      "Epoch: 978/1000 Iteration: 6850 Train loss: 0.368627 Train acc: 0.850000\n",
      "Epoch: 978/1000 Iteration: 6850 Validation loss: 0.512883 Validation acc: 0.775000\n",
      "Epoch: 979/1000 Iteration: 6855 Train loss: 0.534512 Train acc: 0.750000\n",
      "Epoch: 979/1000 Iteration: 6860 Train loss: 0.455242 Train acc: 0.850000\n",
      "Epoch: 980/1000 Iteration: 6865 Train loss: 0.312000 Train acc: 0.900000\n",
      "Epoch: 981/1000 Iteration: 6870 Train loss: 0.578138 Train acc: 0.750000\n",
      "Epoch: 982/1000 Iteration: 6875 Train loss: 0.417060 Train acc: 0.900000\n",
      "Epoch: 982/1000 Iteration: 6875 Validation loss: 0.510852 Validation acc: 0.775000\n",
      "Epoch: 982/1000 Iteration: 6880 Train loss: 0.619853 Train acc: 0.700000\n",
      "Epoch: 983/1000 Iteration: 6885 Train loss: 0.534666 Train acc: 0.850000\n",
      "Epoch: 984/1000 Iteration: 6890 Train loss: 0.583837 Train acc: 0.650000\n",
      "Epoch: 984/1000 Iteration: 6895 Train loss: 0.510699 Train acc: 0.800000\n",
      "Epoch: 985/1000 Iteration: 6900 Train loss: 0.519167 Train acc: 0.900000\n",
      "Epoch: 985/1000 Iteration: 6900 Validation loss: 0.511804 Validation acc: 0.775000\n",
      "Epoch: 986/1000 Iteration: 6905 Train loss: 0.478822 Train acc: 0.850000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 987/1000 Iteration: 6910 Train loss: 0.359298 Train acc: 0.900000\n",
      "Epoch: 987/1000 Iteration: 6915 Train loss: 0.591964 Train acc: 0.750000\n",
      "Epoch: 988/1000 Iteration: 6920 Train loss: 0.356674 Train acc: 0.900000\n",
      "Epoch: 989/1000 Iteration: 6925 Train loss: 0.627544 Train acc: 0.700000\n",
      "Epoch: 989/1000 Iteration: 6925 Validation loss: 0.511572 Validation acc: 0.775000\n",
      "Epoch: 989/1000 Iteration: 6930 Train loss: 0.436012 Train acc: 0.850000\n",
      "Epoch: 990/1000 Iteration: 6935 Train loss: 0.391373 Train acc: 0.850000\n",
      "Epoch: 991/1000 Iteration: 6940 Train loss: 0.374273 Train acc: 0.900000\n",
      "Epoch: 992/1000 Iteration: 6945 Train loss: 0.361574 Train acc: 0.900000\n",
      "Epoch: 992/1000 Iteration: 6950 Train loss: 0.595399 Train acc: 0.650000\n",
      "Epoch: 992/1000 Iteration: 6950 Validation loss: 0.510616 Validation acc: 0.775000\n",
      "Epoch: 993/1000 Iteration: 6955 Train loss: 0.416041 Train acc: 0.900000\n",
      "Epoch: 994/1000 Iteration: 6960 Train loss: 0.620485 Train acc: 0.700000\n",
      "Epoch: 994/1000 Iteration: 6965 Train loss: 0.367466 Train acc: 0.850000\n",
      "Epoch: 995/1000 Iteration: 6970 Train loss: 0.377493 Train acc: 0.900000\n",
      "Epoch: 996/1000 Iteration: 6975 Train loss: 0.425978 Train acc: 0.850000\n",
      "Epoch: 996/1000 Iteration: 6975 Validation loss: 0.511679 Validation acc: 0.775000\n",
      "Epoch: 997/1000 Iteration: 6980 Train loss: 0.313114 Train acc: 0.900000\n",
      "Epoch: 997/1000 Iteration: 6985 Train loss: 0.578578 Train acc: 0.800000\n",
      "Epoch: 998/1000 Iteration: 6990 Train loss: 0.282829 Train acc: 0.950000\n",
      "Epoch: 999/1000 Iteration: 6995 Train loss: 0.586354 Train acc: 0.750000\n",
      "Epoch: 999/1000 Iteration: 7000 Train loss: 0.383790 Train acc: 0.800000\n",
      "Epoch: 999/1000 Iteration: 7000 Validation loss: 0.511726 Validation acc: 0.775000\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e84273d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16e84273668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\har-lstm.ckpt\n",
      "Test accuracy: 0.405000\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
