{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"C:\\\\Users\\\\Daniel\\\\Desktop\\\\GSU 2018\\\\Machine Learning\\\\deep-learning-HAR\\\\data\\\\\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"C:\\\\Users\\\\Daniel\\\\Desktop\\\\GSU 2018\\\\Machine Learning\\\\deep-learning-HAR\\\\data\\\\\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-beb2a6c47616>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlstm_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m27\u001b[0m         \u001b[1;31m# 3 times the amount of channels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlstm_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m        \u001b[1;31m# Number of layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.803831 Train acc: 0.166667\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.784932 Train acc: 0.193333\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.758482 Train acc: 0.230000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.752307 Train acc: 0.233333\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.743851 Train acc: 0.233333\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.727440 Validation acc: 0.276667\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.740383 Train acc: 0.250000\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.721365 Train acc: 0.311667\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.698139 Train acc: 0.345000\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.686368 Train acc: 0.345000\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.675963 Train acc: 0.401667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.665007 Validation acc: 0.452778\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.658664 Train acc: 0.391667\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.650038 Train acc: 0.401667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.640962 Train acc: 0.440000\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.635866 Train acc: 0.416667\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.619799 Train acc: 0.416667\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.595299 Validation acc: 0.526111\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.614437 Train acc: 0.435000\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.589001 Train acc: 0.495000\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.572930 Train acc: 0.468333\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.540282 Train acc: 0.501667\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.548681 Train acc: 0.480000\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.514383 Validation acc: 0.541667\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.505494 Train acc: 0.510000\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.505729 Train acc: 0.490000\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.512593 Train acc: 0.495000\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.501491 Train acc: 0.466667\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.448405 Train acc: 0.546667\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.424219 Validation acc: 0.551111\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.470255 Train acc: 0.480000\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.436812 Train acc: 0.501667\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.408620 Train acc: 0.523333\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.393403 Train acc: 0.523333\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.371776 Train acc: 0.528333\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.333573 Validation acc: 0.557778\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.356356 Train acc: 0.535000\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.363301 Train acc: 0.521667\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.373898 Train acc: 0.505000\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.315829 Train acc: 0.548333\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.317897 Train acc: 0.525000\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.249616 Validation acc: 0.568889\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.320590 Train acc: 0.555000\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.280699 Train acc: 0.558333\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.270926 Train acc: 0.573333\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.235654 Train acc: 0.573333\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.234084 Train acc: 0.560000\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.171024 Validation acc: 0.591667\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.257823 Train acc: 0.531667\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.238605 Train acc: 0.543333\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.172633 Train acc: 0.593333\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.199611 Train acc: 0.555000\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.163281 Train acc: 0.603333\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.096037 Validation acc: 0.612222\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.137072 Train acc: 0.595000\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.149003 Train acc: 0.610000\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.122895 Train acc: 0.590000\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.121785 Train acc: 0.615000\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.108371 Train acc: 0.600000\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 1.025781 Validation acc: 0.646667\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.115656 Train acc: 0.593333\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.069113 Train acc: 0.645000\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.067733 Train acc: 0.620000\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.041262 Train acc: 0.646667\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.027955 Train acc: 0.646667\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 0.967212 Validation acc: 0.660000\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.030259 Train acc: 0.656667\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 0.981856 Train acc: 0.680000\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.053074 Train acc: 0.618333\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 1.029816 Train acc: 0.633333\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 1.059934 Train acc: 0.603333\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 0.921469 Validation acc: 0.666111\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 0.974794 Train acc: 0.681667\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 0.998084 Train acc: 0.645000\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 0.988236 Train acc: 0.653333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 0.960441 Train acc: 0.678333\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 0.962849 Train acc: 0.658333\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 0.885798 Validation acc: 0.671111\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 0.956199 Train acc: 0.660000\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 0.964750 Train acc: 0.660000\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 0.964024 Train acc: 0.630000\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 1.003473 Train acc: 0.635000\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 0.934224 Train acc: 0.671667\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 0.856833 Validation acc: 0.675000\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 0.967618 Train acc: 0.638333\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 0.933351 Train acc: 0.676667\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 0.902151 Train acc: 0.660000\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 0.878979 Train acc: 0.713333\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 0.889443 Train acc: 0.683333\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 0.832586 Validation acc: 0.679444\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 0.913224 Train acc: 0.673333\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 0.934124 Train acc: 0.636667\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 0.918704 Train acc: 0.650000\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.883652 Train acc: 0.701667\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 0.906532 Train acc: 0.661667\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.809798 Validation acc: 0.688889\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.864175 Train acc: 0.701667\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.862394 Train acc: 0.683333\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.867470 Train acc: 0.683333\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.855305 Train acc: 0.680000\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.904475 Train acc: 0.668333\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.787004 Validation acc: 0.699444\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.892778 Train acc: 0.670000\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.890308 Train acc: 0.655000\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.856609 Train acc: 0.676667\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.900955 Train acc: 0.663333\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.868931 Train acc: 0.670000\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.764438 Validation acc: 0.727778\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.816186 Train acc: 0.691667\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.822195 Train acc: 0.716667\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.825876 Train acc: 0.676667\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.854514 Train acc: 0.668333\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.830732 Train acc: 0.693333\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.743614 Validation acc: 0.741111\n",
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.866396 Train acc: 0.688333\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.809716 Train acc: 0.685000\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.835995 Train acc: 0.663333\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.806481 Train acc: 0.706667\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.824232 Train acc: 0.706667\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.722025 Validation acc: 0.755000\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.782811 Train acc: 0.716667\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.778101 Train acc: 0.725000\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.831272 Train acc: 0.678333\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.811057 Train acc: 0.681667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.820622 Train acc: 0.701667\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.704250 Validation acc: 0.762778\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.762786 Train acc: 0.726667\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.822445 Train acc: 0.691667\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.830987 Train acc: 0.680000\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.773811 Train acc: 0.715000\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.750818 Train acc: 0.720000\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.688886 Validation acc: 0.772778\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.734460 Train acc: 0.728333\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.783293 Train acc: 0.701667\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.753797 Train acc: 0.706667\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.811942 Train acc: 0.728333\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.752126 Train acc: 0.736667\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.673640 Validation acc: 0.782222\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.790455 Train acc: 0.713333\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.786672 Train acc: 0.701667\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.742575 Train acc: 0.733333\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.740316 Train acc: 0.711667\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.733726 Train acc: 0.715000\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.659653 Validation acc: 0.791667\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.767325 Train acc: 0.726667\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.745785 Train acc: 0.728333\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.769148 Train acc: 0.716667\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.717730 Train acc: 0.755000\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.773971 Train acc: 0.738333\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.641719 Validation acc: 0.801667\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.737255 Train acc: 0.721667\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.722905 Train acc: 0.746667\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.703934 Train acc: 0.755000\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.703393 Train acc: 0.751667\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.734216 Train acc: 0.736667\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.624614 Validation acc: 0.810000\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.700468 Train acc: 0.756667\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.736579 Train acc: 0.730000\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.654629 Train acc: 0.773333\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.720184 Train acc: 0.756667\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.710227 Train acc: 0.738333\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.606615 Validation acc: 0.821667\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.642168 Train acc: 0.803333\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.655247 Train acc: 0.755000\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.650592 Train acc: 0.793333\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.676706 Train acc: 0.768333\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.686847 Train acc: 0.773333\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.588455 Validation acc: 0.830555\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.685465 Train acc: 0.776667\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.626985 Train acc: 0.790000\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.692851 Train acc: 0.750000\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.667654 Train acc: 0.775000\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.644964 Train acc: 0.783333\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.569500 Validation acc: 0.838889\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.644629 Train acc: 0.781667\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.606567 Train acc: 0.808333\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.669745 Train acc: 0.771667\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.661765 Train acc: 0.783333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.649612 Train acc: 0.778333\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.547502 Validation acc: 0.847222\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.587255 Train acc: 0.803333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.659334 Train acc: 0.761667\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.617827 Train acc: 0.793333\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.611450 Train acc: 0.805000\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.583170 Train acc: 0.790000\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.529774 Validation acc: 0.853889\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.612071 Train acc: 0.780000\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.628253 Train acc: 0.796667\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.608017 Train acc: 0.813333\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.634911 Train acc: 0.793333\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.567364 Train acc: 0.818333\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.512212 Validation acc: 0.857222\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.627996 Train acc: 0.800000\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.594109 Train acc: 0.810000\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.585333 Train acc: 0.821667\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.586375 Train acc: 0.791667\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.546595 Train acc: 0.833333\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.492790 Validation acc: 0.862222\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.593653 Train acc: 0.806667\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.574055 Train acc: 0.810000\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.584734 Train acc: 0.820000\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.541554 Train acc: 0.836667\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.579525 Train acc: 0.803333\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.473631 Validation acc: 0.866111\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.565624 Train acc: 0.816667\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.524918 Train acc: 0.838333\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.516652 Train acc: 0.825000\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.525827 Train acc: 0.841667\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.551080 Train acc: 0.823333\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.455823 Validation acc: 0.869444\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.544982 Train acc: 0.815000\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.580664 Train acc: 0.786667\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.495791 Train acc: 0.836667\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.578018 Train acc: 0.808333\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.553223 Train acc: 0.826667\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.436589 Validation acc: 0.886111\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.515168 Train acc: 0.845000\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.513321 Train acc: 0.865000\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.487850 Train acc: 0.851667\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.498690 Train acc: 0.853333\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.499097 Train acc: 0.846667\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.409723 Validation acc: 0.905556\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.512922 Train acc: 0.840000\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.503618 Train acc: 0.866667\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.514251 Train acc: 0.831667\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.498786 Train acc: 0.865000\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.497711 Train acc: 0.853333\n",
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.388444 Validation acc: 0.918333\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.458802 Train acc: 0.880000\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.454915 Train acc: 0.881667\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.466565 Train acc: 0.881667\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.473386 Train acc: 0.861667\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.464545 Train acc: 0.883333\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.369888 Validation acc: 0.922778\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.398634 Train acc: 0.918333\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.494161 Train acc: 0.846667\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.462095 Train acc: 0.881667\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.444646 Train acc: 0.883333\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.413776 Train acc: 0.906667\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.346495 Validation acc: 0.927778\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.418750 Train acc: 0.873333\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.420152 Train acc: 0.898333\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.450522 Train acc: 0.881667\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.439535 Train acc: 0.885000\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.401092 Train acc: 0.908333\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.323047 Validation acc: 0.935555\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.450367 Train acc: 0.883333\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.456124 Train acc: 0.876667\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.400427 Train acc: 0.891667\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.396253 Train acc: 0.896667\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.400321 Train acc: 0.891667\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.300823 Validation acc: 0.940556\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.398419 Train acc: 0.910000\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.390706 Train acc: 0.910000\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.393111 Train acc: 0.916667\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.346999 Train acc: 0.925000\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.419034 Train acc: 0.893333\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.280655 Validation acc: 0.944444\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.363667 Train acc: 0.913333\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.372537 Train acc: 0.910000\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.358848 Train acc: 0.928333\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.332734 Train acc: 0.926667\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.374651 Train acc: 0.925000\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.261810 Validation acc: 0.946667\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.342126 Train acc: 0.926667\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.379301 Train acc: 0.915000\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.316900 Train acc: 0.926667\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.376374 Train acc: 0.900000\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.351345 Train acc: 0.916667\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.244111 Validation acc: 0.946111\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.324272 Train acc: 0.928333\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.318744 Train acc: 0.940000\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.330546 Train acc: 0.926667\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.323573 Train acc: 0.933333\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.314817 Train acc: 0.935000\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.227528 Validation acc: 0.948889\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.331548 Train acc: 0.915000\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.291324 Train acc: 0.953333\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.356041 Train acc: 0.921667\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.339341 Train acc: 0.918333\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.312652 Train acc: 0.926667\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.216210 Validation acc: 0.950000\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.308352 Train acc: 0.940000\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.283458 Train acc: 0.935000\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.297212 Train acc: 0.943333\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.317125 Train acc: 0.923333\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.309426 Train acc: 0.920000\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.204646 Validation acc: 0.951667\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.280119 Train acc: 0.938333\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.336251 Train acc: 0.913333\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.303455 Train acc: 0.921667\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.292844 Train acc: 0.928333\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.260906 Train acc: 0.960000\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.198851 Validation acc: 0.948333\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.276515 Train acc: 0.951667\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.277039 Train acc: 0.948333\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.289740 Train acc: 0.936667\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.306276 Train acc: 0.923333\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.252592 Train acc: 0.955000\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.188818 Validation acc: 0.951667\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.311617 Train acc: 0.926667\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.300064 Train acc: 0.938333\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.296687 Train acc: 0.928333\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.253947 Train acc: 0.940000\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.252516 Train acc: 0.950000\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.182070 Validation acc: 0.952222\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.255777 Train acc: 0.950000\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.267585 Train acc: 0.950000\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.286434 Train acc: 0.931667\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.238395 Train acc: 0.955000\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.296113 Train acc: 0.921667\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.177621 Validation acc: 0.950556\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.292311 Train acc: 0.938333\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.251894 Train acc: 0.945000\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.236270 Train acc: 0.953333\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.231984 Train acc: 0.950000\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.245023 Train acc: 0.948333\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.170601 Validation acc: 0.952778\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.232051 Train acc: 0.951667\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.270565 Train acc: 0.936667\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.239961 Train acc: 0.938333\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.271417 Train acc: 0.921667\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.277600 Train acc: 0.940000\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.167753 Validation acc: 0.951667\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.243038 Train acc: 0.946667\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.227638 Train acc: 0.951667\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.217577 Train acc: 0.951667\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.257813 Train acc: 0.950000\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.242761 Train acc: 0.943333\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.166116 Validation acc: 0.952778\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.257966 Train acc: 0.940000\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.223890 Train acc: 0.948333\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.269950 Train acc: 0.923333\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.271352 Train acc: 0.931667\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.231416 Train acc: 0.945000\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.157991 Validation acc: 0.953889\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.224768 Train acc: 0.946667\n",
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.237223 Train acc: 0.933333\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.230963 Train acc: 0.950000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.244250 Train acc: 0.935000\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.259608 Train acc: 0.928333\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.162136 Validation acc: 0.951111\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.203792 Train acc: 0.965000\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.273872 Train acc: 0.931667\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.243939 Train acc: 0.948333\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.227312 Train acc: 0.951667\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.198914 Train acc: 0.955000\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.158710 Validation acc: 0.951111\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.211458 Train acc: 0.956667\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.221865 Train acc: 0.955000\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.225009 Train acc: 0.948333\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.252699 Train acc: 0.931667\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.197091 Train acc: 0.965000\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.156559 Validation acc: 0.951111\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.259112 Train acc: 0.938333\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.233606 Train acc: 0.941667\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.213837 Train acc: 0.956667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.198758 Train acc: 0.953333\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.200103 Train acc: 0.958333\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.151488 Validation acc: 0.951667\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.215429 Train acc: 0.950000\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.225079 Train acc: 0.945000\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.240935 Train acc: 0.935000\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.178765 Train acc: 0.961667\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.248632 Train acc: 0.936667\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.147081 Validation acc: 0.953889\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.253412 Train acc: 0.933333\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.209557 Train acc: 0.938333\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.202615 Train acc: 0.960000\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.214099 Train acc: 0.941667\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.212324 Train acc: 0.950000\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.147096 Validation acc: 0.953889\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.220035 Train acc: 0.940000\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.224695 Train acc: 0.946667\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.184313 Train acc: 0.961667\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.234504 Train acc: 0.923333\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.244250 Train acc: 0.941667\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.146616 Validation acc: 0.951667\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.203896 Train acc: 0.951667\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.184240 Train acc: 0.961667\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.197710 Train acc: 0.955000\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.204828 Train acc: 0.945000\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.216921 Train acc: 0.940000\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.147400 Validation acc: 0.953889\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.220769 Train acc: 0.935000\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.175720 Train acc: 0.958333\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.240511 Train acc: 0.930000\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.234182 Train acc: 0.941667\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.194592 Train acc: 0.946667\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.143956 Validation acc: 0.951111\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.187997 Train acc: 0.956667\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.185314 Train acc: 0.956667\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.201611 Train acc: 0.961667\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.206748 Train acc: 0.956667\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.229731 Train acc: 0.933333\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.140177 Validation acc: 0.951667\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.174305 Train acc: 0.958333\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.234275 Train acc: 0.923333\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.230622 Train acc: 0.941667\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.191881 Train acc: 0.956667\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.201501 Train acc: 0.945000\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.141614 Validation acc: 0.953333\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.200466 Train acc: 0.948333\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.178482 Train acc: 0.960000\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.184700 Train acc: 0.956667\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.230693 Train acc: 0.935000\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.191172 Train acc: 0.960000\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.140396 Validation acc: 0.953333\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.231683 Train acc: 0.933333\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.217484 Train acc: 0.941667\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.190467 Train acc: 0.951667\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.198838 Train acc: 0.948333\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.174044 Train acc: 0.960000\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.136745 Validation acc: 0.952778\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.176856 Train acc: 0.956667\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.188860 Train acc: 0.963333\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.220903 Train acc: 0.935000\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.172579 Train acc: 0.963333\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.219729 Train acc: 0.930000\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.138968 Validation acc: 0.952222\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.213574 Train acc: 0.946667\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.182027 Train acc: 0.951667\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.194359 Train acc: 0.958333\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.179224 Train acc: 0.950000\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.179271 Train acc: 0.961667\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.139633 Validation acc: 0.951111\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.193303 Train acc: 0.948333\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.211768 Train acc: 0.940000\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.175041 Train acc: 0.960000\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.224524 Train acc: 0.928333\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.205938 Train acc: 0.941667\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.132476 Validation acc: 0.955000\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.178813 Train acc: 0.945000\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.185449 Train acc: 0.946667\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.181401 Train acc: 0.946667\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.165570 Train acc: 0.961667\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.173669 Train acc: 0.953333\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.132518 Validation acc: 0.952222\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.200340 Train acc: 0.948333\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.148870 Train acc: 0.961667\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.213636 Train acc: 0.931667\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.210088 Train acc: 0.941667\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.176620 Train acc: 0.953333\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.135383 Validation acc: 0.951667\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.179739 Train acc: 0.950000\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.177233 Train acc: 0.946667\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.174242 Train acc: 0.963333\n",
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.182180 Train acc: 0.948333\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.212476 Train acc: 0.941667\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.133427 Validation acc: 0.951667\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.160245 Train acc: 0.956667\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.223532 Train acc: 0.935000\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.207931 Train acc: 0.943333\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.177958 Train acc: 0.953333\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.192461 Train acc: 0.950000\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.135206 Validation acc: 0.953333\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.180456 Train acc: 0.953333\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.183939 Train acc: 0.953333\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.170558 Train acc: 0.955000\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.198872 Train acc: 0.940000\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.152981 Train acc: 0.960000\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.126645 Validation acc: 0.955000\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.221610 Train acc: 0.925000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.185413 Train acc: 0.953333\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.181103 Train acc: 0.950000\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.169436 Train acc: 0.953333\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.173279 Train acc: 0.953333\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.129084 Validation acc: 0.953889\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.170493 Train acc: 0.958333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.176567 Train acc: 0.956667\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.210796 Train acc: 0.941667\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.142151 Train acc: 0.970000\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.225752 Train acc: 0.931667\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.126029 Validation acc: 0.954444\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.187326 Train acc: 0.951667\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.163084 Train acc: 0.958333\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.173868 Train acc: 0.958333\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.170593 Train acc: 0.955000\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.180057 Train acc: 0.955000\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.125273 Validation acc: 0.953889\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.175242 Train acc: 0.946667\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.215847 Train acc: 0.940000\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.134507 Train acc: 0.970000\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.214005 Train acc: 0.925000\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.193888 Train acc: 0.950000\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.125148 Validation acc: 0.954444\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.166519 Train acc: 0.950000\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.168848 Train acc: 0.956667\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.144940 Train acc: 0.958333\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.170154 Train acc: 0.965000\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.176806 Train acc: 0.953333\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.127929 Validation acc: 0.955000\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.181805 Train acc: 0.941667\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.151650 Train acc: 0.963333\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.198796 Train acc: 0.936667\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.186751 Train acc: 0.948333\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.164216 Train acc: 0.956667\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.124079 Validation acc: 0.955556\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.157086 Train acc: 0.950000\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.152086 Train acc: 0.961667\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.171572 Train acc: 0.955000\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.168039 Train acc: 0.948333\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.182738 Train acc: 0.941667\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.124386 Validation acc: 0.955556\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.146030 Train acc: 0.966667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.204687 Train acc: 0.935000\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.175041 Train acc: 0.945000\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.161099 Train acc: 0.951667\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.183559 Train acc: 0.943333\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.132357 Validation acc: 0.952222\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.154438 Train acc: 0.955000\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.154004 Train acc: 0.956667\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.176015 Train acc: 0.955000\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.185151 Train acc: 0.938333\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.140427 Train acc: 0.963333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.129250 Validation acc: 0.952778\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.204724 Train acc: 0.930000\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.179889 Train acc: 0.948333\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.155989 Train acc: 0.958333\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.158251 Train acc: 0.965000\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.141252 Train acc: 0.958333\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.123336 Validation acc: 0.957222\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.161994 Train acc: 0.958333\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.178567 Train acc: 0.951667\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.191705 Train acc: 0.940000\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.140421 Train acc: 0.958333\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.187229 Train acc: 0.950000\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.122181 Validation acc: 0.953889\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.188384 Train acc: 0.948333\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.161386 Train acc: 0.951667\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.158202 Train acc: 0.951667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.149034 Train acc: 0.955000\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.165605 Train acc: 0.956667\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.123932 Validation acc: 0.953333\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.169346 Train acc: 0.960000\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.176740 Train acc: 0.938333\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.150113 Train acc: 0.958333\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.189122 Train acc: 0.933333\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.176120 Train acc: 0.948333\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.119356 Validation acc: 0.955556\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.147471 Train acc: 0.961667\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.141806 Train acc: 0.958333\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.141309 Train acc: 0.946667\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.161225 Train acc: 0.960000\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.170966 Train acc: 0.956667\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.117410 Validation acc: 0.954444\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.167956 Train acc: 0.950000\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.141069 Train acc: 0.966667\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.179567 Train acc: 0.935000\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.193529 Train acc: 0.938333\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.161298 Train acc: 0.951667\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.119512 Validation acc: 0.955555\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.148505 Train acc: 0.960000\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.148844 Train acc: 0.956667\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.151069 Train acc: 0.946667\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.159255 Train acc: 0.955000\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.168922 Train acc: 0.948333\n",
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.122482 Validation acc: 0.954444\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.136530 Train acc: 0.963333\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.197965 Train acc: 0.931667\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.167877 Train acc: 0.960000\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.165181 Train acc: 0.953333\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.149850 Train acc: 0.951667\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.120850 Validation acc: 0.954444\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.149268 Train acc: 0.958333\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.162336 Train acc: 0.958333\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.168752 Train acc: 0.951667\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.171935 Train acc: 0.946667\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.131431 Train acc: 0.966667\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.131672 Validation acc: 0.953333\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.192293 Train acc: 0.936667\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.185634 Train acc: 0.951667\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.157558 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.152200 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.152421 Train acc: 0.955000\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.128340 Validation acc: 0.952778\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.144837 Train acc: 0.963333\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.161802 Train acc: 0.955000\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.168167 Train acc: 0.948333\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.129223 Train acc: 0.961667\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.183376 Train acc: 0.938333\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.125278 Validation acc: 0.953889\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.181172 Train acc: 0.943333\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.146559 Train acc: 0.955000\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.131012 Train acc: 0.973333\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.156784 Train acc: 0.955000\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.131279 Train acc: 0.968333\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.126230 Validation acc: 0.953333\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.162465 Train acc: 0.951667\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.180664 Train acc: 0.938333\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.133714 Train acc: 0.970000\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.181977 Train acc: 0.926667\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.175414 Train acc: 0.940000\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.117302 Validation acc: 0.955000\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.142660 Train acc: 0.953333\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.145192 Train acc: 0.953333\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.142711 Train acc: 0.946667\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.150780 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.143253 Train acc: 0.960000\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.125537 Validation acc: 0.953333\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.165160 Train acc: 0.955000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.126421 Train acc: 0.956667\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.178273 Train acc: 0.938333\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.158854 Train acc: 0.948333\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.143273 Train acc: 0.951667\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.119258 Validation acc: 0.953333\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.148877 Train acc: 0.956667\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.140717 Train acc: 0.955000\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.150460 Train acc: 0.956667\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.145724 Train acc: 0.961667\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.159386 Train acc: 0.951667\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.121914 Validation acc: 0.954444\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.135636 Train acc: 0.963333\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.178287 Train acc: 0.936667\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.173185 Train acc: 0.943333\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.145589 Train acc: 0.958333\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.149135 Train acc: 0.950000\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.122381 Validation acc: 0.953889\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.144995 Train acc: 0.956667\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.144450 Train acc: 0.965000\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.152919 Train acc: 0.960000\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.167184 Train acc: 0.941667\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.131993 Train acc: 0.966667\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.115491 Validation acc: 0.955000\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.185762 Train acc: 0.935000\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.158649 Train acc: 0.951667\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.154774 Train acc: 0.943333\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.135115 Train acc: 0.963333\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.132217 Train acc: 0.960000\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.116467 Validation acc: 0.954444\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.163472 Train acc: 0.965000\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.172247 Train acc: 0.951667\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.161473 Train acc: 0.948333\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.132992 Train acc: 0.963333\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.203330 Train acc: 0.933333\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.117126 Validation acc: 0.953889\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.159267 Train acc: 0.956667\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.139557 Train acc: 0.955000\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.133644 Train acc: 0.956667\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.148205 Train acc: 0.948333\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.125568 Train acc: 0.963333\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.117660 Validation acc: 0.954444\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.147141 Train acc: 0.961667\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.172824 Train acc: 0.948333\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.127000 Train acc: 0.968333\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.159670 Train acc: 0.945000\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.171025 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.122248 Validation acc: 0.953889\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.137238 Train acc: 0.953333\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.126829 Train acc: 0.965000\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.156080 Train acc: 0.945000\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.142915 Train acc: 0.963333\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.143964 Train acc: 0.956667\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.121918 Validation acc: 0.957778\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.166120 Train acc: 0.943333\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.111748 Train acc: 0.970000\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.178235 Train acc: 0.935000\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.183130 Train acc: 0.941667\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.149348 Train acc: 0.951667\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.128673 Validation acc: 0.953889\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.143559 Train acc: 0.956667\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.134587 Train acc: 0.960000\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.135107 Train acc: 0.956667\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.143676 Train acc: 0.955000\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.181485 Train acc: 0.931667\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.120886 Validation acc: 0.954444\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.117319 Train acc: 0.975000\n",
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.172147 Train acc: 0.945000\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.163532 Train acc: 0.951667\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.131608 Train acc: 0.955000\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.141363 Train acc: 0.960000\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.122871 Validation acc: 0.953889\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.136435 Train acc: 0.951667\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.131892 Train acc: 0.956667\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.154267 Train acc: 0.958333\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.157119 Train acc: 0.951667\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.123280 Train acc: 0.966667\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.118823 Validation acc: 0.956667\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.163332 Train acc: 0.938333\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.163951 Train acc: 0.948333\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.156129 Train acc: 0.951667\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.130177 Train acc: 0.961667\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.138887 Train acc: 0.956667\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.119853 Validation acc: 0.955555\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.143056 Train acc: 0.961667\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.144240 Train acc: 0.958333\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.152647 Train acc: 0.948333\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.106498 Train acc: 0.976667\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.154777 Train acc: 0.946667\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.119775 Validation acc: 0.953889\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.158444 Train acc: 0.950000\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.125508 Train acc: 0.963333\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.126002 Train acc: 0.963333\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.129739 Train acc: 0.963333\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.129735 Train acc: 0.965000\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.121193 Validation acc: 0.953333\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.133288 Train acc: 0.956667\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.167120 Train acc: 0.950000\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.124095 Train acc: 0.970000\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.180680 Train acc: 0.933333\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.166001 Train acc: 0.946667\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.121673 Validation acc: 0.953889\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.135722 Train acc: 0.951667\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.155242 Train acc: 0.945000\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.136104 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.146934 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.155560 Train acc: 0.955000\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.119894 Validation acc: 0.956111\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.174404 Train acc: 0.933333\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.124455 Train acc: 0.965000\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.180249 Train acc: 0.933333\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.164679 Train acc: 0.945000\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.148775 Train acc: 0.943333\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.122515 Validation acc: 0.952222\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.129220 Train acc: 0.961667\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.121206 Train acc: 0.948333\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.141361 Train acc: 0.963333\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.138645 Train acc: 0.955000\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.155476 Train acc: 0.953333\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.123422 Validation acc: 0.955556\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.126490 Train acc: 0.970000\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.171991 Train acc: 0.935000\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.165648 Train acc: 0.950000\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.134511 Train acc: 0.950000\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.135902 Train acc: 0.960000\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.120749 Validation acc: 0.955000\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.132724 Train acc: 0.951667\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.129373 Train acc: 0.965000\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.128768 Train acc: 0.953333\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.143187 Train acc: 0.955000\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.122006 Train acc: 0.958333\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.125500 Validation acc: 0.954444\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.174812 Train acc: 0.930000\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.155588 Train acc: 0.950000\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.134083 Train acc: 0.960000\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.118403 Train acc: 0.965000\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.136828 Train acc: 0.953333\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.121961 Validation acc: 0.952778\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.140672 Train acc: 0.958333\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.136352 Train acc: 0.956667\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.141014 Train acc: 0.946667\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.115449 Train acc: 0.970000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.154944 Train acc: 0.940000\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.127648 Validation acc: 0.953889\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.172205 Train acc: 0.936667\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.118066 Train acc: 0.970000\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.133222 Train acc: 0.958333\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.125062 Train acc: 0.955000\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.125002 Train acc: 0.961667\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.134884 Validation acc: 0.953333\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.138182 Train acc: 0.960000\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.146840 Train acc: 0.948333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.114800 Train acc: 0.965000\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.165093 Train acc: 0.943333\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.154050 Train acc: 0.943333\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.122382 Validation acc: 0.955556\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.132866 Train acc: 0.956667\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.136614 Train acc: 0.950000\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.128238 Train acc: 0.953333\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.149496 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.143019 Train acc: 0.958333\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.121529 Validation acc: 0.953889\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.145728 Train acc: 0.953333\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.110476 Train acc: 0.970000\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.158991 Train acc: 0.938333\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.152357 Train acc: 0.951667\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.134092 Train acc: 0.946667\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.122518 Validation acc: 0.955555\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.124859 Train acc: 0.968333\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.128173 Train acc: 0.960000\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.125600 Train acc: 0.968333\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.138233 Train acc: 0.960000\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.141553 Train acc: 0.956667\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.121072 Validation acc: 0.954444\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.110049 Train acc: 0.970000\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.156274 Train acc: 0.945000\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.153792 Train acc: 0.945000\n",
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.126035 Train acc: 0.956667\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.119313 Train acc: 0.966667\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.120060 Validation acc: 0.955555\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.124896 Train acc: 0.956667\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.129335 Train acc: 0.955000\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.142225 Train acc: 0.961667\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.155911 Train acc: 0.946667\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.113464 Train acc: 0.971667\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.121681 Validation acc: 0.956111\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.161537 Train acc: 0.936667\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.147688 Train acc: 0.953333\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.130375 Train acc: 0.950000\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.117306 Train acc: 0.960000\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.123532 Train acc: 0.960000\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.119933 Validation acc: 0.955000\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.127067 Train acc: 0.963333\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.148644 Train acc: 0.961667\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.138347 Train acc: 0.941667\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.123834 Train acc: 0.956667\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.168878 Train acc: 0.936667\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.123065 Validation acc: 0.955000\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.137118 Train acc: 0.955000\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.133703 Train acc: 0.956667\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.117310 Train acc: 0.961667\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.133157 Train acc: 0.956667\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.129492 Train acc: 0.966667\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.121761 Validation acc: 0.956111\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.143282 Train acc: 0.951667\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.153672 Train acc: 0.940000\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.111234 Train acc: 0.961667\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.155540 Train acc: 0.940000\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.139238 Train acc: 0.956667\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.119389 Validation acc: 0.958333\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.119746 Train acc: 0.958333\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.130436 Train acc: 0.955000\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.130878 Train acc: 0.951667\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.134407 Train acc: 0.961667\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.128549 Train acc: 0.963333\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.120930 Validation acc: 0.955000\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.147487 Train acc: 0.943333\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.101505 Train acc: 0.970000\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.165579 Train acc: 0.938333\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.146195 Train acc: 0.948333\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.123704 Train acc: 0.951667\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.120137 Validation acc: 0.955555\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.128029 Train acc: 0.955000\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.116810 Train acc: 0.960000\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.124469 Train acc: 0.970000\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.135921 Train acc: 0.960000\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.143182 Train acc: 0.950000\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.122872 Validation acc: 0.957222\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.097659 Train acc: 0.965000\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.161403 Train acc: 0.941667\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.137068 Train acc: 0.948333\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.116802 Train acc: 0.955000\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.119676 Train acc: 0.956667\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.125110 Validation acc: 0.955556\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.120233 Train acc: 0.956667\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.131875 Train acc: 0.968333\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.138825 Train acc: 0.953333\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.148941 Train acc: 0.941667\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.099968 Train acc: 0.970000\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.119400 Validation acc: 0.958333\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.160745 Train acc: 0.936667\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.153947 Train acc: 0.951667\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.115642 Train acc: 0.955000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.123676 Train acc: 0.960000\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.124494 Train acc: 0.956667\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.124492 Validation acc: 0.957222\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.125867 Train acc: 0.963333\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.136220 Train acc: 0.955000\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.136421 Train acc: 0.955000\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.110389 Train acc: 0.965000\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.156209 Train acc: 0.938333\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.122014 Validation acc: 0.956667\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.144914 Train acc: 0.955000\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.130381 Train acc: 0.948333\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.113156 Train acc: 0.955000\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.112849 Train acc: 0.966667\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.130117 Train acc: 0.961667\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.118426 Validation acc: 0.956667\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.127763 Train acc: 0.956667\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.142876 Train acc: 0.948333\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.098803 Train acc: 0.966667\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.156269 Train acc: 0.941667\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.137492 Train acc: 0.946667\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.123495 Validation acc: 0.954444\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.126383 Train acc: 0.965000\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.110208 Train acc: 0.961667\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.130677 Train acc: 0.955000\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.128448 Train acc: 0.966667\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.123346 Train acc: 0.956667\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.121541 Validation acc: 0.956111\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.144809 Train acc: 0.946667\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.111561 Train acc: 0.961667\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.145497 Train acc: 0.935000\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.144208 Train acc: 0.951667\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.117203 Train acc: 0.958333\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.124285 Validation acc: 0.955556\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.115381 Train acc: 0.963333\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.118327 Train acc: 0.965000\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.124463 Train acc: 0.960000\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.140883 Train acc: 0.948333\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.162978 Train acc: 0.940000\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.117640 Validation acc: 0.957778\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.112746 Train acc: 0.956667\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.156102 Train acc: 0.928333\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.150121 Train acc: 0.948333\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.132952 Train acc: 0.948333\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.122923 Train acc: 0.970000\n",
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.119028 Validation acc: 0.957778\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.109834 Train acc: 0.965000\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.135306 Train acc: 0.951667\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.125824 Train acc: 0.961667\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.137122 Train acc: 0.953333\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.099990 Train acc: 0.968333\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.120584 Validation acc: 0.955000\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.153222 Train acc: 0.933333\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.140065 Train acc: 0.951667\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.116502 Train acc: 0.958333\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.117714 Train acc: 0.951667\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.126588 Train acc: 0.955000\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.126105 Validation acc: 0.957222\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.142623 Train acc: 0.956667\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.144437 Train acc: 0.946667\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.162059 Train acc: 0.925000\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.111671 Train acc: 0.965000\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.147507 Train acc: 0.941667\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.120478 Validation acc: 0.955000\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.146845 Train acc: 0.941667\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.119955 Train acc: 0.951667\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.125701 Train acc: 0.956667\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.113246 Train acc: 0.963333\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.126984 Train acc: 0.953333\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.122610 Validation acc: 0.957222\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.114434 Train acc: 0.963333\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.147151 Train acc: 0.945000\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.096754 Train acc: 0.973333\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.154265 Train acc: 0.945000\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.167849 Train acc: 0.950000\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.125509 Validation acc: 0.956667\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.132734 Train acc: 0.948333\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.114201 Train acc: 0.953333\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.132739 Train acc: 0.956667\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.126198 Train acc: 0.966667\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.144468 Train acc: 0.948333\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.117060 Validation acc: 0.958333\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.141268 Train acc: 0.951667\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.107378 Train acc: 0.968333\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.166698 Train acc: 0.935000\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.145760 Train acc: 0.956667\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.101929 Train acc: 0.966667\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.127123 Validation acc: 0.956111\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.117337 Train acc: 0.965000\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.120538 Train acc: 0.958333\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.124991 Train acc: 0.961667\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.131020 Train acc: 0.955000\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.139879 Train acc: 0.946667\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.115656 Validation acc: 0.956111\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.094585 Train acc: 0.971667\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.143638 Train acc: 0.950000\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.139546 Train acc: 0.961667\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.112885 Train acc: 0.960000\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.110888 Train acc: 0.960000\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.109547 Validation acc: 0.957778\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.125691 Train acc: 0.956667\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.122798 Train acc: 0.960000\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.110198 Train acc: 0.960000\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.136698 Train acc: 0.940000\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.097974 Train acc: 0.968333\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.113181 Validation acc: 0.958889\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.142489 Train acc: 0.941667\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.148151 Train acc: 0.956667\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.122427 Train acc: 0.965000\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.118442 Train acc: 0.956667\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.113662 Train acc: 0.951667\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.118675 Validation acc: 0.956111\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.128529 Train acc: 0.956667\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.120631 Train acc: 0.958333\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.142394 Train acc: 0.945000\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.095291 Train acc: 0.973333\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.166376 Train acc: 0.935000\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.120679 Validation acc: 0.956667\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.138422 Train acc: 0.956667\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.117161 Train acc: 0.955000\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.106593 Train acc: 0.968333\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.116544 Train acc: 0.955000\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.117241 Train acc: 0.965000\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.122997 Validation acc: 0.957778\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.127097 Train acc: 0.960000\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.139692 Train acc: 0.948333\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.104022 Train acc: 0.961667\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.163666 Train acc: 0.935000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.140069 Train acc: 0.955000\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.129216 Validation acc: 0.955555\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.114449 Train acc: 0.960000\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.114718 Train acc: 0.958333\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.115138 Train acc: 0.958333\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.139890 Train acc: 0.960000\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.122150 Train acc: 0.958333\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.117912 Validation acc: 0.957222\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.148485 Train acc: 0.945000\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.098509 Train acc: 0.968333\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.156340 Train acc: 0.928333\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.132011 Train acc: 0.951667\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.108427 Train acc: 0.958333\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.120154 Validation acc: 0.955556\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.099732 Train acc: 0.968333\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.116990 Train acc: 0.961667\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.125026 Train acc: 0.961667\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.130144 Train acc: 0.961667\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.140211 Train acc: 0.955000\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.118966 Validation acc: 0.957778\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.094902 Train acc: 0.966667\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.155029 Train acc: 0.945000\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.138787 Train acc: 0.953333\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.114100 Train acc: 0.965000\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.121939 Train acc: 0.951667\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.117187 Validation acc: 0.956111\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.116718 Train acc: 0.956667\n",
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.120003 Train acc: 0.966667\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.136621 Train acc: 0.955000\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.127827 Train acc: 0.955000\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.104126 Train acc: 0.966667\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.124022 Validation acc: 0.956667\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.159081 Train acc: 0.936667\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.125798 Train acc: 0.958333\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.113547 Train acc: 0.961667\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.103110 Train acc: 0.961667\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.111945 Train acc: 0.958333\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.123592 Validation acc: 0.956111\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.109319 Train acc: 0.966667\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.114317 Train acc: 0.953333\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.140683 Train acc: 0.946667\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.096556 Train acc: 0.966667\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.146807 Train acc: 0.940000\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.123455 Validation acc: 0.955000\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.123986 Train acc: 0.960000\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.116442 Train acc: 0.958333\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.100558 Train acc: 0.963333\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.110445 Train acc: 0.958333\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.122167 Train acc: 0.961667\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.118797 Validation acc: 0.955000\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.108609 Train acc: 0.958333\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.138537 Train acc: 0.945000\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.095802 Train acc: 0.973333\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.139241 Train acc: 0.940000\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.130229 Train acc: 0.958333\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.119646 Validation acc: 0.955556\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.122313 Train acc: 0.955000\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.105163 Train acc: 0.960000\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.107843 Train acc: 0.956667\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.116352 Train acc: 0.966667\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.119401 Train acc: 0.963333\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.122434 Validation acc: 0.955556\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.131092 Train acc: 0.956667\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.098320 Train acc: 0.971667\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.138242 Train acc: 0.941667\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.130619 Train acc: 0.955000\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.120376 Train acc: 0.960000\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.120494 Validation acc: 0.956111\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.101347 Train acc: 0.966667\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.112524 Train acc: 0.961667\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.105952 Train acc: 0.963333\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.127031 Train acc: 0.956667\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.135312 Train acc: 0.946667\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.117990 Validation acc: 0.958889\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.091052 Train acc: 0.980000\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.139179 Train acc: 0.948333\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.129399 Train acc: 0.956667\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.111654 Train acc: 0.961667\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.108576 Train acc: 0.966667\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.121510 Validation acc: 0.956667\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.116018 Train acc: 0.951667\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.118007 Train acc: 0.965000\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.119001 Train acc: 0.963333\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.133141 Train acc: 0.956667\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.084313 Train acc: 0.980000\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.119627 Validation acc: 0.955000\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.147319 Train acc: 0.940000\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.135055 Train acc: 0.956667\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.114422 Train acc: 0.951667\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.105961 Train acc: 0.963333\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.103598 Train acc: 0.956667\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.125583 Validation acc: 0.955555\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.115077 Train acc: 0.966667\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.118176 Train acc: 0.961667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.144182 Train acc: 0.943333\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.094318 Train acc: 0.968333\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.151106 Train acc: 0.931667\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.123014 Validation acc: 0.955000\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.124985 Train acc: 0.961667\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.112960 Train acc: 0.963333\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.098568 Train acc: 0.966667\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.096154 Train acc: 0.966667\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.119900 Train acc: 0.953333\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.119988 Validation acc: 0.956111\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.114939 Train acc: 0.963333\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.156323 Train acc: 0.948333\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.089257 Train acc: 0.975000\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.146880 Train acc: 0.940000\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.115992 Train acc: 0.956667\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.118461 Validation acc: 0.953889\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.098841 Train acc: 0.963333\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.101626 Train acc: 0.958333\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.102305 Train acc: 0.961667\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.114545 Train acc: 0.966667\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.122220 Train acc: 0.956667\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.119604 Validation acc: 0.956111\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.140237 Train acc: 0.945000\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.093826 Train acc: 0.978333\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.135223 Train acc: 0.946667\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.134848 Train acc: 0.953333\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.112332 Train acc: 0.955000\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.120200 Validation acc: 0.955556\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.088016 Train acc: 0.970000\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.119442 Train acc: 0.961667\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.110748 Train acc: 0.960000\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.111359 Train acc: 0.958333\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.133080 Train acc: 0.945000\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.122838 Validation acc: 0.954444\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.098273 Train acc: 0.968333\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.137242 Train acc: 0.948333\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.131988 Train acc: 0.958333\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.100182 Train acc: 0.963333\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.092294 Train acc: 0.965000\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.124889 Validation acc: 0.955000\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.103226 Train acc: 0.960000\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.118339 Train acc: 0.961667\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.113530 Train acc: 0.965000\n",
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.135869 Train acc: 0.950000\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.083440 Train acc: 0.980000\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.129174 Validation acc: 0.953333\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.140475 Train acc: 0.941667\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.135964 Train acc: 0.960000\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.105004 Train acc: 0.956667\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.096795 Train acc: 0.968333\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.107822 Train acc: 0.960000\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.130625 Validation acc: 0.953333\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.117360 Train acc: 0.963333\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.123486 Train acc: 0.965000\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.128160 Train acc: 0.950000\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.081322 Train acc: 0.966667\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.120864 Train acc: 0.948333\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.131091 Validation acc: 0.955556\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.124527 Train acc: 0.956667\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.106008 Train acc: 0.960000\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.109047 Train acc: 0.968333\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.108528 Train acc: 0.968333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.132611 Train acc: 0.956667\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.128993 Validation acc: 0.957778\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.114737 Train acc: 0.963333\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.137176 Train acc: 0.948333\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.087431 Train acc: 0.971667\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.137410 Train acc: 0.938333\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.126265 Train acc: 0.963333\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.125397 Validation acc: 0.958333\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.108813 Train acc: 0.960000\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.098473 Train acc: 0.961667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.098358 Train acc: 0.965000\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.116901 Train acc: 0.963333\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.118562 Train acc: 0.966667\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.124937 Validation acc: 0.955000\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.125256 Train acc: 0.948333\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.091638 Train acc: 0.965000\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.148773 Train acc: 0.941667\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.132997 Train acc: 0.951667\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.112905 Train acc: 0.950000\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.131897 Validation acc: 0.954444\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.102306 Train acc: 0.958333\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.114245 Train acc: 0.956667\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.125661 Train acc: 0.965000\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.123517 Train acc: 0.960000\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.125520 Train acc: 0.945000\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.121320 Validation acc: 0.956667\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.082029 Train acc: 0.970000\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.135427 Train acc: 0.941667\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.126774 Train acc: 0.960000\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.116145 Train acc: 0.963333\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.099295 Train acc: 0.958333\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.128716 Validation acc: 0.953889\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.103116 Train acc: 0.960000\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.104582 Train acc: 0.970000\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.126623 Train acc: 0.961667\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.138214 Train acc: 0.950000\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.079463 Train acc: 0.971667\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.127032 Validation acc: 0.952222\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.140229 Train acc: 0.940000\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.124568 Train acc: 0.960000\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.116294 Train acc: 0.953333\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.097065 Train acc: 0.968333\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.109919 Train acc: 0.953333\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.133291 Validation acc: 0.951667\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.103585 Train acc: 0.965000\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.131923 Train acc: 0.960000\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.118316 Train acc: 0.950000\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.079728 Train acc: 0.971667\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.142497 Train acc: 0.938333\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.121787 Validation acc: 0.955000\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.125539 Train acc: 0.956667\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.111860 Train acc: 0.961667\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.094480 Train acc: 0.965000\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.094916 Train acc: 0.968333\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.106116 Train acc: 0.968333\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.126061 Validation acc: 0.955000\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.112609 Train acc: 0.961667\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.128846 Train acc: 0.951667\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.082917 Train acc: 0.975000\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.143164 Train acc: 0.945000\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.121873 Train acc: 0.961667\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.122962 Validation acc: 0.956667\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.116070 Train acc: 0.960000\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.093372 Train acc: 0.968333\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.095666 Train acc: 0.966667\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.108620 Train acc: 0.961667\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.114264 Train acc: 0.950000\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.122267 Validation acc: 0.956111\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.120304 Train acc: 0.963333\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.080054 Train acc: 0.973333\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.129314 Train acc: 0.950000\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.118970 Train acc: 0.956667\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.110039 Train acc: 0.968333\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.120742 Validation acc: 0.955555\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.098252 Train acc: 0.956667\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.098525 Train acc: 0.961667\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.115415 Train acc: 0.965000\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.116905 Train acc: 0.961667\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.146330 Train acc: 0.950000\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.133830 Validation acc: 0.953333\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.084290 Train acc: 0.973333\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.144223 Train acc: 0.948333\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.116302 Train acc: 0.953333\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.117620 Train acc: 0.958333\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.104301 Train acc: 0.965000\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.122333 Validation acc: 0.951667\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.101356 Train acc: 0.968333\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.105473 Train acc: 0.968333\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.131342 Train acc: 0.960000\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.136822 Train acc: 0.945000\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.088672 Train acc: 0.975000\n",
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.126036 Validation acc: 0.953889\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.129532 Train acc: 0.948333\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.121032 Train acc: 0.950000\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.114351 Train acc: 0.946667\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.142541 Train acc: 0.963333\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.121645 Train acc: 0.950000\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.133878 Validation acc: 0.951667\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.108836 Train acc: 0.965000\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.122181 Train acc: 0.960000\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.136989 Train acc: 0.936667\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.088306 Train acc: 0.975000\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.124239 Train acc: 0.948333\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.128414 Validation acc: 0.952222\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.117599 Train acc: 0.965000\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.107739 Train acc: 0.950000\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.093765 Train acc: 0.970000\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.108649 Train acc: 0.958333\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.090739 Train acc: 0.970000\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.124580 Validation acc: 0.952778\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.132026 Train acc: 0.960000\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.135212 Train acc: 0.950000\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.086754 Train acc: 0.966667\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.149832 Train acc: 0.935000\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.122714 Train acc: 0.963333\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.125827 Validation acc: 0.952222\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.105394 Train acc: 0.958333\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.107084 Train acc: 0.953333\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.108088 Train acc: 0.955000\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.102708 Train acc: 0.966667\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.111186 Train acc: 0.956667\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.119110 Validation acc: 0.956667\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.120936 Train acc: 0.953333\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.084597 Train acc: 0.968333\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.134921 Train acc: 0.945000\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.124502 Train acc: 0.951667\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.095455 Train acc: 0.965000\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.123164 Validation acc: 0.953889\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.089113 Train acc: 0.971667\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.111984 Train acc: 0.951667\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.105219 Train acc: 0.965000\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.116170 Train acc: 0.956667\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.116092 Train acc: 0.953333\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.119573 Validation acc: 0.955000\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.082632 Train acc: 0.970000\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.126145 Train acc: 0.948333\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.121860 Train acc: 0.963333\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.105979 Train acc: 0.963333\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.100240 Train acc: 0.970000\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.118970 Validation acc: 0.956111\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.102976 Train acc: 0.960000\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.103722 Train acc: 0.968333\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.114605 Train acc: 0.963333\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.129272 Train acc: 0.940000\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.093394 Train acc: 0.968333\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.120329 Validation acc: 0.956111\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.122887 Train acc: 0.945000\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.114399 Train acc: 0.963333\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.110559 Train acc: 0.963333\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.097535 Train acc: 0.958333\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.100619 Train acc: 0.961667\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.118493 Validation acc: 0.953889\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.096386 Train acc: 0.970000\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.108628 Train acc: 0.958333\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.121436 Train acc: 0.960000\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.086928 Train acc: 0.971667\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.153781 Train acc: 0.940000\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.114606 Validation acc: 0.954444\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.139389 Train acc: 0.956667\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.099338 Train acc: 0.966667\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.090739 Train acc: 0.973333\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.087632 Train acc: 0.968333\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.097033 Train acc: 0.971667\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.112513 Validation acc: 0.956667\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.109291 Train acc: 0.956667\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.123794 Train acc: 0.960000\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.084447 Train acc: 0.968333\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.123199 Train acc: 0.946667\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.122962 Train acc: 0.958333\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.116772 Validation acc: 0.956667\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.111783 Train acc: 0.961667\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.105489 Train acc: 0.968333\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.097852 Train acc: 0.960000\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.097654 Train acc: 0.970000\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.108521 Train acc: 0.960000\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.118752 Validation acc: 0.956111\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.120078 Train acc: 0.958333\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.080883 Train acc: 0.970000\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.121900 Train acc: 0.945000\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.108952 Train acc: 0.963333\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.107177 Train acc: 0.960000\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.116855 Validation acc: 0.958333\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.092050 Train acc: 0.968333\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.104914 Train acc: 0.958333\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.103262 Train acc: 0.968333\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.118244 Train acc: 0.953333\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.125940 Train acc: 0.958333\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.113779 Validation acc: 0.956111\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.093959 Train acc: 0.961667\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.133547 Train acc: 0.941667\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.136251 Train acc: 0.956667\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.090559 Train acc: 0.960000\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.090827 Train acc: 0.963333\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.117382 Validation acc: 0.957222\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.100685 Train acc: 0.966667\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.109359 Train acc: 0.965000\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.107106 Train acc: 0.961667\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.130629 Train acc: 0.950000\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.088218 Train acc: 0.961667\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.108415 Validation acc: 0.953889\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.131406 Train acc: 0.938333\n",
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.140438 Train acc: 0.956667\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.112091 Train acc: 0.956667\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.091412 Train acc: 0.963333\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.093470 Train acc: 0.968333\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.115514 Validation acc: 0.958889\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.110481 Train acc: 0.963333\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.107588 Train acc: 0.963333\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.123414 Train acc: 0.948333\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.082552 Train acc: 0.968333\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.132914 Train acc: 0.950000\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.126414 Validation acc: 0.955555\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.115741 Train acc: 0.958333\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.094270 Train acc: 0.971667\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.090363 Train acc: 0.970000\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.107804 Train acc: 0.955000\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.119281 Train acc: 0.963333\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.125283 Validation acc: 0.953889\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.112108 Train acc: 0.966667\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.126963 Train acc: 0.946667\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.081582 Train acc: 0.970000\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.129227 Train acc: 0.938333\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.109079 Train acc: 0.960000\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.120935 Validation acc: 0.955555\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.100226 Train acc: 0.958333\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.092479 Train acc: 0.966667\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.097866 Train acc: 0.961667\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.103612 Train acc: 0.968333\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.097866 Train acc: 0.966667\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.131841 Validation acc: 0.954444\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.115672 Train acc: 0.953333\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.080040 Train acc: 0.978333\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.129048 Train acc: 0.943333\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.126232 Train acc: 0.953333\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.111436 Train acc: 0.951667\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.121702 Validation acc: 0.957778\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.080957 Train acc: 0.970000\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.090134 Train acc: 0.965000\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.091501 Train acc: 0.970000\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.109040 Train acc: 0.965000\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.123620 Train acc: 0.951667\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.115822 Validation acc: 0.954444\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.087765 Train acc: 0.970000\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.150577 Train acc: 0.935000\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.122324 Train acc: 0.958333\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.101706 Train acc: 0.963333\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.090933 Train acc: 0.966667\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.115374 Validation acc: 0.955555\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.099873 Train acc: 0.958333\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.102752 Train acc: 0.965000\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.115247 Train acc: 0.960000\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.127995 Train acc: 0.955000\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.078405 Train acc: 0.975000\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.119862 Validation acc: 0.954444\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.127206 Train acc: 0.945000\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.109789 Train acc: 0.960000\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.103051 Train acc: 0.950000\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.086164 Train acc: 0.966667\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.087633 Train acc: 0.956667\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.121806 Validation acc: 0.953889\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.118705 Train acc: 0.966667\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.100849 Train acc: 0.965000\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.126127 Train acc: 0.951667\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.076191 Train acc: 0.973333\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.126840 Train acc: 0.943333\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.119983 Validation acc: 0.953889\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.109836 Train acc: 0.966667\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.118772 Train acc: 0.953333\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.084980 Train acc: 0.976667\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.090945 Train acc: 0.971667\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.089475 Train acc: 0.965000\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.122183 Validation acc: 0.953333\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.109560 Train acc: 0.956667\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.124155 Train acc: 0.956667\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.078543 Train acc: 0.971667\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.129393 Train acc: 0.951667\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.122457 Train acc: 0.963333\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.118004 Validation acc: 0.955555\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.111149 Train acc: 0.960000\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.085251 Train acc: 0.971667\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.106341 Train acc: 0.961667\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.103398 Train acc: 0.966667\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.109069 Train acc: 0.971667\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.120548 Validation acc: 0.956667\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.133376 Train acc: 0.950000\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.080572 Train acc: 0.968333\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.128910 Train acc: 0.938333\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.111252 Train acc: 0.961667\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.104142 Train acc: 0.955000\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.118001 Validation acc: 0.956111\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.085729 Train acc: 0.965000\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.098269 Train acc: 0.960000\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.110020 Train acc: 0.965000\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.106141 Train acc: 0.965000\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.135241 Train acc: 0.941667\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.118623 Validation acc: 0.953333\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.071122 Train acc: 0.975000\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.121562 Train acc: 0.946667\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.109927 Train acc: 0.965000\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.099191 Train acc: 0.966667\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.099695 Train acc: 0.960000\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.116408 Validation acc: 0.956111\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.099222 Train acc: 0.963333\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.099243 Train acc: 0.968333\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.103802 Train acc: 0.966667\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.117822 Train acc: 0.951667\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.084242 Train acc: 0.975000\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.112524 Validation acc: 0.955556\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.130505 Train acc: 0.933333\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.108694 Train acc: 0.958333\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.099176 Train acc: 0.965000\n",
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.081265 Train acc: 0.973333\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.099283 Train acc: 0.960000\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.116373 Validation acc: 0.957778\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.108640 Train acc: 0.968333\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.107211 Train acc: 0.955000\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.114290 Train acc: 0.961667\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.072748 Train acc: 0.983333\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.130867 Train acc: 0.943333\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.117103 Validation acc: 0.956111\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.122915 Train acc: 0.963333\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.100537 Train acc: 0.960000\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.081653 Train acc: 0.973333\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.099666 Train acc: 0.961667\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.111932 Train acc: 0.966667\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.126092 Validation acc: 0.956667\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.095414 Train acc: 0.970000\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.120784 Train acc: 0.955000\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.073928 Train acc: 0.980000\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.114038 Train acc: 0.960000\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.110761 Train acc: 0.961667\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.124921 Validation acc: 0.955555\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.094913 Train acc: 0.976667\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.073106 Train acc: 0.975000\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.094561 Train acc: 0.960000\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.097902 Train acc: 0.968333\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.098292 Train acc: 0.966667\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.128891 Validation acc: 0.955000\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.122414 Train acc: 0.963333\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.074168 Train acc: 0.978333\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.120447 Train acc: 0.948333\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.108766 Train acc: 0.963333\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.093333 Train acc: 0.968333\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.122025 Validation acc: 0.956667\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.093440 Train acc: 0.968333\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.097196 Train acc: 0.963333\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.098696 Train acc: 0.965000\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.095856 Train acc: 0.960000\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.117182 Train acc: 0.953333\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.129152 Validation acc: 0.953333\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.079452 Train acc: 0.966667\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.123617 Train acc: 0.950000\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.118152 Train acc: 0.956667\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.108318 Train acc: 0.955000\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.094856 Train acc: 0.971667\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.123165 Validation acc: 0.952778\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.099423 Train acc: 0.963333\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.091597 Train acc: 0.973333\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.099472 Train acc: 0.973333\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.133356 Train acc: 0.950000\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.080438 Train acc: 0.978333\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.124204 Validation acc: 0.954444\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.127871 Train acc: 0.943333\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.120069 Train acc: 0.961667\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.103617 Train acc: 0.958333\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.072734 Train acc: 0.973333\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.097906 Train acc: 0.968333\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.126375 Validation acc: 0.955556\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.098087 Train acc: 0.973333\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.105315 Train acc: 0.961667\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.115456 Train acc: 0.950000\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.073386 Train acc: 0.970000\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.118908 Train acc: 0.946667\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.123665 Validation acc: 0.955000\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.114321 Train acc: 0.956667\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.086359 Train acc: 0.971667\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.093584 Train acc: 0.966667\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.083876 Train acc: 0.963333\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.103343 Train acc: 0.966667\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.122926 Validation acc: 0.953333\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.084340 Train acc: 0.961667\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.127822 Train acc: 0.953333\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.078977 Train acc: 0.978333\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.127627 Train acc: 0.938333\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.113321 Train acc: 0.955000\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.125200 Validation acc: 0.956111\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.108153 Train acc: 0.951667\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.082595 Train acc: 0.970000\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.091616 Train acc: 0.973333\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.101497 Train acc: 0.968333\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.100716 Train acc: 0.966667\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.127980 Validation acc: 0.952778\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.101906 Train acc: 0.960000\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.070266 Train acc: 0.975000\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.127872 Train acc: 0.938333\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.124873 Train acc: 0.960000\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.098860 Train acc: 0.960000\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.129974 Validation acc: 0.953889\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.084867 Train acc: 0.970000\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.092839 Train acc: 0.953333\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.108043 Train acc: 0.970000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.100855 Train acc: 0.960000\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.125317 Train acc: 0.945000\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.121988 Validation acc: 0.956667\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.073757 Train acc: 0.968333\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.122649 Train acc: 0.950000\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.115698 Train acc: 0.965000\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.088013 Train acc: 0.970000\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.090302 Train acc: 0.971667\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.124933 Validation acc: 0.956111\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.095709 Train acc: 0.961667\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.098481 Train acc: 0.971667\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.100487 Train acc: 0.965000\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.110394 Train acc: 0.955000\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.071468 Train acc: 0.980000\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.123396 Validation acc: 0.956111\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.117393 Train acc: 0.948333\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.104949 Train acc: 0.966667\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.098953 Train acc: 0.961667\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.093688 Train acc: 0.968333\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.083083 Train acc: 0.970000\n",
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.126473 Validation acc: 0.955556\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.085907 Train acc: 0.973333\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.102305 Train acc: 0.963333\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.122371 Train acc: 0.956667\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.072985 Train acc: 0.976667\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.119569 Train acc: 0.945000\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.121542 Validation acc: 0.954444\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.113467 Train acc: 0.956667\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.108424 Train acc: 0.960000\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.082427 Train acc: 0.966667\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.094591 Train acc: 0.961667\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.095274 Train acc: 0.971667\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.119013 Validation acc: 0.955000\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.090102 Train acc: 0.963333\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.115892 Train acc: 0.948333\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.068193 Train acc: 0.978333\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.135651 Train acc: 0.940000\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.096042 Train acc: 0.963333\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.119662 Validation acc: 0.957778\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.101126 Train acc: 0.961667\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.098213 Train acc: 0.955000\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.111998 Train acc: 0.951667\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.094973 Train acc: 0.973333\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.099761 Train acc: 0.973333\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.116742 Validation acc: 0.957222\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.121042 Train acc: 0.951667\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.084612 Train acc: 0.971667\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.139991 Train acc: 0.936667\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.112020 Train acc: 0.958333\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.102829 Train acc: 0.963333\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.118169 Validation acc: 0.955000\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.085666 Train acc: 0.970000\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.090231 Train acc: 0.968333\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.102607 Train acc: 0.968333\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.101079 Train acc: 0.961667\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.124726 Train acc: 0.956667\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.111241 Validation acc: 0.957778\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.079484 Train acc: 0.975000\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.117563 Train acc: 0.958333\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.110383 Train acc: 0.960000\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.097840 Train acc: 0.960000\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.084355 Train acc: 0.965000\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.119696 Validation acc: 0.956667\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.084571 Train acc: 0.971667\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.093413 Train acc: 0.971667\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.096445 Train acc: 0.963333\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.121176 Train acc: 0.961667\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.072226 Train acc: 0.975000\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.118395 Validation acc: 0.956667\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.130306 Train acc: 0.940000\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.115178 Train acc: 0.961667\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.090280 Train acc: 0.970000\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.091034 Train acc: 0.973333\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.087170 Train acc: 0.968333\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.112106 Validation acc: 0.954444\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.097818 Train acc: 0.965000\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.090793 Train acc: 0.968333\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.121921 Train acc: 0.950000\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.069880 Train acc: 0.973333\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.119121 Train acc: 0.955000\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.115630 Validation acc: 0.959444\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.117225 Train acc: 0.961667\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.109565 Train acc: 0.966667\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.132809 Train acc: 0.965000\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.088447 Train acc: 0.958333\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.107108 Train acc: 0.973333\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.112651 Validation acc: 0.955000\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.095501 Train acc: 0.958333\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.105758 Train acc: 0.956667\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.066108 Train acc: 0.975000\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.120467 Train acc: 0.943333\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.115789 Train acc: 0.961667\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.115461 Validation acc: 0.958889\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.095301 Train acc: 0.968333\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.095461 Train acc: 0.973333\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.089848 Train acc: 0.960000\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.100463 Train acc: 0.965000\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.107934 Train acc: 0.960000\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.108726 Validation acc: 0.956111\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.130461 Train acc: 0.940000\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.069196 Train acc: 0.976667\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.127915 Train acc: 0.946667\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.107304 Train acc: 0.961667\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.099963 Train acc: 0.970000\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.114399 Validation acc: 0.958333\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.077793 Train acc: 0.968333\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.094229 Train acc: 0.956667\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.100844 Train acc: 0.968333\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.104850 Train acc: 0.966667\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.115337 Train acc: 0.965000\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.115943 Validation acc: 0.956111\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.074527 Train acc: 0.976667\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.134079 Train acc: 0.943333\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.117956 Train acc: 0.956667\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.088568 Train acc: 0.971667\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.084117 Train acc: 0.965000\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.113673 Validation acc: 0.958333\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.081436 Train acc: 0.966667\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.096709 Train acc: 0.968333\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.088715 Train acc: 0.960000\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.117009 Train acc: 0.958333\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.076622 Train acc: 0.973333\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.119901 Validation acc: 0.956111\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.115684 Train acc: 0.951667\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.116101 Train acc: 0.958333\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.096057 Train acc: 0.966667\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.074833 Train acc: 0.970000\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.091015 Train acc: 0.965000\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.115890 Validation acc: 0.957778\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.102653 Train acc: 0.970000\n",
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.097569 Train acc: 0.965000\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.110282 Train acc: 0.953333\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.067219 Train acc: 0.971667\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.112630 Train acc: 0.950000\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.120529 Validation acc: 0.953889\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.129305 Train acc: 0.963333\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.101893 Train acc: 0.956667\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.078702 Train acc: 0.965000\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.087704 Train acc: 0.968333\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.091407 Train acc: 0.970000\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.116312 Validation acc: 0.956667\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.085612 Train acc: 0.970000\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.118703 Train acc: 0.953333\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.074732 Train acc: 0.971667\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.130434 Train acc: 0.938333\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.119632 Train acc: 0.963333\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.117234 Validation acc: 0.956667\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.091216 Train acc: 0.961667\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.084959 Train acc: 0.968333\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.091244 Train acc: 0.963333\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.090117 Train acc: 0.975000\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.086807 Train acc: 0.963333\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.117056 Validation acc: 0.957222\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.123234 Train acc: 0.953333\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.064902 Train acc: 0.975000\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.122741 Train acc: 0.953333\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.126850 Train acc: 0.960000\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.079894 Train acc: 0.973333\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.119291 Validation acc: 0.956111\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.075663 Train acc: 0.971667\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.095768 Train acc: 0.963333\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.093074 Train acc: 0.970000\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.102441 Train acc: 0.961667\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.114016 Train acc: 0.956667\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.118017 Validation acc: 0.955556\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.065957 Train acc: 0.975000\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.129209 Train acc: 0.948333\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.112096 Train acc: 0.963333\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.104084 Train acc: 0.946667\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.079904 Train acc: 0.971667\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.117654 Validation acc: 0.953889\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.076212 Train acc: 0.971667\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.099998 Train acc: 0.975000\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.095068 Train acc: 0.973333\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.117232 Train acc: 0.955000\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.066960 Train acc: 0.976667\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.118897 Validation acc: 0.956111\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.125351 Train acc: 0.953333\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.098325 Train acc: 0.968333\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.094665 Train acc: 0.965000\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.081605 Train acc: 0.965000\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.086708 Train acc: 0.968333\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.116977 Validation acc: 0.955555\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.101907 Train acc: 0.965000\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.098808 Train acc: 0.968333\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.112719 Train acc: 0.948333\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.063647 Train acc: 0.976667\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.128551 Train acc: 0.946667\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.120289 Validation acc: 0.952222\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.111469 Train acc: 0.966667\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.088579 Train acc: 0.966667\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.080715 Train acc: 0.970000\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.082030 Train acc: 0.970000\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.093999 Train acc: 0.968333\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.112564 Validation acc: 0.957778\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.090423 Train acc: 0.965000\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.107633 Train acc: 0.965000\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.065849 Train acc: 0.971667\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.114770 Train acc: 0.946667\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.104580 Train acc: 0.960000\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.114412 Validation acc: 0.956111\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.097942 Train acc: 0.961667\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.078945 Train acc: 0.975000\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.096187 Train acc: 0.963333\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.099112 Train acc: 0.970000\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.095077 Train acc: 0.965000\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.116247 Validation acc: 0.956111\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.107689 Train acc: 0.956667\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.067140 Train acc: 0.976667\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.126091 Train acc: 0.951667\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.107745 Train acc: 0.968333\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.101632 Train acc: 0.966667\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.112500 Validation acc: 0.954444\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.079850 Train acc: 0.970000\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.087346 Train acc: 0.971667\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.100070 Train acc: 0.970000\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.098789 Train acc: 0.965000\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.118874 Train acc: 0.960000\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.113451 Validation acc: 0.958333\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.070612 Train acc: 0.975000\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.119332 Train acc: 0.948333\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.108845 Train acc: 0.961667\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.095456 Train acc: 0.958333\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.077764 Train acc: 0.973333\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.118967 Validation acc: 0.955555\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.072560 Train acc: 0.968333\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.087494 Train acc: 0.975000\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.088952 Train acc: 0.961667\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.116029 Train acc: 0.960000\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.071299 Train acc: 0.976667\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.121265 Validation acc: 0.956111\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.118072 Train acc: 0.948333\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.109663 Train acc: 0.966667\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.086248 Train acc: 0.966667\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.078748 Train acc: 0.965000\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.084360 Train acc: 0.968333\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.112715 Validation acc: 0.958333\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.093154 Train acc: 0.970000\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.094073 Train acc: 0.971667\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.116156 Train acc: 0.960000\n",
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.068641 Train acc: 0.973333\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.122851 Train acc: 0.943333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.122027 Validation acc: 0.956111\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.116340 Train acc: 0.956667\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.087569 Train acc: 0.970000\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.072734 Train acc: 0.978333\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.070905 Train acc: 0.968333\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.089989 Train acc: 0.971667\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.111004 Validation acc: 0.957778\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.088056 Train acc: 0.975000\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.118714 Train acc: 0.958333\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.059156 Train acc: 0.975000\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.112020 Train acc: 0.955000\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.100552 Train acc: 0.963333\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.115424 Validation acc: 0.956667\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.099765 Train acc: 0.970000\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.079360 Train acc: 0.975000\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.081141 Train acc: 0.966667\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.092548 Train acc: 0.973333\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.095168 Train acc: 0.970000\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.119036 Validation acc: 0.954444\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.121862 Train acc: 0.953333\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.064647 Train acc: 0.980000\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.130568 Train acc: 0.938333\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.115897 Train acc: 0.958333\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.092781 Train acc: 0.961667\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.115741 Validation acc: 0.956111\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.080530 Train acc: 0.975000\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.090753 Train acc: 0.958333\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.098608 Train acc: 0.968333\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.104934 Train acc: 0.965000\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.108795 Train acc: 0.963333\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.115031 Validation acc: 0.957778\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.068070 Train acc: 0.978333\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.126156 Train acc: 0.945000\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.110797 Train acc: 0.958333\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.098082 Train acc: 0.965000\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.075896 Train acc: 0.971667\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.113572 Validation acc: 0.957222\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.084939 Train acc: 0.966667\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.096881 Train acc: 0.971667\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.098962 Train acc: 0.963333\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.104174 Train acc: 0.953333\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.062596 Train acc: 0.981667\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.124945 Validation acc: 0.953333\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.123267 Train acc: 0.951667\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.110903 Train acc: 0.961667\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.097473 Train acc: 0.961667\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.074194 Train acc: 0.973333\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.077265 Train acc: 0.966667\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.108600 Validation acc: 0.957222\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.083828 Train acc: 0.971667\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.088755 Train acc: 0.966667\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.108353 Train acc: 0.955000\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.071835 Train acc: 0.978333\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.115552 Train acc: 0.951667\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.110397 Validation acc: 0.957222\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.116002 Train acc: 0.961667\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.092411 Train acc: 0.958333\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.076098 Train acc: 0.971667\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.073102 Train acc: 0.970000\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.097598 Train acc: 0.968333\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.108006 Validation acc: 0.958889\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.089015 Train acc: 0.968333\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.112157 Train acc: 0.958333\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.060664 Train acc: 0.980000\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.131398 Train acc: 0.936667\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.112874 Train acc: 0.966667\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.109416 Validation acc: 0.957222\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.089329 Train acc: 0.973333\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.078623 Train acc: 0.970000\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.081331 Train acc: 0.970000\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.103825 Train acc: 0.965000\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.089804 Train acc: 0.973333\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.117976 Validation acc: 0.955000\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.122558 Train acc: 0.956667\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.069153 Train acc: 0.968333\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.116880 Train acc: 0.955000\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.108454 Train acc: 0.968333\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.087146 Train acc: 0.971667\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.113772 Validation acc: 0.957222\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.078957 Train acc: 0.975000\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.080078 Train acc: 0.966667\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.101574 Train acc: 0.970000\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.093843 Train acc: 0.965000\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.126697 Train acc: 0.951667\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.111710 Validation acc: 0.958333\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.055439 Train acc: 0.980000\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.136213 Train acc: 0.938333\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.122188 Train acc: 0.956667\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.094002 Train acc: 0.963333\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.086029 Train acc: 0.971667\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.126115 Validation acc: 0.953333\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.093689 Train acc: 0.963333\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.091355 Train acc: 0.968333\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.085933 Train acc: 0.971667\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.112097 Train acc: 0.958333\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.071996 Train acc: 0.978333\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.121040 Validation acc: 0.956111\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.120046 Train acc: 0.945000\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.101744 Train acc: 0.966667\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.094221 Train acc: 0.961667\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.081015 Train acc: 0.975000\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.082948 Train acc: 0.961667\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.123119 Validation acc: 0.954444\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.093271 Train acc: 0.966667\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.092045 Train acc: 0.963333\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.105847 Train acc: 0.960000\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.063508 Train acc: 0.980000\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.121610 Train acc: 0.950000\n",
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.124192 Validation acc: 0.952222\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.106205 Train acc: 0.958333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.104450 Train acc: 0.956667\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.077767 Train acc: 0.966667\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.081605 Train acc: 0.970000\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.087037 Train acc: 0.968333\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.124982 Validation acc: 0.955555\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.087900 Train acc: 0.971667\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.118048 Train acc: 0.948333\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.070279 Train acc: 0.973333\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.133310 Train acc: 0.938333\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.121117 Train acc: 0.955000\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.131311 Validation acc: 0.951111\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.107054 Train acc: 0.961667\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.092138 Train acc: 0.971667\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.094189 Train acc: 0.966667\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.109235 Train acc: 0.966667\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.098907 Train acc: 0.960000\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.110702 Validation acc: 0.953333\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.133430 Train acc: 0.948333\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.074141 Train acc: 0.970000\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.119165 Train acc: 0.953333\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.109080 Train acc: 0.955000\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.106694 Train acc: 0.953333\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.111975 Validation acc: 0.953333\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.098997 Train acc: 0.958333\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.085152 Train acc: 0.970000\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.096924 Train acc: 0.970000\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.107645 Train acc: 0.960000\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.129981 Train acc: 0.948333\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.111852 Validation acc: 0.953889\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.071476 Train acc: 0.971667\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.118692 Train acc: 0.950000\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.117791 Train acc: 0.955000\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.095436 Train acc: 0.958333\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.086297 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.114703 Validation acc: 0.954444\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.094354 Train acc: 0.961667\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.094270 Train acc: 0.970000\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.106767 Train acc: 0.955000\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.127649 Train acc: 0.943333\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.072455 Train acc: 0.976667\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.122266 Validation acc: 0.953333\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.114890 Train acc: 0.938333\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.103986 Train acc: 0.956667\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.101423 Train acc: 0.955000\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.086271 Train acc: 0.966667\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.093655 Train acc: 0.958333\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.121732 Validation acc: 0.957778\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.090151 Train acc: 0.971667\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.091816 Train acc: 0.968333\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.123152 Train acc: 0.946667\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.074705 Train acc: 0.975000\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.116588 Train acc: 0.951667\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.120329 Validation acc: 0.958333\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.111107 Train acc: 0.965000\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.099707 Train acc: 0.965000\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.091735 Train acc: 0.973333\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.078387 Train acc: 0.971667\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.084290 Train acc: 0.975000\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.114029 Validation acc: 0.956667\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.086275 Train acc: 0.963333\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.101221 Train acc: 0.960000\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.061260 Train acc: 0.978333\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.126378 Train acc: 0.941667\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.107143 Train acc: 0.961667\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.111782 Validation acc: 0.956111\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.088261 Train acc: 0.960000\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.070704 Train acc: 0.971667\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.088613 Train acc: 0.968333\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.089931 Train acc: 0.966667\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.089208 Train acc: 0.966667\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.108006 Validation acc: 0.955000\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.105872 Train acc: 0.960000\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.065669 Train acc: 0.978333\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.116937 Train acc: 0.945000\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.099342 Train acc: 0.968333\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.096888 Train acc: 0.965000\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.125810 Validation acc: 0.957778\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.105630 Train acc: 0.958333\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.090208 Train acc: 0.956667\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.109756 Train acc: 0.961667\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.098434 Train acc: 0.960000\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.108807 Train acc: 0.955000\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.108294 Validation acc: 0.957778\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.062945 Train acc: 0.978333\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.126549 Train acc: 0.945000\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.105550 Train acc: 0.965000\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.110456 Train acc: 0.960000\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.093547 Train acc: 0.965000\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.116546 Validation acc: 0.953333\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.092763 Train acc: 0.963333\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.108022 Train acc: 0.960000\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.102423 Train acc: 0.968333\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.108912 Train acc: 0.955000\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.070293 Train acc: 0.968333\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.110598 Validation acc: 0.957778\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.128697 Train acc: 0.941667\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.115401 Train acc: 0.956667\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.090957 Train acc: 0.966667\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.094767 Train acc: 0.961667\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.092960 Train acc: 0.960000\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.115662 Validation acc: 0.952222\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.107953 Train acc: 0.961667\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.103003 Train acc: 0.960000\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.112107 Train acc: 0.955000\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.089944 Train acc: 0.965000\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.129102 Train acc: 0.948333\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.106941 Validation acc: 0.957778\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.116411 Train acc: 0.960000\n",
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.098699 Train acc: 0.956667\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.081628 Train acc: 0.965000\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.082251 Train acc: 0.965000\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.091393 Train acc: 0.970000\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.112601 Validation acc: 0.960556\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.086344 Train acc: 0.966667\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.117942 Train acc: 0.948333\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.066749 Train acc: 0.976667\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.114955 Train acc: 0.953333\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.114870 Train acc: 0.965000\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.120364 Validation acc: 0.954444\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.095310 Train acc: 0.966667\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.079896 Train acc: 0.970000\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.091335 Train acc: 0.963333\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.099598 Train acc: 0.966667\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.096406 Train acc: 0.965000\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.118915 Validation acc: 0.955555\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.113242 Train acc: 0.958333\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.059522 Train acc: 0.983333\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.120633 Train acc: 0.950000\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.093353 Train acc: 0.966667\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.090268 Train acc: 0.965000\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.114657 Validation acc: 0.957222\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.075199 Train acc: 0.966667\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.080483 Train acc: 0.966667\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.096934 Train acc: 0.973333\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.091809 Train acc: 0.968333\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.105583 Train acc: 0.955000\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.112520 Validation acc: 0.958889\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.062231 Train acc: 0.981667\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.128077 Train acc: 0.951667\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.094130 Train acc: 0.973333\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.086735 Train acc: 0.966667\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.078602 Train acc: 0.971667\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.114637 Validation acc: 0.954444\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.083191 Train acc: 0.961667\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.096533 Train acc: 0.970000\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.095825 Train acc: 0.965000\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.113436 Train acc: 0.955000\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.062231 Train acc: 0.976667\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.121098 Validation acc: 0.956667\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.116987 Train acc: 0.951667\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.107332 Train acc: 0.961667\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.090464 Train acc: 0.968333\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.068628 Train acc: 0.970000\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.078754 Train acc: 0.970000\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.116131 Validation acc: 0.957222\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.099475 Train acc: 0.971667\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.088394 Train acc: 0.968333\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.105146 Train acc: 0.958333\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.058185 Train acc: 0.980000\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.124059 Train acc: 0.948333\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.119732 Validation acc: 0.957222\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.113835 Train acc: 0.953333\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.081343 Train acc: 0.971667\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.072966 Train acc: 0.968333\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.081005 Train acc: 0.968333\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.091356 Train acc: 0.968333\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.115836 Validation acc: 0.956667\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.094897 Train acc: 0.965000\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.103368 Train acc: 0.961667\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.073050 Train acc: 0.975000\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.127914 Train acc: 0.938333\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.105557 Train acc: 0.963333\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.107581 Validation acc: 0.952222\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.091395 Train acc: 0.956667\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.081469 Train acc: 0.961667\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.071446 Train acc: 0.976667\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.087919 Train acc: 0.971667\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.092074 Train acc: 0.965000\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.113731 Validation acc: 0.956111\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.105015 Train acc: 0.955000\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.063292 Train acc: 0.976667\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.124363 Train acc: 0.946667\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.111801 Train acc: 0.966667\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.094796 Train acc: 0.956667\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.111391 Validation acc: 0.957778\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.086086 Train acc: 0.966667\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.087840 Train acc: 0.963333\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.098836 Train acc: 0.973333\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.102069 Train acc: 0.968333\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.108891 Train acc: 0.963333\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.117708 Validation acc: 0.956667\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.063090 Train acc: 0.975000\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.116352 Train acc: 0.945000\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.155074 Train acc: 0.958333\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.095570 Train acc: 0.966667\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.097806 Train acc: 0.968333\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.108817 Validation acc: 0.958889\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.069905 Train acc: 0.975000\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.098351 Train acc: 0.965000\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.095773 Train acc: 0.963333\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.109855 Train acc: 0.956667\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.067794 Train acc: 0.978333\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.113331 Validation acc: 0.957778\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.126717 Train acc: 0.946667\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.092617 Train acc: 0.963333\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.085320 Train acc: 0.965000\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.076406 Train acc: 0.973333\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.085704 Train acc: 0.963333\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.111041 Validation acc: 0.955555\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.097443 Train acc: 0.968333\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.095865 Train acc: 0.965000\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.103354 Train acc: 0.955000\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.062294 Train acc: 0.976667\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.106944 Train acc: 0.960000\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.108758 Validation acc: 0.956667\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.099888 Train acc: 0.968333\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.095306 Train acc: 0.966667\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.057871 Train acc: 0.981667\n",
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.074955 Train acc: 0.973333\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.088495 Train acc: 0.973333\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.109304 Validation acc: 0.955556\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.084114 Train acc: 0.971667\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.100468 Train acc: 0.958333\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.058038 Train acc: 0.983333\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.124831 Train acc: 0.946667\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.104169 Train acc: 0.968333\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.106086 Validation acc: 0.960000\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.088252 Train acc: 0.975000\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.073236 Train acc: 0.971667\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.075875 Train acc: 0.968333\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.092647 Train acc: 0.966667\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.089241 Train acc: 0.971667\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.107356 Validation acc: 0.959444\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.103297 Train acc: 0.955000\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.064869 Train acc: 0.975000\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.122127 Train acc: 0.945000\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.098247 Train acc: 0.970000\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.078991 Train acc: 0.973333\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.105742 Validation acc: 0.957222\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.066822 Train acc: 0.971667\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.075950 Train acc: 0.970000\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.095499 Train acc: 0.968333\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.084777 Train acc: 0.973333\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.101085 Train acc: 0.963333\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.104901 Validation acc: 0.957222\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.064449 Train acc: 0.983333\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.118516 Train acc: 0.940000\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.103549 Train acc: 0.968333\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.093183 Train acc: 0.963333\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.078442 Train acc: 0.975000\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.104617 Validation acc: 0.957778\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.091898 Train acc: 0.966667\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.086046 Train acc: 0.973333\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.079865 Train acc: 0.971667\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.108202 Train acc: 0.956667\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.055810 Train acc: 0.986667\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.107022 Validation acc: 0.957778\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.107644 Train acc: 0.953333\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.096296 Train acc: 0.966667\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.091700 Train acc: 0.965000\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.071518 Train acc: 0.973333\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.079099 Train acc: 0.976667\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.108211 Validation acc: 0.956111\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.088685 Train acc: 0.973333\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.082699 Train acc: 0.971667\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.110818 Train acc: 0.958333\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.063967 Train acc: 0.983333\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.106710 Train acc: 0.945000\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.107195 Validation acc: 0.957778\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.094452 Train acc: 0.970000\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.087277 Train acc: 0.970000\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.070894 Train acc: 0.975000\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.089758 Train acc: 0.968333\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.087178 Train acc: 0.973333\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.107547 Validation acc: 0.957778\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.082872 Train acc: 0.973333\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.107295 Train acc: 0.950000\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.050917 Train acc: 0.985000\n",
      "Epoch: 999/1000 Iteration: 8995 Train loss: 0.104300 Train acc: 0.951667\n",
      "Epoch: 999/1000 Iteration: 9000 Train loss: 0.096096 Train acc: 0.970000\n",
      "Epoch: 999/1000 Iteration: 9000 Validation loss: 0.109396 Validation acc: 0.957222\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhWlDBERCQrShgiIpKV/w9uTZbyjzrB7gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f479e514630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f479e514d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.880833\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
