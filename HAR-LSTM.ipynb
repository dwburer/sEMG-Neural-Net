{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body_acc_x\n",
      "body_acc_y\n",
      "body_acc_z\n",
      "body_gyro_x\n",
      "body_gyro_y\n",
      "body_gyro_z\n",
      "total_acc_x\n",
      "total_acc_y\n",
      "total_acc_z\n",
      "body_acc_x\n",
      "body_acc_y\n",
      "body_acc_z\n",
      "body_gyro_x\n",
      "body_gyro_y\n",
      "body_gyro_z\n",
      "total_acc_x\n",
      "total_acc_y\n",
      "total_acc_z\n"
     ]
    }
   ],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.803296 Train acc: 0.188333\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.806126 Train acc: 0.191667\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.791142 Train acc: 0.195000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.770564 Train acc: 0.228333\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.775511 Train acc: 0.230000\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.762561 Validation acc: 0.313333\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.764322 Train acc: 0.241667\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.768987 Train acc: 0.226667\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.743999 Train acc: 0.303333\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.757225 Train acc: 0.251667\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.726127 Train acc: 0.296667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.719184 Validation acc: 0.352778\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.727249 Train acc: 0.281667\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.710947 Train acc: 0.308333\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.697098 Train acc: 0.328333\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.702634 Train acc: 0.310000\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.692911 Train acc: 0.348333\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.673176 Validation acc: 0.382778\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.692415 Train acc: 0.320000\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.668894 Train acc: 0.375000\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.674406 Train acc: 0.350000\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.649045 Train acc: 0.371667\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.644625 Train acc: 0.358333\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.624218 Validation acc: 0.401667\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.612565 Train acc: 0.380000\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.616783 Train acc: 0.395000\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.607405 Train acc: 0.401667\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.614970 Train acc: 0.363333\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.617177 Train acc: 0.398333\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.573653 Validation acc: 0.440556\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.616932 Train acc: 0.371667\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.603700 Train acc: 0.395000\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.556651 Train acc: 0.413333\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.553556 Train acc: 0.433333\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.547292 Train acc: 0.445000\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.521786 Validation acc: 0.502222\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.528821 Train acc: 0.431667\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.549491 Train acc: 0.418333\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.547775 Train acc: 0.415000\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.524200 Train acc: 0.426667\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.518503 Train acc: 0.435000\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.467721 Validation acc: 0.538889\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.519105 Train acc: 0.448333\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.464866 Train acc: 0.480000\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.470563 Train acc: 0.476667\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.442298 Train acc: 0.495000\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.433034 Train acc: 0.501667\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.411059 Validation acc: 0.563889\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.450125 Train acc: 0.458333\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.453054 Train acc: 0.458333\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.442533 Train acc: 0.496667\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.423057 Train acc: 0.488333\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.427051 Train acc: 0.500000\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.351208 Validation acc: 0.591111\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.374703 Train acc: 0.513333\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.378059 Train acc: 0.506667\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.346858 Train acc: 0.550000\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.333659 Train acc: 0.553333\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.343160 Train acc: 0.546667\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 1.286840 Validation acc: 0.613889\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.342024 Train acc: 0.530000\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.337154 Train acc: 0.523333\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.319739 Train acc: 0.528333\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.326450 Train acc: 0.551667\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.261416 Train acc: 0.598333\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 1.216116 Validation acc: 0.642778\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.251047 Train acc: 0.590000\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 1.226392 Train acc: 0.606667\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.232520 Train acc: 0.580000\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 1.223369 Train acc: 0.603333\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 1.228144 Train acc: 0.595000\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 1.142042 Validation acc: 0.654444\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 1.197776 Train acc: 0.616667\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 1.203491 Train acc: 0.585000\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 1.177244 Train acc: 0.638333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 1.111654 Train acc: 0.635000\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 1.106671 Train acc: 0.655000\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 1.070462 Validation acc: 0.667778\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 1.075640 Train acc: 0.661667\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 1.106490 Train acc: 0.658333\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 1.108165 Train acc: 0.631667\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 1.096316 Train acc: 0.638333\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 1.077523 Train acc: 0.631667\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 1.007787 Validation acc: 0.672222\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 1.099140 Train acc: 0.640000\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 1.075930 Train acc: 0.645000\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 1.035528 Train acc: 0.655000\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 1.040227 Train acc: 0.645000\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 0.995140 Train acc: 0.666667\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 0.954053 Validation acc: 0.680556\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 1.014734 Train acc: 0.656667\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 1.023350 Train acc: 0.646667\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 1.024672 Train acc: 0.640000\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.991560 Train acc: 0.658333\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 1.034979 Train acc: 0.631667\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.907650 Validation acc: 0.690556\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.997499 Train acc: 0.660000\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.953026 Train acc: 0.660000\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.945302 Train acc: 0.690000\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.928518 Train acc: 0.680000\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.949585 Train acc: 0.663333\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.869557 Validation acc: 0.699444\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.956301 Train acc: 0.660000\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.962257 Train acc: 0.638333\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.924345 Train acc: 0.681667\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.961176 Train acc: 0.656667\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.953377 Train acc: 0.645000\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.836261 Validation acc: 0.709444\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.901085 Train acc: 0.690000\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.905365 Train acc: 0.675000\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.869955 Train acc: 0.681667\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.898939 Train acc: 0.668333\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.900212 Train acc: 0.643333\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.807951 Validation acc: 0.713889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.908496 Train acc: 0.645000\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.879283 Train acc: 0.663333\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.902196 Train acc: 0.646667\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.892120 Train acc: 0.685000\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.859298 Train acc: 0.670000\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.784116 Validation acc: 0.716111\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.872280 Train acc: 0.686667\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.831326 Train acc: 0.703333\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.862275 Train acc: 0.676667\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.829639 Train acc: 0.706667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.869929 Train acc: 0.670000\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.762957 Validation acc: 0.726667\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.831177 Train acc: 0.680000\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.881696 Train acc: 0.666667\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.877750 Train acc: 0.681667\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.830536 Train acc: 0.668333\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.809037 Train acc: 0.671667\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.745186 Validation acc: 0.737778\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.810848 Train acc: 0.676667\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.833451 Train acc: 0.696667\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.820710 Train acc: 0.680000\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.830823 Train acc: 0.665000\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.788717 Train acc: 0.718333\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.728530 Validation acc: 0.752222\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.851025 Train acc: 0.660000\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.839418 Train acc: 0.661667\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.771982 Train acc: 0.720000\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.782568 Train acc: 0.713333\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.762751 Train acc: 0.716667\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.712608 Validation acc: 0.762778\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.792798 Train acc: 0.721667\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.802653 Train acc: 0.713333\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.810733 Train acc: 0.703333\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.772030 Train acc: 0.695000\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.809221 Train acc: 0.691667\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.697690 Validation acc: 0.774444\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.810830 Train acc: 0.693333\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.764939 Train acc: 0.706667\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.768501 Train acc: 0.720000\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.739425 Train acc: 0.721667\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.778256 Train acc: 0.713333\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.679902 Validation acc: 0.780000\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.771268 Train acc: 0.706667\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.792217 Train acc: 0.686667\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.762477 Train acc: 0.705000\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.774166 Train acc: 0.701667\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.776586 Train acc: 0.700000\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.667301 Validation acc: 0.798333\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.741328 Train acc: 0.698333\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.718801 Train acc: 0.733333\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.709793 Train acc: 0.736667\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.732770 Train acc: 0.730000\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.739120 Train acc: 0.726667\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.647707 Validation acc: 0.800000\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.751731 Train acc: 0.720000\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.723702 Train acc: 0.701667\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.761432 Train acc: 0.701667\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.733541 Train acc: 0.706667\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.717517 Train acc: 0.731667\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.630740 Validation acc: 0.818889\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.703970 Train acc: 0.725000\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.681763 Train acc: 0.746667\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.716318 Train acc: 0.736667\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.697748 Train acc: 0.733333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.725952 Train acc: 0.741667\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.611952 Validation acc: 0.826667\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.674376 Train acc: 0.763333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.707010 Train acc: 0.738333\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.702239 Train acc: 0.760000\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.691792 Train acc: 0.740000\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.677840 Train acc: 0.758333\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.594631 Validation acc: 0.837778\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.635378 Train acc: 0.783333\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.700651 Train acc: 0.741667\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.665517 Train acc: 0.780000\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.678248 Train acc: 0.763333\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.664000 Train acc: 0.768333\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.576494 Validation acc: 0.840556\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.679586 Train acc: 0.766667\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.694117 Train acc: 0.743333\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.635396 Train acc: 0.805000\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.645478 Train acc: 0.780000\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.608835 Train acc: 0.800000\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.558279 Validation acc: 0.849444\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.649263 Train acc: 0.770000\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.651016 Train acc: 0.773333\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.662806 Train acc: 0.800000\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.626291 Train acc: 0.766667\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.654748 Train acc: 0.766667\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.541186 Validation acc: 0.853333\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.647073 Train acc: 0.768333\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.650691 Train acc: 0.781667\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.624706 Train acc: 0.783333\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.593063 Train acc: 0.815000\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.640963 Train acc: 0.788333\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.526521 Validation acc: 0.853889\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.637037 Train acc: 0.766667\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.612105 Train acc: 0.816667\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.575538 Train acc: 0.808333\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.647420 Train acc: 0.758333\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.633469 Train acc: 0.790000\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.511181 Validation acc: 0.856667\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.585523 Train acc: 0.810000\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.583773 Train acc: 0.783333\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.568408 Train acc: 0.835000\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.598253 Train acc: 0.790000\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.585048 Train acc: 0.803333\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.495674 Validation acc: 0.855556\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.607876 Train acc: 0.788333\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.589833 Train acc: 0.798333\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.613937 Train acc: 0.778333\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.595373 Train acc: 0.818333\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.570527 Train acc: 0.831667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.485212 Validation acc: 0.860555\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.580007 Train acc: 0.801667\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.530578 Train acc: 0.845000\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.597250 Train acc: 0.808333\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.590641 Train acc: 0.783333\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.576386 Train acc: 0.825000\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.469718 Validation acc: 0.870000\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.563208 Train acc: 0.806667\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.579191 Train acc: 0.783333\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.566577 Train acc: 0.805000\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.532529 Train acc: 0.828333\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.552256 Train acc: 0.815000\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.456404 Validation acc: 0.876667\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.523802 Train acc: 0.831667\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.555996 Train acc: 0.808333\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.540457 Train acc: 0.811667\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.534399 Train acc: 0.821667\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.550492 Train acc: 0.823333\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.443571 Validation acc: 0.883889\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.581654 Train acc: 0.803333\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.550657 Train acc: 0.830000\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.512068 Train acc: 0.840000\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.531087 Train acc: 0.821667\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.519704 Train acc: 0.838333\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.433031 Validation acc: 0.890556\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.530091 Train acc: 0.836667\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.487261 Train acc: 0.848333\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.508559 Train acc: 0.853333\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.495806 Train acc: 0.836667\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.544263 Train acc: 0.816667\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.417866 Validation acc: 0.901111\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.531933 Train acc: 0.840000\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.495927 Train acc: 0.843333\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.502574 Train acc: 0.841667\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.497042 Train acc: 0.845000\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.524139 Train acc: 0.835000\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.404786 Validation acc: 0.913889\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.496571 Train acc: 0.830000\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.494538 Train acc: 0.858333\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.473928 Train acc: 0.875000\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.512278 Train acc: 0.821667\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.528184 Train acc: 0.835000\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.392023 Validation acc: 0.922222\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.467785 Train acc: 0.861667\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.497854 Train acc: 0.841667\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.452513 Train acc: 0.896667\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.486792 Train acc: 0.868333\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.463180 Train acc: 0.880000\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.377714 Validation acc: 0.924444\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.453891 Train acc: 0.868333\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.452055 Train acc: 0.886667\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.521565 Train acc: 0.845000\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.502278 Train acc: 0.856667\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.425351 Train acc: 0.890000\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.359965 Validation acc: 0.929444\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.439132 Train acc: 0.880000\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.425137 Train acc: 0.896667\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.437421 Train acc: 0.893333\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.442206 Train acc: 0.883333\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.433206 Train acc: 0.893333\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.345442 Validation acc: 0.933889\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.417166 Train acc: 0.905000\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.460535 Train acc: 0.885000\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.461185 Train acc: 0.890000\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.411592 Train acc: 0.898333\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.441015 Train acc: 0.890000\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.328676 Validation acc: 0.938333\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.412640 Train acc: 0.908333\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.422305 Train acc: 0.906667\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.420621 Train acc: 0.903333\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.435647 Train acc: 0.905000\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.398015 Train acc: 0.925000\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.313727 Validation acc: 0.938333\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.421149 Train acc: 0.905000\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.452491 Train acc: 0.891667\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.392259 Train acc: 0.905000\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.391502 Train acc: 0.915000\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.373860 Train acc: 0.920000\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.299729 Validation acc: 0.941667\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.398748 Train acc: 0.913333\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.381060 Train acc: 0.930000\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.399403 Train acc: 0.903333\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.380559 Train acc: 0.923333\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.415436 Train acc: 0.915000\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.288541 Validation acc: 0.946111\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.417223 Train acc: 0.916667\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.373108 Train acc: 0.923333\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.389546 Train acc: 0.911667\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.370888 Train acc: 0.916667\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.375340 Train acc: 0.933333\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.277018 Validation acc: 0.950000\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.373028 Train acc: 0.923333\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.358321 Train acc: 0.918333\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.351559 Train acc: 0.935000\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.375293 Train acc: 0.933333\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.383391 Train acc: 0.928333\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.266979 Validation acc: 0.948333\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.348216 Train acc: 0.930000\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.372536 Train acc: 0.926667\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.359290 Train acc: 0.931667\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.340276 Train acc: 0.936667\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.364989 Train acc: 0.928333\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.257473 Validation acc: 0.953333\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.355670 Train acc: 0.918333\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.340270 Train acc: 0.935000\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.363714 Train acc: 0.925000\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.370133 Train acc: 0.928333\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.325239 Train acc: 0.930000\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.252496 Validation acc: 0.947778\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.343671 Train acc: 0.923333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.334168 Train acc: 0.946667\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.351174 Train acc: 0.940000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.347692 Train acc: 0.930000\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.337356 Train acc: 0.938333\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.243761 Validation acc: 0.955000\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.331752 Train acc: 0.945000\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.348326 Train acc: 0.925000\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.340241 Train acc: 0.933333\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.326187 Train acc: 0.923333\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.329513 Train acc: 0.936667\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.238432 Validation acc: 0.953889\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.319500 Train acc: 0.938333\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.339653 Train acc: 0.933333\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.331696 Train acc: 0.926667\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.336131 Train acc: 0.931667\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.314774 Train acc: 0.943333\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.231340 Validation acc: 0.955556\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.344941 Train acc: 0.920000\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.352724 Train acc: 0.930000\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.309836 Train acc: 0.941667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.322175 Train acc: 0.940000\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.314482 Train acc: 0.935000\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.226723 Validation acc: 0.956111\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.298569 Train acc: 0.941667\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.311561 Train acc: 0.945000\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.301942 Train acc: 0.933333\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.283937 Train acc: 0.953333\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.320868 Train acc: 0.925000\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.221250 Validation acc: 0.955556\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.347144 Train acc: 0.930000\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.277205 Train acc: 0.946667\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.300796 Train acc: 0.946667\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.299523 Train acc: 0.928333\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.299057 Train acc: 0.948333\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.218330 Validation acc: 0.953333\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.293158 Train acc: 0.931667\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.327244 Train acc: 0.931667\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.289562 Train acc: 0.946667\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.314152 Train acc: 0.928333\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.326747 Train acc: 0.938333\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.214723 Validation acc: 0.952778\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.304033 Train acc: 0.940000\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.295454 Train acc: 0.936667\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.304002 Train acc: 0.936667\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.311425 Train acc: 0.938333\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.301723 Train acc: 0.941667\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.210074 Validation acc: 0.954444\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.301391 Train acc: 0.938333\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.283818 Train acc: 0.948333\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.325606 Train acc: 0.923333\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.321377 Train acc: 0.933333\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.302115 Train acc: 0.930000\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.207044 Validation acc: 0.952778\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.279315 Train acc: 0.943333\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.291893 Train acc: 0.936667\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.299747 Train acc: 0.943333\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.303895 Train acc: 0.935000\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.306930 Train acc: 0.926667\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.201266 Validation acc: 0.955555\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.283167 Train acc: 0.948333\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.310939 Train acc: 0.921667\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.314881 Train acc: 0.935000\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.273514 Train acc: 0.948333\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.281024 Train acc: 0.946667\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.198702 Validation acc: 0.953333\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.286984 Train acc: 0.938333\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.319309 Train acc: 0.936667\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.280368 Train acc: 0.941667\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.277585 Train acc: 0.935000\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.260418 Train acc: 0.953333\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.194992 Validation acc: 0.953889\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.324051 Train acc: 0.915000\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.291951 Train acc: 0.935000\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.273841 Train acc: 0.945000\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.282377 Train acc: 0.933333\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.272868 Train acc: 0.945000\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.191914 Validation acc: 0.955000\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.266766 Train acc: 0.951667\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.277411 Train acc: 0.943333\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.274390 Train acc: 0.940000\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.259771 Train acc: 0.953333\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.292296 Train acc: 0.926667\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.187162 Validation acc: 0.955555\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.282535 Train acc: 0.945000\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.247033 Train acc: 0.943333\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.280203 Train acc: 0.943333\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.292134 Train acc: 0.938333\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.278559 Train acc: 0.943333\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.184913 Validation acc: 0.953889\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.268849 Train acc: 0.950000\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.287867 Train acc: 0.930000\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.252502 Train acc: 0.945000\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.296318 Train acc: 0.921667\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.294353 Train acc: 0.935000\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.184299 Validation acc: 0.953889\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.258440 Train acc: 0.948333\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.285420 Train acc: 0.933333\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.260061 Train acc: 0.946667\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.259635 Train acc: 0.938333\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.283715 Train acc: 0.943333\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.179447 Validation acc: 0.954444\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.262216 Train acc: 0.941667\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.228037 Train acc: 0.961667\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.275426 Train acc: 0.931667\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.286168 Train acc: 0.933333\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.258760 Train acc: 0.950000\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.179033 Validation acc: 0.953333\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.252486 Train acc: 0.941667\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.246975 Train acc: 0.941667\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.255402 Train acc: 0.951667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.261601 Train acc: 0.936667\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.262438 Train acc: 0.941667\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.176006 Validation acc: 0.955000\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.238417 Train acc: 0.955000\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.278516 Train acc: 0.930000\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.278877 Train acc: 0.943333\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.251899 Train acc: 0.943333\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.256765 Train acc: 0.945000\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.172250 Validation acc: 0.954444\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.237875 Train acc: 0.945000\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.240105 Train acc: 0.946667\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.250251 Train acc: 0.945000\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.236353 Train acc: 0.938333\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.222639 Train acc: 0.956667\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.170503 Validation acc: 0.956111\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.287645 Train acc: 0.925000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.277936 Train acc: 0.940000\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.251360 Train acc: 0.948333\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.236833 Train acc: 0.950000\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.238597 Train acc: 0.945000\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.169642 Validation acc: 0.954444\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.243568 Train acc: 0.951667\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.243298 Train acc: 0.943333\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.253961 Train acc: 0.935000\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.224715 Train acc: 0.956667\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.271252 Train acc: 0.928333\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.169866 Validation acc: 0.953333\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.254658 Train acc: 0.943333\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.227459 Train acc: 0.951667\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.247231 Train acc: 0.936667\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.238312 Train acc: 0.948333\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.233564 Train acc: 0.951667\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.165144 Validation acc: 0.953889\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.254103 Train acc: 0.936667\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.256386 Train acc: 0.941667\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.234060 Train acc: 0.955000\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.260934 Train acc: 0.923333\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.246206 Train acc: 0.946667\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.165434 Validation acc: 0.953333\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.232745 Train acc: 0.946667\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.260830 Train acc: 0.941667\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.221907 Train acc: 0.948333\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.251631 Train acc: 0.946667\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.240287 Train acc: 0.943333\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.163937 Validation acc: 0.952222\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.231847 Train acc: 0.941667\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.218406 Train acc: 0.955000\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.262633 Train acc: 0.928333\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.237152 Train acc: 0.950000\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.221908 Train acc: 0.950000\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.162965 Validation acc: 0.951667\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.234745 Train acc: 0.936667\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.234423 Train acc: 0.945000\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.224240 Train acc: 0.951667\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.233010 Train acc: 0.943333\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.234641 Train acc: 0.933333\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.159614 Validation acc: 0.953333\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.207214 Train acc: 0.950000\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.256726 Train acc: 0.926667\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.252557 Train acc: 0.945000\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.218714 Train acc: 0.951667\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.227723 Train acc: 0.950000\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.161696 Validation acc: 0.951111\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.226142 Train acc: 0.943333\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.214326 Train acc: 0.956667\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.233757 Train acc: 0.950000\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.249773 Train acc: 0.938333\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.202948 Train acc: 0.955000\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.159735 Validation acc: 0.951667\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.257770 Train acc: 0.935000\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.242225 Train acc: 0.948333\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.215326 Train acc: 0.951667\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.249794 Train acc: 0.948333\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.212250 Train acc: 0.956667\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.159975 Validation acc: 0.951111\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.210979 Train acc: 0.961667\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.234096 Train acc: 0.941667\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.231158 Train acc: 0.946667\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.210300 Train acc: 0.961667\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.230729 Train acc: 0.933333\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.155319 Validation acc: 0.952222\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.228853 Train acc: 0.938333\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.217726 Train acc: 0.948333\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.210998 Train acc: 0.951667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.199113 Train acc: 0.956667\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.192400 Train acc: 0.965000\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.154342 Validation acc: 0.951667\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.224208 Train acc: 0.951667\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.228992 Train acc: 0.946667\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.204429 Train acc: 0.951667\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.240336 Train acc: 0.935000\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.240982 Train acc: 0.935000\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.150704 Validation acc: 0.952778\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.204412 Train acc: 0.956667\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.216439 Train acc: 0.946667\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.217170 Train acc: 0.950000\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.205889 Train acc: 0.956667\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.216104 Train acc: 0.943333\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.148317 Validation acc: 0.954444\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.230333 Train acc: 0.936667\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.191293 Train acc: 0.958333\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.239853 Train acc: 0.931667\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.204067 Train acc: 0.948333\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.208503 Train acc: 0.956667\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.148232 Validation acc: 0.953333\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.208615 Train acc: 0.958333\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.197145 Train acc: 0.953333\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.191258 Train acc: 0.965000\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.222791 Train acc: 0.943333\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.227602 Train acc: 0.935000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.146528 Validation acc: 0.953333\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.182554 Train acc: 0.961667\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.237372 Train acc: 0.923333\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.231389 Train acc: 0.936667\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.221270 Train acc: 0.948333\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.202682 Train acc: 0.950000\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.146911 Validation acc: 0.953333\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.185252 Train acc: 0.958333\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.193255 Train acc: 0.965000\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.196199 Train acc: 0.943333\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.227750 Train acc: 0.941667\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.193549 Train acc: 0.958333\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.147592 Validation acc: 0.950556\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.251352 Train acc: 0.925000\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.201876 Train acc: 0.945000\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.201598 Train acc: 0.945000\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.211457 Train acc: 0.946667\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.191711 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.143703 Validation acc: 0.952222\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.204042 Train acc: 0.956667\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.205634 Train acc: 0.943333\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.201545 Train acc: 0.941667\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.187420 Train acc: 0.960000\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.221489 Train acc: 0.931667\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.143000 Validation acc: 0.953333\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.216329 Train acc: 0.945000\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.206628 Train acc: 0.953333\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.197337 Train acc: 0.941667\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.180062 Train acc: 0.960000\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.187993 Train acc: 0.963333\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.143448 Validation acc: 0.952222\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.214875 Train acc: 0.945000\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.237264 Train acc: 0.935000\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.181489 Train acc: 0.958333\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.218251 Train acc: 0.926667\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.209997 Train acc: 0.955000\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.145290 Validation acc: 0.950000\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.193422 Train acc: 0.951667\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.195843 Train acc: 0.950000\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.183740 Train acc: 0.951667\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.190116 Train acc: 0.956667\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.203621 Train acc: 0.953333\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.140610 Validation acc: 0.951667\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.214740 Train acc: 0.940000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.183389 Train acc: 0.960000\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.219856 Train acc: 0.940000\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.209110 Train acc: 0.951667\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.184779 Train acc: 0.956667\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.139907 Validation acc: 0.951111\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.211780 Train acc: 0.946667\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.179499 Train acc: 0.951667\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.176227 Train acc: 0.965000\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.203602 Train acc: 0.945000\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.209543 Train acc: 0.940000\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.140012 Validation acc: 0.950556\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.174444 Train acc: 0.950000\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.229907 Train acc: 0.931667\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.212670 Train acc: 0.941667\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.176735 Train acc: 0.953333\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.185057 Train acc: 0.953333\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.140546 Validation acc: 0.950556\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.181341 Train acc: 0.955000\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.185608 Train acc: 0.961667\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.197454 Train acc: 0.943333\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.210840 Train acc: 0.943333\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.176640 Train acc: 0.961667\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.141156 Validation acc: 0.950000\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.218318 Train acc: 0.930000\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.220222 Train acc: 0.948333\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.186059 Train acc: 0.955000\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.194897 Train acc: 0.948333\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.176526 Train acc: 0.953333\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.134896 Validation acc: 0.952222\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.182234 Train acc: 0.963333\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.188336 Train acc: 0.958333\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.206235 Train acc: 0.936667\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.174479 Train acc: 0.961667\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.210811 Train acc: 0.930000\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.137243 Validation acc: 0.954444\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.196971 Train acc: 0.953333\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.194517 Train acc: 0.946667\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.182636 Train acc: 0.956667\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.172590 Train acc: 0.948333\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.174890 Train acc: 0.958333\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.133817 Validation acc: 0.951667\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.191904 Train acc: 0.946667\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.202083 Train acc: 0.943333\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.166566 Train acc: 0.956667\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.209022 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.194765 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.133568 Validation acc: 0.954444\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.185292 Train acc: 0.956667\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.188699 Train acc: 0.951667\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.162540 Train acc: 0.958333\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.166344 Train acc: 0.965000\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.184476 Train acc: 0.948333\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.131327 Validation acc: 0.954444\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.198313 Train acc: 0.948333\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.159716 Train acc: 0.956667\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.206266 Train acc: 0.931667\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.198761 Train acc: 0.945000\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.179261 Train acc: 0.958333\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.132903 Validation acc: 0.955000\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.178471 Train acc: 0.953333\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.156522 Train acc: 0.955000\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.183285 Train acc: 0.963333\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.180043 Train acc: 0.946667\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.208376 Train acc: 0.933333\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.131606 Validation acc: 0.953889\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.156838 Train acc: 0.958333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.209708 Train acc: 0.930000\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.190484 Train acc: 0.950000\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.178002 Train acc: 0.950000\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.191503 Train acc: 0.940000\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.131811 Validation acc: 0.955555\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.158459 Train acc: 0.950000\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.167354 Train acc: 0.951667\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.192775 Train acc: 0.950000\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.196972 Train acc: 0.938333\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.156747 Train acc: 0.968333\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.132264 Validation acc: 0.954444\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.203892 Train acc: 0.933333\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.201415 Train acc: 0.943333\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.173663 Train acc: 0.956667\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.192814 Train acc: 0.943333\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.164391 Train acc: 0.958333\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.129419 Validation acc: 0.955000\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.180259 Train acc: 0.956667\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.180240 Train acc: 0.953333\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.203486 Train acc: 0.938333\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.156149 Train acc: 0.960000\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.203432 Train acc: 0.926667\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.128472 Validation acc: 0.956667\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.193215 Train acc: 0.951667\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.166279 Train acc: 0.951667\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.168790 Train acc: 0.956667\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.162852 Train acc: 0.958333\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.167300 Train acc: 0.961667\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.133966 Validation acc: 0.955000\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.175227 Train acc: 0.958333\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.188740 Train acc: 0.948333\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.161004 Train acc: 0.956667\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.191090 Train acc: 0.943333\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.194707 Train acc: 0.955000\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.128289 Validation acc: 0.955000\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.165868 Train acc: 0.953333\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.151422 Train acc: 0.958333\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.156249 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.172237 Train acc: 0.960000\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.167731 Train acc: 0.951667\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.132427 Validation acc: 0.955000\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.199087 Train acc: 0.938333\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.150722 Train acc: 0.963333\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.197634 Train acc: 0.933333\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.168925 Train acc: 0.953333\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.170186 Train acc: 0.950000\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.127130 Validation acc: 0.953333\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.180078 Train acc: 0.951667\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.180001 Train acc: 0.948333\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.161767 Train acc: 0.956667\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.172208 Train acc: 0.951667\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.198875 Train acc: 0.941667\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.131349 Validation acc: 0.955000\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.158085 Train acc: 0.965000\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.203689 Train acc: 0.923333\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.179392 Train acc: 0.953333\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.168913 Train acc: 0.950000\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.168415 Train acc: 0.955000\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.126707 Validation acc: 0.952222\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.160820 Train acc: 0.950000\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.164597 Train acc: 0.956667\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.175247 Train acc: 0.948333\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.177222 Train acc: 0.948333\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.147485 Train acc: 0.963333\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.128598 Validation acc: 0.953333\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.202437 Train acc: 0.933333\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.185340 Train acc: 0.955000\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.174705 Train acc: 0.951667\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.170404 Train acc: 0.956667\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.158120 Train acc: 0.961667\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.127528 Validation acc: 0.953333\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.150122 Train acc: 0.968333\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.172618 Train acc: 0.953333\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.187837 Train acc: 0.941667\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.143943 Train acc: 0.960000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.189990 Train acc: 0.946667\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.128983 Validation acc: 0.956111\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.189118 Train acc: 0.940000\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.163753 Train acc: 0.951667\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.162089 Train acc: 0.960000\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.149640 Train acc: 0.958333\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.160882 Train acc: 0.960000\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.129049 Validation acc: 0.953889\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.173686 Train acc: 0.948333\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.186876 Train acc: 0.940000\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.161685 Train acc: 0.961667\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.184129 Train acc: 0.940000\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.188508 Train acc: 0.946667\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.128540 Validation acc: 0.955555\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.168847 Train acc: 0.953333\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.159325 Train acc: 0.955000\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.147930 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.145608 Train acc: 0.961667\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.170334 Train acc: 0.953333\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.130184 Validation acc: 0.954444\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.181380 Train acc: 0.940000\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.137819 Train acc: 0.961667\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.193708 Train acc: 0.941667\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.172723 Train acc: 0.953333\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.158996 Train acc: 0.960000\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.131598 Validation acc: 0.952778\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.170581 Train acc: 0.958333\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.142613 Train acc: 0.956667\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.156713 Train acc: 0.961667\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.164605 Train acc: 0.960000\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.185292 Train acc: 0.938333\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.130512 Validation acc: 0.953333\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.139944 Train acc: 0.961667\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.172902 Train acc: 0.935000\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.170497 Train acc: 0.953333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.150279 Train acc: 0.961667\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.170499 Train acc: 0.950000\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.129582 Validation acc: 0.954444\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.145648 Train acc: 0.960000\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.170713 Train acc: 0.961667\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.159141 Train acc: 0.960000\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.183746 Train acc: 0.943333\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.142249 Train acc: 0.960000\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.125814 Validation acc: 0.955000\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.184816 Train acc: 0.941667\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.175880 Train acc: 0.950000\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.148689 Train acc: 0.961667\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.154774 Train acc: 0.953333\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.146325 Train acc: 0.956667\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.127182 Validation acc: 0.952222\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.147310 Train acc: 0.961667\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.170834 Train acc: 0.958333\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.177548 Train acc: 0.933333\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.142245 Train acc: 0.966667\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.175680 Train acc: 0.931667\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.128519 Validation acc: 0.948889\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.165802 Train acc: 0.953333\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.164099 Train acc: 0.948333\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.149526 Train acc: 0.953333\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.134031 Train acc: 0.958333\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.155246 Train acc: 0.963333\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.127488 Validation acc: 0.952778\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.158994 Train acc: 0.953333\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.173244 Train acc: 0.950000\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.129806 Train acc: 0.966667\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.181517 Train acc: 0.940000\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.174648 Train acc: 0.946667\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.126419 Validation acc: 0.953333\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.160809 Train acc: 0.953333\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.159960 Train acc: 0.956667\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.147471 Train acc: 0.950000\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.151090 Train acc: 0.968333\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.151867 Train acc: 0.953333\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.125483 Validation acc: 0.954444\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.167242 Train acc: 0.940000\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.133882 Train acc: 0.963333\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.204717 Train acc: 0.921667\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.163617 Train acc: 0.953333\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.155759 Train acc: 0.951667\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.127134 Validation acc: 0.953889\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.168843 Train acc: 0.951667\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.141540 Train acc: 0.951667\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.166244 Train acc: 0.961667\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.168903 Train acc: 0.938333\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.170029 Train acc: 0.938333\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.125143 Validation acc: 0.953889\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.129081 Train acc: 0.960000\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.171260 Train acc: 0.930000\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.164129 Train acc: 0.950000\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.161116 Train acc: 0.956667\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.161377 Train acc: 0.958333\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.127765 Validation acc: 0.953889\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.144405 Train acc: 0.948333\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.136837 Train acc: 0.968333\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.160177 Train acc: 0.948333\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.173355 Train acc: 0.938333\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.121225 Train acc: 0.970000\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.130691 Validation acc: 0.952222\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.169454 Train acc: 0.925000\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.168812 Train acc: 0.953333\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.144893 Train acc: 0.955000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.151974 Train acc: 0.955000\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.135996 Train acc: 0.956667\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.124560 Validation acc: 0.953333\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.147521 Train acc: 0.961667\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.164394 Train acc: 0.950000\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.179635 Train acc: 0.938333\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.115276 Train acc: 0.971667\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.195610 Train acc: 0.923333\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.125325 Validation acc: 0.953333\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.167663 Train acc: 0.951667\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.148506 Train acc: 0.963333\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.154704 Train acc: 0.955000\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.130819 Train acc: 0.961667\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.139596 Train acc: 0.965000\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.124653 Validation acc: 0.953889\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.151442 Train acc: 0.956667\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.173932 Train acc: 0.941667\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.130251 Train acc: 0.956667\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.150539 Train acc: 0.946667\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.165834 Train acc: 0.953333\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.118362 Validation acc: 0.955000\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.150415 Train acc: 0.955000\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.149051 Train acc: 0.960000\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.129047 Train acc: 0.955000\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.146580 Train acc: 0.961667\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.161435 Train acc: 0.956667\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.124338 Validation acc: 0.954444\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.168253 Train acc: 0.950000\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.126996 Train acc: 0.966667\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.180104 Train acc: 0.936667\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.163609 Train acc: 0.951667\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.158601 Train acc: 0.955000\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.126739 Validation acc: 0.953333\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.143730 Train acc: 0.955000\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.142099 Train acc: 0.951667\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.140179 Train acc: 0.960000\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.159516 Train acc: 0.950000\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.169246 Train acc: 0.941667\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.127673 Validation acc: 0.952778\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.117294 Train acc: 0.961667\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.167200 Train acc: 0.940000\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.151489 Train acc: 0.953333\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.150745 Train acc: 0.950000\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.159418 Train acc: 0.950000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.116718 Validation acc: 0.955000\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.135488 Train acc: 0.953333\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.154036 Train acc: 0.956667\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.167325 Train acc: 0.950000\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.159848 Train acc: 0.935000\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.122309 Train acc: 0.971667\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.127948 Validation acc: 0.953333\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.167859 Train acc: 0.935000\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.151867 Train acc: 0.956667\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.142811 Train acc: 0.955000\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.151512 Train acc: 0.946667\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.138555 Train acc: 0.960000\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.126743 Validation acc: 0.953333\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.136396 Train acc: 0.960000\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.135410 Train acc: 0.960000\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.161009 Train acc: 0.946667\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.111476 Train acc: 0.973333\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.169484 Train acc: 0.936667\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.127253 Validation acc: 0.953333\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.170261 Train acc: 0.951667\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.146805 Train acc: 0.955000\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.162187 Train acc: 0.950000\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.130718 Train acc: 0.960000\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.138604 Train acc: 0.960000\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.126817 Validation acc: 0.953889\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.148191 Train acc: 0.958333\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.154030 Train acc: 0.948333\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.122418 Train acc: 0.971667\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.161959 Train acc: 0.941667\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.157434 Train acc: 0.945000\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.127110 Validation acc: 0.952778\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.152681 Train acc: 0.948333\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.153025 Train acc: 0.951667\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.135169 Train acc: 0.958333\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.135284 Train acc: 0.963333\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.138396 Train acc: 0.956667\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.126127 Validation acc: 0.952778\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.162986 Train acc: 0.940000\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.107387 Train acc: 0.970000\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.178465 Train acc: 0.930000\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.155709 Train acc: 0.950000\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.146889 Train acc: 0.956667\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.124989 Validation acc: 0.951667\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.143991 Train acc: 0.948333\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.118538 Train acc: 0.965000\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.134748 Train acc: 0.955000\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.151061 Train acc: 0.948333\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.155074 Train acc: 0.943333\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.122342 Validation acc: 0.953333\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.118708 Train acc: 0.961667\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.174290 Train acc: 0.936667\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.157659 Train acc: 0.953333\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.135601 Train acc: 0.956667\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.154999 Train acc: 0.951667\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.125828 Validation acc: 0.952778\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.127607 Train acc: 0.956667\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.140097 Train acc: 0.963333\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.145389 Train acc: 0.956667\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.157796 Train acc: 0.951667\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.118979 Train acc: 0.970000\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.125698 Validation acc: 0.951667\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.168330 Train acc: 0.945000\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.141090 Train acc: 0.953333\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.135969 Train acc: 0.951667\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.134957 Train acc: 0.955000\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.134311 Train acc: 0.953333\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.123820 Validation acc: 0.952778\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.129609 Train acc: 0.968333\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.142890 Train acc: 0.961667\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.156155 Train acc: 0.938333\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.107441 Train acc: 0.965000\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.171492 Train acc: 0.938333\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.125318 Validation acc: 0.953333\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.150518 Train acc: 0.951667\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.137859 Train acc: 0.956667\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.137916 Train acc: 0.955000\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.136212 Train acc: 0.953333\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.146033 Train acc: 0.961667\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.125649 Validation acc: 0.952222\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.147617 Train acc: 0.953333\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.165941 Train acc: 0.943333\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.130474 Train acc: 0.956667\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.159598 Train acc: 0.940000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.156457 Train acc: 0.945000\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.126049 Validation acc: 0.950556\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.141119 Train acc: 0.960000\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.136282 Train acc: 0.958333\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.120494 Train acc: 0.956667\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.139834 Train acc: 0.965000\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.152136 Train acc: 0.950000\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.126050 Validation acc: 0.953333\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.166153 Train acc: 0.938333\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.121164 Train acc: 0.956667\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.177127 Train acc: 0.930000\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.154248 Train acc: 0.956667\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.136236 Train acc: 0.955000\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.123533 Validation acc: 0.953333\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.153640 Train acc: 0.953333\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.127415 Train acc: 0.961667\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.141647 Train acc: 0.965000\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.140530 Train acc: 0.955000\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.177546 Train acc: 0.943333\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.123729 Validation acc: 0.952778\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.105026 Train acc: 0.973333\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.153737 Train acc: 0.950000\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.145085 Train acc: 0.958333\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.143119 Train acc: 0.955000\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.135091 Train acc: 0.950000\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.124033 Validation acc: 0.952778\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.132253 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.130569 Train acc: 0.966667\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.137585 Train acc: 0.961667\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.147482 Train acc: 0.950000\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.108999 Train acc: 0.966667\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.123977 Validation acc: 0.952222\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.160307 Train acc: 0.931667\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.149051 Train acc: 0.946667\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.149542 Train acc: 0.955000\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.144840 Train acc: 0.960000\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.123406 Train acc: 0.956667\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.123355 Validation acc: 0.952222\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.127427 Train acc: 0.958333\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.150781 Train acc: 0.956667\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.147026 Train acc: 0.943333\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.116196 Train acc: 0.971667\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.159626 Train acc: 0.933333\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.124616 Validation acc: 0.954444\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.148287 Train acc: 0.960000\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.144862 Train acc: 0.948333\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.146638 Train acc: 0.945000\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.117445 Train acc: 0.958333\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.114766 Train acc: 0.970000\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.125074 Validation acc: 0.953333\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.145329 Train acc: 0.953333\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.142773 Train acc: 0.953333\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.118683 Train acc: 0.963333\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.166131 Train acc: 0.931667\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.145459 Train acc: 0.951667\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.123714 Validation acc: 0.951667\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.128006 Train acc: 0.951667\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.147557 Train acc: 0.961667\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.128811 Train acc: 0.955000\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.119472 Train acc: 0.965000\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.137294 Train acc: 0.951667\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.122748 Validation acc: 0.952222\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.155870 Train acc: 0.940000\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.101808 Train acc: 0.971667\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.159077 Train acc: 0.946667\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.141291 Train acc: 0.953333\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.128921 Train acc: 0.960000\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.123065 Validation acc: 0.954444\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.147427 Train acc: 0.945000\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.114361 Train acc: 0.965000\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.143484 Train acc: 0.960000\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.133801 Train acc: 0.963333\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.163422 Train acc: 0.938333\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.122446 Validation acc: 0.954444\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.110625 Train acc: 0.960000\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.169044 Train acc: 0.936667\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.155426 Train acc: 0.955000\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.128205 Train acc: 0.953333\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.139438 Train acc: 0.951667\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.124039 Validation acc: 0.951667\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.119138 Train acc: 0.960000\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.131797 Train acc: 0.958333\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.144265 Train acc: 0.956667\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.140544 Train acc: 0.945000\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.101908 Train acc: 0.971667\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.126591 Validation acc: 0.952778\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.154771 Train acc: 0.936667\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.141536 Train acc: 0.955000\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.124462 Train acc: 0.953333\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.129932 Train acc: 0.960000\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.124659 Train acc: 0.951667\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.125947 Validation acc: 0.952778\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.135624 Train acc: 0.968333\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.141892 Train acc: 0.956667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.164443 Train acc: 0.930000\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.102704 Train acc: 0.973333\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.180714 Train acc: 0.926667\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.126939 Validation acc: 0.952778\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.137745 Train acc: 0.943333\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.141081 Train acc: 0.956667\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.129235 Train acc: 0.950000\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.113956 Train acc: 0.966667\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.120872 Train acc: 0.968333\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.126672 Validation acc: 0.955555\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.137838 Train acc: 0.950000\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.158271 Train acc: 0.930000\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.114017 Train acc: 0.966667\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.158448 Train acc: 0.935000\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.145774 Train acc: 0.951667\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.120865 Validation acc: 0.952222\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.130354 Train acc: 0.956667\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.128219 Train acc: 0.956667\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.122072 Train acc: 0.960000\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.133411 Train acc: 0.963333\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.139756 Train acc: 0.958333\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.119975 Validation acc: 0.954444\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.144679 Train acc: 0.938333\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.100817 Train acc: 0.970000\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.161880 Train acc: 0.928333\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.140867 Train acc: 0.960000\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.138427 Train acc: 0.956667\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.123186 Validation acc: 0.951111\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.128320 Train acc: 0.958333\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.120394 Train acc: 0.961667\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.134358 Train acc: 0.968333\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.140339 Train acc: 0.950000\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.155664 Train acc: 0.938333\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.122700 Validation acc: 0.953889\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.099250 Train acc: 0.971667\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.167867 Train acc: 0.940000\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.146959 Train acc: 0.955000\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.126943 Train acc: 0.953333\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.129743 Train acc: 0.956667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.123030 Validation acc: 0.953889\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.116003 Train acc: 0.961667\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.140232 Train acc: 0.961667\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.128603 Train acc: 0.946667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.148683 Train acc: 0.943333\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.110159 Train acc: 0.965000\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.120275 Validation acc: 0.952778\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.145805 Train acc: 0.943333\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.149757 Train acc: 0.946667\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.119827 Train acc: 0.963333\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.135467 Train acc: 0.958333\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.101279 Train acc: 0.961667\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.121144 Validation acc: 0.952222\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.114991 Train acc: 0.960000\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.124864 Train acc: 0.953333\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.138873 Train acc: 0.946667\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.107671 Train acc: 0.965000\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.159252 Train acc: 0.938333\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.121302 Validation acc: 0.953889\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.149592 Train acc: 0.950000\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.136716 Train acc: 0.960000\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.129950 Train acc: 0.950000\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.116763 Train acc: 0.963333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.126083 Train acc: 0.958333\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.120818 Validation acc: 0.952222\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.140461 Train acc: 0.956667\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.139586 Train acc: 0.941667\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.092034 Train acc: 0.970000\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.154803 Train acc: 0.940000\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.147003 Train acc: 0.955000\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.122126 Validation acc: 0.951667\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.136352 Train acc: 0.945000\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.142559 Train acc: 0.951667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.115561 Train acc: 0.955000\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.142426 Train acc: 0.961667\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.132581 Train acc: 0.953333\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.120766 Validation acc: 0.952222\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.140572 Train acc: 0.943333\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.106642 Train acc: 0.971667\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.156450 Train acc: 0.931667\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.140790 Train acc: 0.950000\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.128092 Train acc: 0.950000\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.121842 Validation acc: 0.955000\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.129950 Train acc: 0.958333\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.114644 Train acc: 0.958333\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.117692 Train acc: 0.968333\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.131043 Train acc: 0.958333\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.139655 Train acc: 0.938333\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.120334 Validation acc: 0.955556\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.099314 Train acc: 0.966667\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.153782 Train acc: 0.936667\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.137063 Train acc: 0.956667\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.141436 Train acc: 0.950000\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.139914 Train acc: 0.960000\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.119753 Validation acc: 0.953889\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.108908 Train acc: 0.961667\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.118586 Train acc: 0.963333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.132050 Train acc: 0.960000\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.148087 Train acc: 0.948333\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.094327 Train acc: 0.976667\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.123723 Validation acc: 0.953333\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.158286 Train acc: 0.926667\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.143051 Train acc: 0.953333\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.137789 Train acc: 0.951667\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.134560 Train acc: 0.955000\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.109952 Train acc: 0.963333\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.119140 Validation acc: 0.951667\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.132322 Train acc: 0.968333\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.138416 Train acc: 0.958333\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.164229 Train acc: 0.925000\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.103618 Train acc: 0.963333\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.147085 Train acc: 0.941667\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.118123 Validation acc: 0.953333\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.153377 Train acc: 0.953333\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.124874 Train acc: 0.955000\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.127843 Train acc: 0.963333\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.115972 Train acc: 0.955000\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.129350 Train acc: 0.958333\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.123349 Validation acc: 0.953333\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.140720 Train acc: 0.951667\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.152150 Train acc: 0.935000\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.095032 Train acc: 0.971667\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.161379 Train acc: 0.933333\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.129651 Train acc: 0.951667\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.121032 Validation acc: 0.953333\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.120118 Train acc: 0.966667\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.137777 Train acc: 0.941667\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.106844 Train acc: 0.960000\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.127977 Train acc: 0.960000\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.135805 Train acc: 0.955000\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.122447 Validation acc: 0.952222\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.136932 Train acc: 0.938333\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.096862 Train acc: 0.970000\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.158601 Train acc: 0.926667\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.148314 Train acc: 0.951667\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.115800 Train acc: 0.963333\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.118079 Validation acc: 0.952778\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.127130 Train acc: 0.956667\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.109152 Train acc: 0.960000\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.110033 Train acc: 0.963333\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.134735 Train acc: 0.953333\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.135914 Train acc: 0.943333\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.115106 Validation acc: 0.953889\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.095627 Train acc: 0.970000\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.154991 Train acc: 0.931667\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.141956 Train acc: 0.963333\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.130990 Train acc: 0.958333\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.129187 Train acc: 0.961667\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.116056 Validation acc: 0.953889\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.115991 Train acc: 0.955000\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.105512 Train acc: 0.971667\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.131840 Train acc: 0.963333\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.141065 Train acc: 0.946667\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.104833 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.115042 Validation acc: 0.954444\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.158405 Train acc: 0.930000\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.136431 Train acc: 0.948333\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.118648 Train acc: 0.963333\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.132067 Train acc: 0.950000\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.111042 Train acc: 0.960000\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.112197 Validation acc: 0.953889\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.123012 Train acc: 0.963333\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.131863 Train acc: 0.951667\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.135837 Train acc: 0.948333\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.094846 Train acc: 0.966667\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.157781 Train acc: 0.930000\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.118245 Validation acc: 0.952778\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.142744 Train acc: 0.955000\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.117383 Train acc: 0.955000\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.125659 Train acc: 0.953333\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.111910 Train acc: 0.961667\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.124442 Train acc: 0.961667\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.118109 Validation acc: 0.953889\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.132020 Train acc: 0.951667\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.141601 Train acc: 0.943333\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.095865 Train acc: 0.970000\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.157538 Train acc: 0.940000\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.144036 Train acc: 0.950000\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.120082 Validation acc: 0.953333\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.133566 Train acc: 0.950000\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.145183 Train acc: 0.948333\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.108038 Train acc: 0.960000\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.133393 Train acc: 0.960000\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.128956 Train acc: 0.948333\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.120222 Validation acc: 0.952778\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.132874 Train acc: 0.946667\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.095304 Train acc: 0.960000\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.139792 Train acc: 0.941667\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.129827 Train acc: 0.956667\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.113690 Train acc: 0.963333\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.118858 Validation acc: 0.953889\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.118591 Train acc: 0.958333\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.105758 Train acc: 0.958333\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.120633 Train acc: 0.960000\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.127881 Train acc: 0.961667\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.138460 Train acc: 0.955000\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.118768 Validation acc: 0.952778\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.089038 Train acc: 0.975000\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.149446 Train acc: 0.931667\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.131686 Train acc: 0.955000\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.121193 Train acc: 0.955000\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.133702 Train acc: 0.946667\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.118414 Validation acc: 0.953889\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.108459 Train acc: 0.953333\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.120272 Train acc: 0.956667\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.137706 Train acc: 0.953333\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.135788 Train acc: 0.941667\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.101231 Train acc: 0.965000\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.117343 Validation acc: 0.953889\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.151924 Train acc: 0.941667\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.138959 Train acc: 0.953333\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.133256 Train acc: 0.950000\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.125783 Train acc: 0.946667\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.096436 Train acc: 0.966667\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.118043 Validation acc: 0.953889\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.126790 Train acc: 0.960000\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.126364 Train acc: 0.955000\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.133436 Train acc: 0.950000\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.094005 Train acc: 0.965000\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.146412 Train acc: 0.940000\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.113927 Validation acc: 0.952778\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.135080 Train acc: 0.956667\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.125726 Train acc: 0.956667\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.118625 Train acc: 0.958333\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.101068 Train acc: 0.963333\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.121405 Train acc: 0.966667\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.112481 Validation acc: 0.954444\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.120797 Train acc: 0.960000\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.135660 Train acc: 0.945000\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.088408 Train acc: 0.973333\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.162460 Train acc: 0.928333\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.118153 Train acc: 0.958333\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.118578 Validation acc: 0.957222\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.126438 Train acc: 0.960000\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.123598 Train acc: 0.951667\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.098859 Train acc: 0.961667\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.134495 Train acc: 0.960000\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.125827 Train acc: 0.953333\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.115150 Validation acc: 0.952778\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.131238 Train acc: 0.945000\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.095838 Train acc: 0.966667\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.143792 Train acc: 0.933333\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.127732 Train acc: 0.956667\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.127031 Train acc: 0.953333\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.112544 Validation acc: 0.953889\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.125133 Train acc: 0.956667\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.110260 Train acc: 0.950000\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.121143 Train acc: 0.960000\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.131066 Train acc: 0.965000\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.135142 Train acc: 0.938333\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.113080 Validation acc: 0.957778\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.081248 Train acc: 0.968333\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.147500 Train acc: 0.935000\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.130075 Train acc: 0.956667\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.123128 Train acc: 0.963333\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.124386 Train acc: 0.950000\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.114454 Validation acc: 0.955000\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.107440 Train acc: 0.965000\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.115410 Train acc: 0.963333\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.122440 Train acc: 0.965000\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.139214 Train acc: 0.948333\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.084162 Train acc: 0.975000\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.112847 Validation acc: 0.953333\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.156141 Train acc: 0.938333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.143759 Train acc: 0.955000\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.127347 Train acc: 0.950000\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.117380 Train acc: 0.961667\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.103328 Train acc: 0.963333\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.112502 Validation acc: 0.955000\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.124003 Train acc: 0.968333\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.111879 Train acc: 0.961667\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.134205 Train acc: 0.948333\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.096378 Train acc: 0.971667\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.146502 Train acc: 0.931667\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.109077 Validation acc: 0.954444\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.141751 Train acc: 0.951667\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.139391 Train acc: 0.955000\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.116394 Train acc: 0.956667\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.094526 Train acc: 0.956667\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.115950 Train acc: 0.966667\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.109932 Validation acc: 0.953889\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.123597 Train acc: 0.955000\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.135072 Train acc: 0.948333\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.090236 Train acc: 0.976667\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.136553 Train acc: 0.936667\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.133492 Train acc: 0.956667\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.112501 Validation acc: 0.953889\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.122218 Train acc: 0.956667\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.114666 Train acc: 0.963333\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.102384 Train acc: 0.960000\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.112032 Train acc: 0.955000\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.112263 Train acc: 0.963333\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.113739 Validation acc: 0.953333\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.123063 Train acc: 0.951667\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.084131 Train acc: 0.970000\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.153265 Train acc: 0.930000\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.130381 Train acc: 0.953333\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.106842 Train acc: 0.958333\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.113263 Validation acc: 0.953889\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.115787 Train acc: 0.958333\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.102585 Train acc: 0.960000\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.121883 Train acc: 0.960000\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.125985 Train acc: 0.958333\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.139705 Train acc: 0.941667\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.109406 Validation acc: 0.957222\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.081786 Train acc: 0.978333\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.145764 Train acc: 0.940000\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.130678 Train acc: 0.951667\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.115881 Train acc: 0.955000\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.115781 Train acc: 0.955000\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.121197 Validation acc: 0.952222\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.103651 Train acc: 0.961667\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.113071 Train acc: 0.958333\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.112728 Train acc: 0.958333\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.138325 Train acc: 0.951667\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.087881 Train acc: 0.966667\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.110339 Validation acc: 0.955556\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.136982 Train acc: 0.933333\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.130183 Train acc: 0.950000\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.125278 Train acc: 0.958333\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.123993 Train acc: 0.950000\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.091519 Train acc: 0.961667\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.108945 Validation acc: 0.955000\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.133298 Train acc: 0.961667\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.129871 Train acc: 0.951667\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.120412 Train acc: 0.936667\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.084041 Train acc: 0.971667\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.139661 Train acc: 0.938333\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.114277 Validation acc: 0.957778\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.126355 Train acc: 0.951667\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.114261 Train acc: 0.953333\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.120409 Train acc: 0.956667\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.108389 Train acc: 0.955000\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.111068 Train acc: 0.966667\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.112237 Validation acc: 0.958889\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.112507 Train acc: 0.955000\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.124927 Train acc: 0.936667\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.089097 Train acc: 0.973333\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.138220 Train acc: 0.941667\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.120518 Train acc: 0.956667\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.112145 Validation acc: 0.955555\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.119633 Train acc: 0.960000\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.132786 Train acc: 0.951667\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.096547 Train acc: 0.960000\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.111200 Train acc: 0.963333\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.105482 Train acc: 0.960000\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.111855 Validation acc: 0.956667\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.133121 Train acc: 0.950000\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.087465 Train acc: 0.966667\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.145948 Train acc: 0.940000\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.130962 Train acc: 0.951667\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.115423 Train acc: 0.953333\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.111916 Validation acc: 0.956111\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.125354 Train acc: 0.953333\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.092521 Train acc: 0.970000\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.119479 Train acc: 0.966667\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.113782 Train acc: 0.963333\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.143451 Train acc: 0.946667\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.111952 Validation acc: 0.953889\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.077110 Train acc: 0.976667\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.151218 Train acc: 0.935000\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.119873 Train acc: 0.956667\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.112961 Train acc: 0.958333\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.110250 Train acc: 0.965000\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.123050 Validation acc: 0.955556\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.095942 Train acc: 0.965000\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.114622 Train acc: 0.966667\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.137397 Train acc: 0.953333\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.124949 Train acc: 0.953333\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.085063 Train acc: 0.976667\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.121203 Validation acc: 0.951667\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.136173 Train acc: 0.941667\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.128354 Train acc: 0.951667\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.115752 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.111730 Train acc: 0.955000\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.099750 Train acc: 0.968333\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.111064 Validation acc: 0.951667\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.115294 Train acc: 0.963333\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.117487 Train acc: 0.965000\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.135719 Train acc: 0.943333\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.086701 Train acc: 0.958333\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.145731 Train acc: 0.935000\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.108702 Validation acc: 0.952778\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.130831 Train acc: 0.960000\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.114238 Train acc: 0.958333\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.115127 Train acc: 0.951667\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.089893 Train acc: 0.963333\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.114606 Train acc: 0.970000\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.113164 Validation acc: 0.953333\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.107048 Train acc: 0.971667\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.122434 Train acc: 0.943333\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.077281 Train acc: 0.976667\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.141069 Train acc: 0.931667\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.129321 Train acc: 0.953333\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.111633 Validation acc: 0.951111\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.116295 Train acc: 0.958333\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.119674 Train acc: 0.956667\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.092184 Train acc: 0.970000\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.107964 Train acc: 0.966667\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.107438 Train acc: 0.966667\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.112162 Validation acc: 0.951667\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.131636 Train acc: 0.948333\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.089270 Train acc: 0.963333\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.141158 Train acc: 0.930000\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.137746 Train acc: 0.958333\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.119370 Train acc: 0.958333\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.104156 Validation acc: 0.952778\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.110145 Train acc: 0.963333\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.090142 Train acc: 0.966667\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.118119 Train acc: 0.961667\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.118914 Train acc: 0.968333\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.137020 Train acc: 0.946667\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.102375 Validation acc: 0.951667\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.080186 Train acc: 0.976667\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.147102 Train acc: 0.933333\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.127359 Train acc: 0.960000\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.114882 Train acc: 0.963333\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.108370 Train acc: 0.963333\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.106584 Validation acc: 0.952778\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.097985 Train acc: 0.968333\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.121320 Train acc: 0.961667\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.111451 Train acc: 0.966667\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.123622 Train acc: 0.956667\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.079516 Train acc: 0.976667\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.109022 Validation acc: 0.953889\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.147536 Train acc: 0.926667\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.120616 Train acc: 0.955000\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.108847 Train acc: 0.960000\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.110106 Train acc: 0.956667\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.083176 Train acc: 0.975000\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.111900 Validation acc: 0.953333\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.109097 Train acc: 0.958333\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.119333 Train acc: 0.973333\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.135141 Train acc: 0.943333\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.078540 Train acc: 0.976667\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.138152 Train acc: 0.933333\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.107834 Validation acc: 0.955556\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.126231 Train acc: 0.956667\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.110352 Train acc: 0.961667\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.110907 Train acc: 0.960000\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.097875 Train acc: 0.966667\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.108016 Train acc: 0.965000\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.108212 Validation acc: 0.955555\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.104546 Train acc: 0.970000\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.128634 Train acc: 0.953333\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.077299 Train acc: 0.978333\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.147452 Train acc: 0.940000\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.138204 Train acc: 0.960000\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.106794 Validation acc: 0.956667\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.109568 Train acc: 0.956667\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.127242 Train acc: 0.961667\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.094858 Train acc: 0.970000\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.120774 Train acc: 0.955000\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.114276 Train acc: 0.966667\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.107237 Validation acc: 0.953333\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.134866 Train acc: 0.946667\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.083437 Train acc: 0.973333\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.140915 Train acc: 0.936667\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.121318 Train acc: 0.951667\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.107869 Train acc: 0.958333\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.109693 Validation acc: 0.951667\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.109924 Train acc: 0.966667\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.078157 Train acc: 0.970000\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.107624 Train acc: 0.960000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.109371 Train acc: 0.961667\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.124821 Train acc: 0.948333\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.105996 Validation acc: 0.952778\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.077037 Train acc: 0.975000\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.145263 Train acc: 0.935000\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.113972 Train acc: 0.958333\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.109293 Train acc: 0.965000\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.098515 Train acc: 0.965000\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.106414 Validation acc: 0.952222\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.085491 Train acc: 0.975000\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.102075 Train acc: 0.968333\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.109883 Train acc: 0.965000\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.111546 Train acc: 0.955000\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.085920 Train acc: 0.973333\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.110027 Validation acc: 0.952222\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.143010 Train acc: 0.938333\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.138590 Train acc: 0.955000\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.102633 Train acc: 0.956667\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.110178 Train acc: 0.956667\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.087514 Train acc: 0.971667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.113227 Validation acc: 0.951667\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.119832 Train acc: 0.963333\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.102371 Train acc: 0.968333\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.120312 Train acc: 0.953333\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.077580 Train acc: 0.978333\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.142282 Train acc: 0.936667\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.110609 Validation acc: 0.952778\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.118999 Train acc: 0.960000\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.110182 Train acc: 0.958333\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.108046 Train acc: 0.961667\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.096341 Train acc: 0.966667\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.104748 Train acc: 0.955000\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.111249 Validation acc: 0.954444\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.107761 Train acc: 0.956667\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.149513 Train acc: 0.936667\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.087235 Train acc: 0.975000\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.152655 Train acc: 0.933333\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.115703 Train acc: 0.960000\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.110131 Validation acc: 0.951111\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.110601 Train acc: 0.953333\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.115672 Train acc: 0.956667\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.085314 Train acc: 0.966667\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.114123 Train acc: 0.960000\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.110627 Train acc: 0.961667\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.106956 Validation acc: 0.952222\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.128784 Train acc: 0.948333\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.072388 Train acc: 0.975000\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.133783 Train acc: 0.933333\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.119559 Train acc: 0.958333\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.104207 Train acc: 0.966667\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.107677 Validation acc: 0.954444\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.101712 Train acc: 0.956667\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.084745 Train acc: 0.975000\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.115153 Train acc: 0.963333\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.103675 Train acc: 0.966667\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.119845 Train acc: 0.948333\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.109167 Validation acc: 0.951667\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.073742 Train acc: 0.981667\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.142184 Train acc: 0.935000\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.124091 Train acc: 0.963333\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.118102 Train acc: 0.955000\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.107795 Train acc: 0.958333\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.111523 Validation acc: 0.950556\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.088033 Train acc: 0.965000\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.108871 Train acc: 0.961667\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.103992 Train acc: 0.970000\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.124657 Train acc: 0.953333\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.075502 Train acc: 0.976667\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.111099 Validation acc: 0.950000\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.134846 Train acc: 0.935000\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.122956 Train acc: 0.953333\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.111925 Train acc: 0.955000\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.105151 Train acc: 0.958333\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.092694 Train acc: 0.958333\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.109256 Validation acc: 0.953889\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.107585 Train acc: 0.968333\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.110118 Train acc: 0.961667\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.127921 Train acc: 0.953333\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.075451 Train acc: 0.980000\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.139866 Train acc: 0.933333\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.108069 Validation acc: 0.954444\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.123803 Train acc: 0.958333\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.106284 Train acc: 0.961667\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.106042 Train acc: 0.960000\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.082987 Train acc: 0.971667\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.107745 Train acc: 0.966667\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.108874 Validation acc: 0.953889\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.096672 Train acc: 0.968333\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.124681 Train acc: 0.951667\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.079012 Train acc: 0.978333\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.141926 Train acc: 0.931667\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.120898 Train acc: 0.955000\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.112376 Validation acc: 0.953333\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.105285 Train acc: 0.958333\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.106448 Train acc: 0.956667\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.089281 Train acc: 0.966667\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.122082 Train acc: 0.958333\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.109894 Train acc: 0.963333\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.105564 Validation acc: 0.952778\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.133249 Train acc: 0.943333\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.084154 Train acc: 0.970000\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.142831 Train acc: 0.936667\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.131303 Train acc: 0.953333\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.107354 Train acc: 0.955000\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.105281 Validation acc: 0.952222\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.104739 Train acc: 0.963333\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.092427 Train acc: 0.968333\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.098479 Train acc: 0.963333\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.101336 Train acc: 0.970000\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.120857 Train acc: 0.948333\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.106596 Validation acc: 0.952778\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.074382 Train acc: 0.976667\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.140052 Train acc: 0.936667\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.114583 Train acc: 0.960000\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.097605 Train acc: 0.963333\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.114235 Train acc: 0.960000\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.105344 Validation acc: 0.953333\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.087822 Train acc: 0.971667\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.103993 Train acc: 0.965000\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.112513 Train acc: 0.968333\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.123541 Train acc: 0.953333\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.081194 Train acc: 0.966667\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.115840 Validation acc: 0.954444\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.127792 Train acc: 0.943333\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.149107 Train acc: 0.953333\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.107178 Train acc: 0.955000\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.103962 Train acc: 0.961667\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.076405 Train acc: 0.976667\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.102908 Validation acc: 0.954444\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.118658 Train acc: 0.955000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.099732 Train acc: 0.966667\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.114492 Train acc: 0.948333\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.082729 Train acc: 0.971667\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.133502 Train acc: 0.945000\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.103843 Validation acc: 0.955000\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.110426 Train acc: 0.958333\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.099407 Train acc: 0.963333\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.096219 Train acc: 0.963333\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.085622 Train acc: 0.970000\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.111187 Train acc: 0.960000\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.104575 Validation acc: 0.956111\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.102403 Train acc: 0.968333\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.114143 Train acc: 0.961667\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.073152 Train acc: 0.980000\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.141352 Train acc: 0.936667\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.118142 Train acc: 0.950000\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.114775 Validation acc: 0.952778\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.108909 Train acc: 0.961667\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.105663 Train acc: 0.961667\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.085553 Train acc: 0.968333\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.103907 Train acc: 0.965000\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.103948 Train acc: 0.966667\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.105572 Validation acc: 0.953889\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.115521 Train acc: 0.950000\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.074476 Train acc: 0.973333\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.136408 Train acc: 0.938333\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.117540 Train acc: 0.955000\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.103217 Train acc: 0.966667\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.103821 Validation acc: 0.956111\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.106933 Train acc: 0.960000\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.084972 Train acc: 0.965000\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.115263 Train acc: 0.960000\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.097504 Train acc: 0.973333\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.119179 Train acc: 0.950000\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.103510 Validation acc: 0.956111\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.079104 Train acc: 0.975000\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.127208 Train acc: 0.950000\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.119986 Train acc: 0.958333\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.099245 Train acc: 0.966667\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.094689 Train acc: 0.963333\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.106116 Validation acc: 0.955556\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.085974 Train acc: 0.971667\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.100687 Train acc: 0.965000\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.101782 Train acc: 0.976667\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.111039 Train acc: 0.956667\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.070817 Train acc: 0.980000\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.107682 Validation acc: 0.955556\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.130537 Train acc: 0.938333\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.114459 Train acc: 0.960000\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.098816 Train acc: 0.968333\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.098978 Train acc: 0.966667\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.080648 Train acc: 0.970000\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.107127 Validation acc: 0.953889\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.109399 Train acc: 0.960000\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.104355 Train acc: 0.966667\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.113543 Train acc: 0.953333\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.080746 Train acc: 0.976667\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.135844 Train acc: 0.938333\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.108360 Validation acc: 0.955000\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.116398 Train acc: 0.955000\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.100442 Train acc: 0.961667\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.098168 Train acc: 0.961667\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.087004 Train acc: 0.966667\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.118276 Train acc: 0.966667\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.115140 Validation acc: 0.955000\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.099432 Train acc: 0.965000\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.114410 Train acc: 0.953333\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.077101 Train acc: 0.980000\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.126551 Train acc: 0.935000\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.124567 Train acc: 0.960000\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.112406 Validation acc: 0.956111\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.104481 Train acc: 0.958333\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.096000 Train acc: 0.961667\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.089284 Train acc: 0.965000\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.112251 Train acc: 0.966667\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.096489 Train acc: 0.963333\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.116866 Validation acc: 0.955000\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.114393 Train acc: 0.956667\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.079424 Train acc: 0.976667\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.138074 Train acc: 0.940000\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.118986 Train acc: 0.960000\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.106196 Train acc: 0.960000\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.110750 Validation acc: 0.955000\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.108483 Train acc: 0.963333\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.085447 Train acc: 0.966667\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.097204 Train acc: 0.968333\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.097197 Train acc: 0.968333\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.118623 Train acc: 0.945000\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.109112 Validation acc: 0.956111\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.072839 Train acc: 0.973333\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.140310 Train acc: 0.933333\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.108400 Train acc: 0.958333\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.108363 Train acc: 0.956667\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.098243 Train acc: 0.963333\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.111980 Validation acc: 0.954444\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.079589 Train acc: 0.968333\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.097421 Train acc: 0.968333\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.104851 Train acc: 0.966667\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.116663 Train acc: 0.956667\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.072771 Train acc: 0.971667\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.110741 Validation acc: 0.956111\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.124260 Train acc: 0.945000\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.123967 Train acc: 0.963333\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.095946 Train acc: 0.963333\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.104143 Train acc: 0.966667\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.082650 Train acc: 0.970000\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.109546 Validation acc: 0.957222\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.092216 Train acc: 0.968333\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.090753 Train acc: 0.966667\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.111458 Train acc: 0.958333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.083132 Train acc: 0.975000\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.128374 Train acc: 0.938333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.114896 Validation acc: 0.956667\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.115166 Train acc: 0.960000\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.096731 Train acc: 0.963333\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.100812 Train acc: 0.966667\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.089649 Train acc: 0.966667\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.109023 Train acc: 0.958333\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.114394 Validation acc: 0.951667\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.103480 Train acc: 0.965000\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.107011 Train acc: 0.953333\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.073757 Train acc: 0.973333\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.132747 Train acc: 0.925000\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.118765 Train acc: 0.960000\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.101876 Validation acc: 0.958333\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.106983 Train acc: 0.963333\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.086305 Train acc: 0.973333\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.077745 Train acc: 0.970000\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.089631 Train acc: 0.963333\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.101563 Train acc: 0.968333\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.103057 Validation acc: 0.956667\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.103846 Train acc: 0.955000\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.077674 Train acc: 0.978333\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.135131 Train acc: 0.943333\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.105921 Train acc: 0.961667\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.101752 Train acc: 0.963333\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.103502 Validation acc: 0.960000\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.106380 Train acc: 0.956667\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.082815 Train acc: 0.975000\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.101952 Train acc: 0.961667\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.097607 Train acc: 0.970000\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.118605 Train acc: 0.956667\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.103495 Validation acc: 0.956667\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.073946 Train acc: 0.976667\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.125269 Train acc: 0.948333\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.131164 Train acc: 0.956667\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.093305 Train acc: 0.970000\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.097182 Train acc: 0.966667\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.115436 Validation acc: 0.955000\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.084187 Train acc: 0.971667\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.091424 Train acc: 0.971667\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.099858 Train acc: 0.970000\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.121341 Train acc: 0.953333\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.068855 Train acc: 0.981667\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.111670 Validation acc: 0.957778\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.146004 Train acc: 0.938333\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.116046 Train acc: 0.956667\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.103482 Train acc: 0.963333\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.106595 Train acc: 0.955000\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.085165 Train acc: 0.966667\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.117919 Validation acc: 0.956111\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.092032 Train acc: 0.971667\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.106084 Train acc: 0.968333\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.118529 Train acc: 0.953333\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.071128 Train acc: 0.973333\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.145133 Train acc: 0.940000\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.109913 Validation acc: 0.955555\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.119425 Train acc: 0.960000\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.099131 Train acc: 0.966667\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.119347 Train acc: 0.960000\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.130335 Train acc: 0.960000\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.097405 Train acc: 0.970000\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.112761 Validation acc: 0.958889\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.103532 Train acc: 0.971667\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.116488 Train acc: 0.958333\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.074957 Train acc: 0.976667\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.140314 Train acc: 0.928333\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.117704 Train acc: 0.958333\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.114980 Validation acc: 0.956667\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.096284 Train acc: 0.966667\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.096035 Train acc: 0.966667\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.086299 Train acc: 0.968333\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.099107 Train acc: 0.971667\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.086770 Train acc: 0.973333\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.101649 Validation acc: 0.956667\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.109504 Train acc: 0.958333\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.082717 Train acc: 0.970000\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.141661 Train acc: 0.946667\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.111823 Train acc: 0.951667\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.100379 Train acc: 0.968333\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.109692 Validation acc: 0.952222\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.094221 Train acc: 0.965000\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.081685 Train acc: 0.975000\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.097078 Train acc: 0.970000\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.096584 Train acc: 0.973333\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.100742 Train acc: 0.966667\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.111476 Validation acc: 0.956667\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.064818 Train acc: 0.976667\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.128023 Train acc: 0.940000\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.108760 Train acc: 0.961667\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.099436 Train acc: 0.958333\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.096656 Train acc: 0.960000\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.105123 Validation acc: 0.958333\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.081030 Train acc: 0.970000\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.094779 Train acc: 0.966667\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.094123 Train acc: 0.973333\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.111155 Train acc: 0.955000\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.065981 Train acc: 0.980000\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.106842 Validation acc: 0.956667\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.129751 Train acc: 0.943333\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.123741 Train acc: 0.958333\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.099089 Train acc: 0.958333\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.096854 Train acc: 0.958333\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.078459 Train acc: 0.975000\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.110287 Validation acc: 0.957778\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.121089 Train acc: 0.963333\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.093518 Train acc: 0.970000\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.113988 Train acc: 0.946667\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.076254 Train acc: 0.975000\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.134550 Train acc: 0.936667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.102416 Validation acc: 0.960556\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.105008 Train acc: 0.958333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.096471 Train acc: 0.963333\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.098910 Train acc: 0.963333\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.084369 Train acc: 0.970000\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.100685 Train acc: 0.961667\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.105975 Validation acc: 0.956667\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.096499 Train acc: 0.971667\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.104374 Train acc: 0.958333\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.074635 Train acc: 0.973333\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.142094 Train acc: 0.941667\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.121053 Train acc: 0.951667\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.100863 Validation acc: 0.960000\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.096329 Train acc: 0.971667\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.089795 Train acc: 0.965000\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.083394 Train acc: 0.966667\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.104758 Train acc: 0.966667\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.099404 Train acc: 0.970000\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.102198 Validation acc: 0.959444\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.117329 Train acc: 0.946667\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.076866 Train acc: 0.976667\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.152020 Train acc: 0.930000\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.118915 Train acc: 0.953333\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.090429 Train acc: 0.966667\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.105004 Validation acc: 0.957222\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.095014 Train acc: 0.965000\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.081236 Train acc: 0.971667\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.097163 Train acc: 0.968333\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.087876 Train acc: 0.970000\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.103740 Train acc: 0.958333\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.103179 Validation acc: 0.958333\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.073096 Train acc: 0.976667\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.144198 Train acc: 0.938333\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.113131 Train acc: 0.965000\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.088914 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.090836 Train acc: 0.966667\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.109559 Validation acc: 0.958889\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.080848 Train acc: 0.970000\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.099125 Train acc: 0.963333\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.088875 Train acc: 0.973333\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.101487 Train acc: 0.961667\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.074248 Train acc: 0.978333\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.109456 Validation acc: 0.959444\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.130391 Train acc: 0.938333\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.106621 Train acc: 0.963333\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.097420 Train acc: 0.965000\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.088142 Train acc: 0.965000\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.081836 Train acc: 0.971667\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.109713 Validation acc: 0.958333\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.115596 Train acc: 0.960000\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.088514 Train acc: 0.976667\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.118685 Train acc: 0.960000\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.074821 Train acc: 0.978333\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.127047 Train acc: 0.943333\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.105547 Validation acc: 0.958333\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.131376 Train acc: 0.951667\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.086958 Train acc: 0.965000\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.091570 Train acc: 0.968333\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.082138 Train acc: 0.965000\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.107652 Train acc: 0.965000\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.104328 Validation acc: 0.959444\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.082274 Train acc: 0.971667\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.110886 Train acc: 0.961667\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.063935 Train acc: 0.976667\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.145951 Train acc: 0.938333\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.119036 Train acc: 0.955000\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.100405 Validation acc: 0.960000\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.090422 Train acc: 0.960000\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.085691 Train acc: 0.970000\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.079964 Train acc: 0.971667\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.106745 Train acc: 0.961667\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.083269 Train acc: 0.975000\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.102780 Validation acc: 0.958333\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.111111 Train acc: 0.961667\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.071361 Train acc: 0.973333\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.132330 Train acc: 0.941667\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.107527 Train acc: 0.960000\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.095843 Train acc: 0.961667\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.100951 Validation acc: 0.959444\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.095458 Train acc: 0.958333\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.082234 Train acc: 0.960000\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.099992 Train acc: 0.961667\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.085194 Train acc: 0.978333\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.106492 Train acc: 0.951667\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.103058 Validation acc: 0.958333\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.070502 Train acc: 0.976667\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.140210 Train acc: 0.933333\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.119675 Train acc: 0.963333\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.094442 Train acc: 0.965000\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.116487 Train acc: 0.946667\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.104159 Validation acc: 0.958333\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.080034 Train acc: 0.975000\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.098847 Train acc: 0.965000\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.092028 Train acc: 0.971667\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.109326 Train acc: 0.958333\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.067753 Train acc: 0.975000\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.103950 Validation acc: 0.957778\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.118641 Train acc: 0.943333\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.118512 Train acc: 0.956667\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.089355 Train acc: 0.965000\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.095518 Train acc: 0.963333\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.077677 Train acc: 0.975000\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.107654 Validation acc: 0.959444\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.093386 Train acc: 0.961667\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.093318 Train acc: 0.975000\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.109164 Train acc: 0.956667\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.071388 Train acc: 0.973333\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.139001 Train acc: 0.935000\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.101548 Validation acc: 0.958333\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.114350 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.097867 Train acc: 0.956667\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.096263 Train acc: 0.965000\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.084549 Train acc: 0.976667\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.086923 Train acc: 0.966667\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.102241 Validation acc: 0.958889\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.086017 Train acc: 0.980000\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.097335 Train acc: 0.961667\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.064596 Train acc: 0.981667\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.116066 Train acc: 0.945000\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.106554 Train acc: 0.965000\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.102545 Validation acc: 0.958333\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.086696 Train acc: 0.970000\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.084029 Train acc: 0.965000\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.084261 Train acc: 0.973333\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.104959 Train acc: 0.971667\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.088629 Train acc: 0.973333\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.107999 Validation acc: 0.960556\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.107125 Train acc: 0.963333\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.069771 Train acc: 0.976667\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.123296 Train acc: 0.951667\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.127032 Train acc: 0.953333\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.096187 Train acc: 0.968333\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.101311 Validation acc: 0.959444\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.088163 Train acc: 0.968333\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.076377 Train acc: 0.968333\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.093969 Train acc: 0.971667\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.083627 Train acc: 0.978333\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.093814 Train acc: 0.965000\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.104144 Validation acc: 0.961111\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.071828 Train acc: 0.973333\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.136183 Train acc: 0.938333\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.123724 Train acc: 0.956667\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.094582 Train acc: 0.963333\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.076570 Train acc: 0.968333\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.102883 Validation acc: 0.959444\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.076390 Train acc: 0.970000\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.100413 Train acc: 0.961667\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.081494 Train acc: 0.976667\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.095579 Train acc: 0.965000\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.074011 Train acc: 0.978333\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.101901 Validation acc: 0.959444\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.122830 Train acc: 0.943333\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.113920 Train acc: 0.961667\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.090830 Train acc: 0.963333\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.084315 Train acc: 0.968333\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.067614 Train acc: 0.971667\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.099427 Validation acc: 0.960000\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.110432 Train acc: 0.966667\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.086506 Train acc: 0.973333\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.105277 Train acc: 0.966667\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.077193 Train acc: 0.976667\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.132520 Train acc: 0.936667\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.106114 Validation acc: 0.960556\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.104737 Train acc: 0.960000\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.096691 Train acc: 0.966667\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.095250 Train acc: 0.968333\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.081568 Train acc: 0.965000\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.090806 Train acc: 0.966667\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.104509 Validation acc: 0.959444\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.083042 Train acc: 0.973333\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.107119 Train acc: 0.956667\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.062626 Train acc: 0.980000\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.129680 Train acc: 0.948333\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.117254 Train acc: 0.960000\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.105245 Validation acc: 0.960556\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.085124 Train acc: 0.968333\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.085248 Train acc: 0.965000\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.071620 Train acc: 0.980000\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.104317 Train acc: 0.968333\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.087316 Train acc: 0.975000\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.105395 Validation acc: 0.959444\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.103981 Train acc: 0.961667\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.065334 Train acc: 0.985000\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.136525 Train acc: 0.936667\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.114466 Train acc: 0.963333\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.092768 Train acc: 0.963333\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.106476 Validation acc: 0.959444\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.089744 Train acc: 0.961667\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.071635 Train acc: 0.976667\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.090962 Train acc: 0.970000\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.085524 Train acc: 0.975000\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.099497 Train acc: 0.963333\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.109666 Validation acc: 0.959444\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.071629 Train acc: 0.978333\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.126103 Train acc: 0.941667\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.103628 Train acc: 0.965000\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.097264 Train acc: 0.956667\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.091998 Train acc: 0.955000\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.106221 Validation acc: 0.961111\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.077785 Train acc: 0.971667\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.083366 Train acc: 0.968333\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.082934 Train acc: 0.976667\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.097557 Train acc: 0.963333\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.066884 Train acc: 0.971667\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.106414 Validation acc: 0.960000\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.130404 Train acc: 0.940000\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.124352 Train acc: 0.958333\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.090970 Train acc: 0.966667\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.084408 Train acc: 0.963333\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.078322 Train acc: 0.970000\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.105502 Validation acc: 0.960000\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.102082 Train acc: 0.965000\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.081414 Train acc: 0.973333\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.104189 Train acc: 0.961667\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.069955 Train acc: 0.978333\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.143477 Train acc: 0.943333\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.108719 Validation acc: 0.960000\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.123146 Train acc: 0.956667\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.088294 Train acc: 0.963333\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.083985 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.073111 Train acc: 0.965000\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.098518 Train acc: 0.965000\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.108478 Validation acc: 0.960556\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.082576 Train acc: 0.976667\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.103256 Train acc: 0.953333\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.063535 Train acc: 0.975000\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.128554 Train acc: 0.940000\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.125671 Train acc: 0.958333\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.107640 Validation acc: 0.960556\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.090887 Train acc: 0.968333\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.078040 Train acc: 0.971667\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.081819 Train acc: 0.970000\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.100345 Train acc: 0.968333\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.078081 Train acc: 0.981667\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.104775 Validation acc: 0.959444\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.100688 Train acc: 0.958333\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.063797 Train acc: 0.978333\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.130101 Train acc: 0.938333\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.118023 Train acc: 0.958333\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.087302 Train acc: 0.971667\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.099839 Validation acc: 0.960000\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.089336 Train acc: 0.963333\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.081723 Train acc: 0.961667\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.099382 Train acc: 0.961667\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.089169 Train acc: 0.970000\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.105851 Train acc: 0.958333\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.106059 Validation acc: 0.958333\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.066791 Train acc: 0.976667\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.131748 Train acc: 0.951667\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.105176 Train acc: 0.956667\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.093320 Train acc: 0.965000\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.085448 Train acc: 0.956667\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.108163 Validation acc: 0.958889\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.080440 Train acc: 0.965000\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.088734 Train acc: 0.971667\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.073976 Train acc: 0.980000\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.109947 Train acc: 0.965000\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.069120 Train acc: 0.973333\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.111213 Validation acc: 0.960000\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.126614 Train acc: 0.938333\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.105984 Train acc: 0.960000\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.090023 Train acc: 0.970000\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.078524 Train acc: 0.965000\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.070137 Train acc: 0.970000\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.109556 Validation acc: 0.960556\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.089595 Train acc: 0.968333\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.080453 Train acc: 0.975000\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.100414 Train acc: 0.955000\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.066578 Train acc: 0.970000\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.127236 Train acc: 0.936667\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.109026 Validation acc: 0.961111\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.112259 Train acc: 0.960000\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.089848 Train acc: 0.965000\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.087063 Train acc: 0.960000\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.080208 Train acc: 0.970000\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.099734 Train acc: 0.966667\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.099684 Validation acc: 0.960000\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.081503 Train acc: 0.970000\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.110081 Train acc: 0.951667\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.072776 Train acc: 0.980000\n",
      "Epoch: 999/1000 Iteration: 8995 Train loss: 0.134326 Train acc: 0.946667\n",
      "Epoch: 999/1000 Iteration: 9000 Train loss: 0.120923 Train acc: 0.958333\n",
      "Epoch: 999/1000 Iteration: 9000 Validation loss: 0.103544 Validation acc: 0.960556\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJQwREcnK/wf/JmcPSqYdgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea751c5f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feb384fba58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/har-lstm.ckpt\n",
      "Test accuracy: 0.878333\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
