{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR CNN training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.semg_utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.abspath(os.getcwd())\n",
    "X_train, labels_train, list_ch_train, X_test, labels_test, list_ch_test = read_data(data_path= path + os.sep + \"sEMG\" + os.sep + \"Database 2\" + os.sep)\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize?\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100       # Batch size\n",
    "seq_len = 2496          # Number of steps\n",
    "learning_rate = 0.00001\n",
    "epochs = 200\n",
    "\n",
    "n_classes = 6\n",
    "n_channels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Convolutional Layers\n",
    "\n",
    "Note: Should we use a different activation? Like tf.nn.tanh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /virtualenvs/machine_learning/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # (batch, 2496, 2) --> (batch, 1248, 4)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=4, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 1248, 4) --> (batch, 624, 8)\n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=8, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 624, 8) --> (batch, 312, 16)\n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=16, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 312, 16) --> (batch, 156, 32)\n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=32, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 156, 32) --> (batch, 78, 64)\n",
    "    conv5 = tf.layers.conv1d(inputs=max_pool_4, filters=64, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_5 = tf.layers.max_pooling1d(inputs=conv5, pool_size=2, strides=2, padding='same')\n",
    "    \n",
    "    # (batch, 78, 64) --> (batch, 39, 128)\n",
    "    conv6 = tf.layers.conv1d(inputs=max_pool_5, filters=128, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    max_pool_6 = tf.layers.max_pooling1d(inputs=conv6, pool_size=2, strides=2, padding='same')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, flatten and pass to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ea81b0fd0b05>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    # Flatten and add dropout\n",
    "    flat = tf.reshape(max_pool_6, (-1, 128 * 39))\n",
    "    flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "    \n",
    "    # Predictions\n",
    "    logits = tf.layers.dense(flat, n_classes)\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-cnn') == False):\n",
    "    !mkdir checkpoints-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 5 Train loss: 1.807647 Train acc: 0.140000\n",
      "Epoch: 1/200 Iteration: 10 Train loss: 1.777870 Train acc: 0.190000\n",
      "Epoch: 1/200 Iteration: 10 Validation loss: 1.792212 Validation acc: 0.180000\n",
      "Epoch: 2/200 Iteration: 15 Train loss: 1.792846 Train acc: 0.190000\n",
      "Epoch: 3/200 Iteration: 20 Train loss: 1.761654 Train acc: 0.260000\n",
      "Epoch: 3/200 Iteration: 20 Validation loss: 1.787570 Validation acc: 0.180000\n",
      "Epoch: 4/200 Iteration: 25 Train loss: 1.770509 Train acc: 0.250000\n",
      "Epoch: 4/200 Iteration: 30 Train loss: 1.771861 Train acc: 0.180000\n",
      "Epoch: 4/200 Iteration: 30 Validation loss: 1.783134 Validation acc: 0.185000\n",
      "Epoch: 5/200 Iteration: 35 Train loss: 1.786848 Train acc: 0.170000\n",
      "Epoch: 6/200 Iteration: 40 Train loss: 1.767429 Train acc: 0.230000\n",
      "Epoch: 6/200 Iteration: 40 Validation loss: 1.778891 Validation acc: 0.200000\n",
      "Epoch: 7/200 Iteration: 45 Train loss: 1.793062 Train acc: 0.150000\n",
      "Epoch: 8/200 Iteration: 50 Train loss: 1.764955 Train acc: 0.250000\n",
      "Epoch: 8/200 Iteration: 50 Validation loss: 1.774796 Validation acc: 0.265000\n",
      "Epoch: 9/200 Iteration: 55 Train loss: 1.785607 Train acc: 0.170000\n",
      "Epoch: 9/200 Iteration: 60 Train loss: 1.761367 Train acc: 0.200000\n",
      "Epoch: 9/200 Iteration: 60 Validation loss: 1.770881 Validation acc: 0.270000\n",
      "Epoch: 10/200 Iteration: 65 Train loss: 1.757963 Train acc: 0.220000\n",
      "Epoch: 11/200 Iteration: 70 Train loss: 1.765513 Train acc: 0.160000\n",
      "Epoch: 11/200 Iteration: 70 Validation loss: 1.767116 Validation acc: 0.230000\n",
      "Epoch: 12/200 Iteration: 75 Train loss: 1.782501 Train acc: 0.160000\n",
      "Epoch: 13/200 Iteration: 80 Train loss: 1.772121 Train acc: 0.120000\n",
      "Epoch: 13/200 Iteration: 80 Validation loss: 1.763485 Validation acc: 0.230000\n",
      "Epoch: 14/200 Iteration: 85 Train loss: 1.761414 Train acc: 0.220000\n",
      "Epoch: 14/200 Iteration: 90 Train loss: 1.725143 Train acc: 0.270000\n",
      "Epoch: 14/200 Iteration: 90 Validation loss: 1.759980 Validation acc: 0.220000\n",
      "Epoch: 15/200 Iteration: 95 Train loss: 1.748482 Train acc: 0.230000\n",
      "Epoch: 16/200 Iteration: 100 Train loss: 1.742965 Train acc: 0.240000\n",
      "Epoch: 16/200 Iteration: 100 Validation loss: 1.756565 Validation acc: 0.220000\n",
      "Epoch: 17/200 Iteration: 105 Train loss: 1.761587 Train acc: 0.190000\n",
      "Epoch: 18/200 Iteration: 110 Train loss: 1.749586 Train acc: 0.190000\n",
      "Epoch: 18/200 Iteration: 110 Validation loss: 1.753218 Validation acc: 0.220000\n",
      "Epoch: 19/200 Iteration: 115 Train loss: 1.772086 Train acc: 0.170000\n",
      "Epoch: 19/200 Iteration: 120 Train loss: 1.717263 Train acc: 0.240000\n",
      "Epoch: 19/200 Iteration: 120 Validation loss: 1.750008 Validation acc: 0.220000\n",
      "Epoch: 20/200 Iteration: 125 Train loss: 1.720634 Train acc: 0.250000\n",
      "Epoch: 21/200 Iteration: 130 Train loss: 1.716994 Train acc: 0.240000\n",
      "Epoch: 21/200 Iteration: 130 Validation loss: 1.746903 Validation acc: 0.215000\n",
      "Epoch: 22/200 Iteration: 135 Train loss: 1.762454 Train acc: 0.130000\n",
      "Epoch: 23/200 Iteration: 140 Train loss: 1.733782 Train acc: 0.220000\n",
      "Epoch: 23/200 Iteration: 140 Validation loss: 1.743851 Validation acc: 0.210000\n",
      "Epoch: 24/200 Iteration: 145 Train loss: 1.745842 Train acc: 0.160000\n",
      "Epoch: 24/200 Iteration: 150 Train loss: 1.710398 Train acc: 0.200000\n",
      "Epoch: 24/200 Iteration: 150 Validation loss: 1.740880 Validation acc: 0.210000\n",
      "Epoch: 25/200 Iteration: 155 Train loss: 1.704221 Train acc: 0.270000\n",
      "Epoch: 26/200 Iteration: 160 Train loss: 1.730907 Train acc: 0.220000\n",
      "Epoch: 26/200 Iteration: 160 Validation loss: 1.737984 Validation acc: 0.210000\n",
      "Epoch: 27/200 Iteration: 165 Train loss: 1.746329 Train acc: 0.180000\n",
      "Epoch: 28/200 Iteration: 170 Train loss: 1.715888 Train acc: 0.210000\n",
      "Epoch: 28/200 Iteration: 170 Validation loss: 1.735160 Validation acc: 0.210000\n",
      "Epoch: 29/200 Iteration: 175 Train loss: 1.755213 Train acc: 0.190000\n",
      "Epoch: 29/200 Iteration: 180 Train loss: 1.680737 Train acc: 0.270000\n",
      "Epoch: 29/200 Iteration: 180 Validation loss: 1.732409 Validation acc: 0.210000\n",
      "Epoch: 30/200 Iteration: 185 Train loss: 1.704724 Train acc: 0.200000\n",
      "Epoch: 31/200 Iteration: 190 Train loss: 1.701511 Train acc: 0.220000\n",
      "Epoch: 31/200 Iteration: 190 Validation loss: 1.729721 Validation acc: 0.210000\n",
      "Epoch: 32/200 Iteration: 195 Train loss: 1.741249 Train acc: 0.190000\n",
      "Epoch: 33/200 Iteration: 200 Train loss: 1.701432 Train acc: 0.230000\n",
      "Epoch: 33/200 Iteration: 200 Validation loss: 1.727057 Validation acc: 0.210000\n",
      "Epoch: 34/200 Iteration: 205 Train loss: 1.728678 Train acc: 0.190000\n",
      "Epoch: 34/200 Iteration: 210 Train loss: 1.673697 Train acc: 0.250000\n",
      "Epoch: 34/200 Iteration: 210 Validation loss: 1.724478 Validation acc: 0.210000\n",
      "Epoch: 35/200 Iteration: 215 Train loss: 1.678653 Train acc: 0.240000\n",
      "Epoch: 36/200 Iteration: 220 Train loss: 1.694501 Train acc: 0.230000\n",
      "Epoch: 36/200 Iteration: 220 Validation loss: 1.721937 Validation acc: 0.210000\n",
      "Epoch: 37/200 Iteration: 225 Train loss: 1.745541 Train acc: 0.150000\n",
      "Epoch: 38/200 Iteration: 230 Train loss: 1.714112 Train acc: 0.190000\n",
      "Epoch: 38/200 Iteration: 230 Validation loss: 1.719420 Validation acc: 0.210000\n",
      "Epoch: 39/200 Iteration: 235 Train loss: 1.721187 Train acc: 0.230000\n",
      "Epoch: 39/200 Iteration: 240 Train loss: 1.652617 Train acc: 0.310000\n",
      "Epoch: 39/200 Iteration: 240 Validation loss: 1.716967 Validation acc: 0.210000\n",
      "Epoch: 40/200 Iteration: 245 Train loss: 1.676333 Train acc: 0.230000\n",
      "Epoch: 41/200 Iteration: 250 Train loss: 1.707302 Train acc: 0.210000\n",
      "Epoch: 41/200 Iteration: 250 Validation loss: 1.714541 Validation acc: 0.210000\n",
      "Epoch: 42/200 Iteration: 255 Train loss: 1.727159 Train acc: 0.150000\n",
      "Epoch: 43/200 Iteration: 260 Train loss: 1.695434 Train acc: 0.240000\n",
      "Epoch: 43/200 Iteration: 260 Validation loss: 1.712156 Validation acc: 0.210000\n",
      "Epoch: 44/200 Iteration: 265 Train loss: 1.704661 Train acc: 0.220000\n",
      "Epoch: 44/200 Iteration: 270 Train loss: 1.670903 Train acc: 0.240000\n",
      "Epoch: 44/200 Iteration: 270 Validation loss: 1.709795 Validation acc: 0.210000\n",
      "Epoch: 45/200 Iteration: 275 Train loss: 1.668389 Train acc: 0.250000\n",
      "Epoch: 46/200 Iteration: 280 Train loss: 1.669934 Train acc: 0.260000\n",
      "Epoch: 46/200 Iteration: 280 Validation loss: 1.707431 Validation acc: 0.210000\n",
      "Epoch: 47/200 Iteration: 285 Train loss: 1.726689 Train acc: 0.170000\n",
      "Epoch: 48/200 Iteration: 290 Train loss: 1.689805 Train acc: 0.220000\n",
      "Epoch: 48/200 Iteration: 290 Validation loss: 1.705094 Validation acc: 0.210000\n",
      "Epoch: 49/200 Iteration: 295 Train loss: 1.701260 Train acc: 0.230000\n",
      "Epoch: 49/200 Iteration: 300 Train loss: 1.658619 Train acc: 0.280000\n",
      "Epoch: 49/200 Iteration: 300 Validation loss: 1.702779 Validation acc: 0.210000\n",
      "Epoch: 50/200 Iteration: 305 Train loss: 1.666404 Train acc: 0.200000\n",
      "Epoch: 51/200 Iteration: 310 Train loss: 1.676640 Train acc: 0.230000\n",
      "Epoch: 51/200 Iteration: 310 Validation loss: 1.700469 Validation acc: 0.215000\n",
      "Epoch: 52/200 Iteration: 315 Train loss: 1.698307 Train acc: 0.180000\n",
      "Epoch: 53/200 Iteration: 320 Train loss: 1.656237 Train acc: 0.240000\n",
      "Epoch: 53/200 Iteration: 320 Validation loss: 1.698151 Validation acc: 0.215000\n",
      "Epoch: 54/200 Iteration: 325 Train loss: 1.710685 Train acc: 0.190000\n",
      "Epoch: 54/200 Iteration: 330 Train loss: 1.635542 Train acc: 0.270000\n",
      "Epoch: 54/200 Iteration: 330 Validation loss: 1.695864 Validation acc: 0.220000\n",
      "Epoch: 55/200 Iteration: 335 Train loss: 1.642101 Train acc: 0.270000\n",
      "Epoch: 56/200 Iteration: 340 Train loss: 1.674552 Train acc: 0.250000\n",
      "Epoch: 56/200 Iteration: 340 Validation loss: 1.693602 Validation acc: 0.220000\n",
      "Epoch: 57/200 Iteration: 345 Train loss: 1.705292 Train acc: 0.190000\n",
      "Epoch: 58/200 Iteration: 350 Train loss: 1.680391 Train acc: 0.240000\n",
      "Epoch: 58/200 Iteration: 350 Validation loss: 1.691358 Validation acc: 0.220000\n",
      "Epoch: 59/200 Iteration: 355 Train loss: 1.665692 Train acc: 0.260000\n",
      "Epoch: 59/200 Iteration: 360 Train loss: 1.619197 Train acc: 0.290000\n",
      "Epoch: 59/200 Iteration: 360 Validation loss: 1.689121 Validation acc: 0.230000\n",
      "Epoch: 60/200 Iteration: 365 Train loss: 1.622258 Train acc: 0.270000\n",
      "Epoch: 61/200 Iteration: 370 Train loss: 1.645592 Train acc: 0.240000\n",
      "Epoch: 61/200 Iteration: 370 Validation loss: 1.686843 Validation acc: 0.230000\n",
      "Epoch: 62/200 Iteration: 375 Train loss: 1.699231 Train acc: 0.150000\n",
      "Epoch: 63/200 Iteration: 380 Train loss: 1.660307 Train acc: 0.260000\n",
      "Epoch: 63/200 Iteration: 380 Validation loss: 1.684576 Validation acc: 0.230000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/200 Iteration: 385 Train loss: 1.652834 Train acc: 0.260000\n",
      "Epoch: 64/200 Iteration: 390 Train loss: 1.618681 Train acc: 0.260000\n",
      "Epoch: 64/200 Iteration: 390 Validation loss: 1.682328 Validation acc: 0.235000\n",
      "Epoch: 65/200 Iteration: 395 Train loss: 1.639008 Train acc: 0.270000\n",
      "Epoch: 66/200 Iteration: 400 Train loss: 1.649752 Train acc: 0.240000\n",
      "Epoch: 66/200 Iteration: 400 Validation loss: 1.680088 Validation acc: 0.235000\n",
      "Epoch: 67/200 Iteration: 405 Train loss: 1.685731 Train acc: 0.190000\n",
      "Epoch: 68/200 Iteration: 410 Train loss: 1.650534 Train acc: 0.240000\n",
      "Epoch: 68/200 Iteration: 410 Validation loss: 1.677845 Validation acc: 0.240000\n",
      "Epoch: 69/200 Iteration: 415 Train loss: 1.664252 Train acc: 0.240000\n",
      "Epoch: 69/200 Iteration: 420 Train loss: 1.603226 Train acc: 0.260000\n",
      "Epoch: 69/200 Iteration: 420 Validation loss: 1.675583 Validation acc: 0.240000\n",
      "Epoch: 70/200 Iteration: 425 Train loss: 1.630283 Train acc: 0.220000\n",
      "Epoch: 71/200 Iteration: 430 Train loss: 1.643621 Train acc: 0.270000\n",
      "Epoch: 71/200 Iteration: 430 Validation loss: 1.673305 Validation acc: 0.240000\n",
      "Epoch: 72/200 Iteration: 435 Train loss: 1.678977 Train acc: 0.200000\n",
      "Epoch: 73/200 Iteration: 440 Train loss: 1.649978 Train acc: 0.250000\n",
      "Epoch: 73/200 Iteration: 440 Validation loss: 1.670992 Validation acc: 0.240000\n",
      "Epoch: 74/200 Iteration: 445 Train loss: 1.669580 Train acc: 0.240000\n",
      "Epoch: 74/200 Iteration: 450 Train loss: 1.586756 Train acc: 0.280000\n",
      "Epoch: 74/200 Iteration: 450 Validation loss: 1.668653 Validation acc: 0.240000\n",
      "Epoch: 75/200 Iteration: 455 Train loss: 1.616427 Train acc: 0.280000\n",
      "Epoch: 76/200 Iteration: 460 Train loss: 1.631146 Train acc: 0.270000\n",
      "Epoch: 76/200 Iteration: 460 Validation loss: 1.666292 Validation acc: 0.245000\n",
      "Epoch: 77/200 Iteration: 465 Train loss: 1.670751 Train acc: 0.180000\n",
      "Epoch: 78/200 Iteration: 470 Train loss: 1.630136 Train acc: 0.240000\n",
      "Epoch: 78/200 Iteration: 470 Validation loss: 1.663940 Validation acc: 0.250000\n",
      "Epoch: 79/200 Iteration: 475 Train loss: 1.645471 Train acc: 0.280000\n",
      "Epoch: 79/200 Iteration: 480 Train loss: 1.578455 Train acc: 0.280000\n",
      "Epoch: 79/200 Iteration: 480 Validation loss: 1.661586 Validation acc: 0.250000\n",
      "Epoch: 80/200 Iteration: 485 Train loss: 1.612698 Train acc: 0.250000\n",
      "Epoch: 81/200 Iteration: 490 Train loss: 1.631578 Train acc: 0.290000\n",
      "Epoch: 81/200 Iteration: 490 Validation loss: 1.659210 Validation acc: 0.250000\n",
      "Epoch: 82/200 Iteration: 495 Train loss: 1.685668 Train acc: 0.160000\n",
      "Epoch: 83/200 Iteration: 500 Train loss: 1.624698 Train acc: 0.230000\n",
      "Epoch: 83/200 Iteration: 500 Validation loss: 1.656845 Validation acc: 0.245000\n",
      "Epoch: 84/200 Iteration: 505 Train loss: 1.651876 Train acc: 0.250000\n",
      "Epoch: 84/200 Iteration: 510 Train loss: 1.578625 Train acc: 0.280000\n",
      "Epoch: 84/200 Iteration: 510 Validation loss: 1.654443 Validation acc: 0.250000\n",
      "Epoch: 85/200 Iteration: 515 Train loss: 1.599578 Train acc: 0.250000\n",
      "Epoch: 86/200 Iteration: 520 Train loss: 1.598708 Train acc: 0.280000\n",
      "Epoch: 86/200 Iteration: 520 Validation loss: 1.651997 Validation acc: 0.250000\n",
      "Epoch: 87/200 Iteration: 525 Train loss: 1.674989 Train acc: 0.190000\n",
      "Epoch: 88/200 Iteration: 530 Train loss: 1.601708 Train acc: 0.260000\n",
      "Epoch: 88/200 Iteration: 530 Validation loss: 1.649538 Validation acc: 0.250000\n",
      "Epoch: 89/200 Iteration: 535 Train loss: 1.645351 Train acc: 0.270000\n",
      "Epoch: 89/200 Iteration: 540 Train loss: 1.570099 Train acc: 0.260000\n",
      "Epoch: 89/200 Iteration: 540 Validation loss: 1.647037 Validation acc: 0.250000\n",
      "Epoch: 90/200 Iteration: 545 Train loss: 1.580410 Train acc: 0.270000\n",
      "Epoch: 91/200 Iteration: 550 Train loss: 1.608591 Train acc: 0.260000\n",
      "Epoch: 91/200 Iteration: 550 Validation loss: 1.644508 Validation acc: 0.250000\n",
      "Epoch: 92/200 Iteration: 555 Train loss: 1.632091 Train acc: 0.210000\n",
      "Epoch: 93/200 Iteration: 560 Train loss: 1.607967 Train acc: 0.250000\n",
      "Epoch: 93/200 Iteration: 560 Validation loss: 1.641929 Validation acc: 0.250000\n",
      "Epoch: 94/200 Iteration: 565 Train loss: 1.632243 Train acc: 0.280000\n",
      "Epoch: 94/200 Iteration: 570 Train loss: 1.566091 Train acc: 0.270000\n",
      "Epoch: 94/200 Iteration: 570 Validation loss: 1.639291 Validation acc: 0.250000\n",
      "Epoch: 95/200 Iteration: 575 Train loss: 1.558205 Train acc: 0.310000\n",
      "Epoch: 96/200 Iteration: 580 Train loss: 1.589667 Train acc: 0.260000\n",
      "Epoch: 96/200 Iteration: 580 Validation loss: 1.636626 Validation acc: 0.250000\n",
      "Epoch: 97/200 Iteration: 585 Train loss: 1.648687 Train acc: 0.210000\n",
      "Epoch: 98/200 Iteration: 590 Train loss: 1.591200 Train acc: 0.270000\n",
      "Epoch: 98/200 Iteration: 590 Validation loss: 1.633874 Validation acc: 0.250000\n",
      "Epoch: 99/200 Iteration: 595 Train loss: 1.606188 Train acc: 0.240000\n",
      "Epoch: 99/200 Iteration: 600 Train loss: 1.551786 Train acc: 0.290000\n",
      "Epoch: 99/200 Iteration: 600 Validation loss: 1.631112 Validation acc: 0.250000\n",
      "Epoch: 100/200 Iteration: 605 Train loss: 1.564098 Train acc: 0.280000\n",
      "Epoch: 101/200 Iteration: 610 Train loss: 1.584163 Train acc: 0.260000\n",
      "Epoch: 101/200 Iteration: 610 Validation loss: 1.628290 Validation acc: 0.255000\n",
      "Epoch: 102/200 Iteration: 615 Train loss: 1.629397 Train acc: 0.220000\n",
      "Epoch: 103/200 Iteration: 620 Train loss: 1.579528 Train acc: 0.260000\n",
      "Epoch: 103/200 Iteration: 620 Validation loss: 1.625387 Validation acc: 0.255000\n",
      "Epoch: 104/200 Iteration: 625 Train loss: 1.622750 Train acc: 0.270000\n",
      "Epoch: 104/200 Iteration: 630 Train loss: 1.533392 Train acc: 0.320000\n",
      "Epoch: 104/200 Iteration: 630 Validation loss: 1.622389 Validation acc: 0.255000\n",
      "Epoch: 105/200 Iteration: 635 Train loss: 1.553394 Train acc: 0.280000\n",
      "Epoch: 106/200 Iteration: 640 Train loss: 1.601402 Train acc: 0.300000\n",
      "Epoch: 106/200 Iteration: 640 Validation loss: 1.619326 Validation acc: 0.255000\n",
      "Epoch: 107/200 Iteration: 645 Train loss: 1.643279 Train acc: 0.200000\n",
      "Epoch: 108/200 Iteration: 650 Train loss: 1.576576 Train acc: 0.280000\n",
      "Epoch: 108/200 Iteration: 650 Validation loss: 1.616197 Validation acc: 0.255000\n",
      "Epoch: 109/200 Iteration: 655 Train loss: 1.607065 Train acc: 0.300000\n",
      "Epoch: 109/200 Iteration: 660 Train loss: 1.537422 Train acc: 0.300000\n",
      "Epoch: 109/200 Iteration: 660 Validation loss: 1.612951 Validation acc: 0.255000\n",
      "Epoch: 110/200 Iteration: 665 Train loss: 1.532049 Train acc: 0.300000\n",
      "Epoch: 111/200 Iteration: 670 Train loss: 1.592565 Train acc: 0.230000\n",
      "Epoch: 111/200 Iteration: 670 Validation loss: 1.609620 Validation acc: 0.255000\n",
      "Epoch: 112/200 Iteration: 675 Train loss: 1.587698 Train acc: 0.210000\n",
      "Epoch: 113/200 Iteration: 680 Train loss: 1.555342 Train acc: 0.300000\n",
      "Epoch: 113/200 Iteration: 680 Validation loss: 1.606251 Validation acc: 0.255000\n",
      "Epoch: 114/200 Iteration: 685 Train loss: 1.586509 Train acc: 0.320000\n",
      "Epoch: 114/200 Iteration: 690 Train loss: 1.522736 Train acc: 0.300000\n",
      "Epoch: 114/200 Iteration: 690 Validation loss: 1.602823 Validation acc: 0.250000\n",
      "Epoch: 115/200 Iteration: 695 Train loss: 1.523529 Train acc: 0.290000\n",
      "Epoch: 116/200 Iteration: 700 Train loss: 1.571955 Train acc: 0.280000\n",
      "Epoch: 116/200 Iteration: 700 Validation loss: 1.599328 Validation acc: 0.245000\n",
      "Epoch: 117/200 Iteration: 705 Train loss: 1.589601 Train acc: 0.230000\n",
      "Epoch: 118/200 Iteration: 710 Train loss: 1.537189 Train acc: 0.290000\n",
      "Epoch: 118/200 Iteration: 710 Validation loss: 1.595828 Validation acc: 0.245000\n",
      "Epoch: 119/200 Iteration: 715 Train loss: 1.579104 Train acc: 0.320000\n",
      "Epoch: 119/200 Iteration: 720 Train loss: 1.516311 Train acc: 0.280000\n",
      "Epoch: 119/200 Iteration: 720 Validation loss: 1.592283 Validation acc: 0.250000\n",
      "Epoch: 120/200 Iteration: 725 Train loss: 1.551600 Train acc: 0.300000\n",
      "Epoch: 121/200 Iteration: 730 Train loss: 1.559057 Train acc: 0.270000\n",
      "Epoch: 121/200 Iteration: 730 Validation loss: 1.588667 Validation acc: 0.265000\n",
      "Epoch: 122/200 Iteration: 735 Train loss: 1.592014 Train acc: 0.190000\n",
      "Epoch: 123/200 Iteration: 740 Train loss: 1.552790 Train acc: 0.270000\n",
      "Epoch: 123/200 Iteration: 740 Validation loss: 1.584986 Validation acc: 0.265000\n",
      "Epoch: 124/200 Iteration: 745 Train loss: 1.559902 Train acc: 0.310000\n",
      "Epoch: 124/200 Iteration: 750 Train loss: 1.484265 Train acc: 0.350000\n",
      "Epoch: 124/200 Iteration: 750 Validation loss: 1.581272 Validation acc: 0.265000\n",
      "Epoch: 125/200 Iteration: 755 Train loss: 1.511578 Train acc: 0.360000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126/200 Iteration: 760 Train loss: 1.561234 Train acc: 0.320000\n",
      "Epoch: 126/200 Iteration: 760 Validation loss: 1.577484 Validation acc: 0.270000\n",
      "Epoch: 127/200 Iteration: 765 Train loss: 1.590549 Train acc: 0.200000\n",
      "Epoch: 128/200 Iteration: 770 Train loss: 1.512694 Train acc: 0.310000\n",
      "Epoch: 128/200 Iteration: 770 Validation loss: 1.573640 Validation acc: 0.270000\n",
      "Epoch: 129/200 Iteration: 775 Train loss: 1.572634 Train acc: 0.350000\n",
      "Epoch: 129/200 Iteration: 780 Train loss: 1.475151 Train acc: 0.350000\n",
      "Epoch: 129/200 Iteration: 780 Validation loss: 1.569695 Validation acc: 0.280000\n",
      "Epoch: 130/200 Iteration: 785 Train loss: 1.519334 Train acc: 0.300000\n",
      "Epoch: 131/200 Iteration: 790 Train loss: 1.528352 Train acc: 0.300000\n",
      "Epoch: 131/200 Iteration: 790 Validation loss: 1.565685 Validation acc: 0.280000\n",
      "Epoch: 132/200 Iteration: 795 Train loss: 1.565740 Train acc: 0.230000\n",
      "Epoch: 133/200 Iteration: 800 Train loss: 1.530930 Train acc: 0.290000\n",
      "Epoch: 133/200 Iteration: 800 Validation loss: 1.561601 Validation acc: 0.280000\n",
      "Epoch: 134/200 Iteration: 805 Train loss: 1.562266 Train acc: 0.330000\n",
      "Epoch: 134/200 Iteration: 810 Train loss: 1.472110 Train acc: 0.340000\n",
      "Epoch: 134/200 Iteration: 810 Validation loss: 1.557445 Validation acc: 0.290000\n",
      "Epoch: 135/200 Iteration: 815 Train loss: 1.498322 Train acc: 0.320000\n",
      "Epoch: 136/200 Iteration: 820 Train loss: 1.522406 Train acc: 0.300000\n",
      "Epoch: 136/200 Iteration: 820 Validation loss: 1.553164 Validation acc: 0.290000\n",
      "Epoch: 137/200 Iteration: 825 Train loss: 1.553784 Train acc: 0.260000\n",
      "Epoch: 138/200 Iteration: 830 Train loss: 1.501292 Train acc: 0.340000\n",
      "Epoch: 138/200 Iteration: 830 Validation loss: 1.548819 Validation acc: 0.295000\n",
      "Epoch: 139/200 Iteration: 835 Train loss: 1.541646 Train acc: 0.370000\n",
      "Epoch: 139/200 Iteration: 840 Train loss: 1.459297 Train acc: 0.360000\n",
      "Epoch: 139/200 Iteration: 840 Validation loss: 1.544396 Validation acc: 0.295000\n",
      "Epoch: 140/200 Iteration: 845 Train loss: 1.490697 Train acc: 0.350000\n",
      "Epoch: 141/200 Iteration: 850 Train loss: 1.497137 Train acc: 0.350000\n",
      "Epoch: 141/200 Iteration: 850 Validation loss: 1.539882 Validation acc: 0.305000\n",
      "Epoch: 142/200 Iteration: 855 Train loss: 1.540697 Train acc: 0.260000\n",
      "Epoch: 143/200 Iteration: 860 Train loss: 1.461896 Train acc: 0.410000\n",
      "Epoch: 143/200 Iteration: 860 Validation loss: 1.535279 Validation acc: 0.310000\n",
      "Epoch: 144/200 Iteration: 865 Train loss: 1.507341 Train acc: 0.400000\n",
      "Epoch: 144/200 Iteration: 870 Train loss: 1.446531 Train acc: 0.350000\n",
      "Epoch: 144/200 Iteration: 870 Validation loss: 1.530582 Validation acc: 0.330000\n",
      "Epoch: 145/200 Iteration: 875 Train loss: 1.474334 Train acc: 0.370000\n",
      "Epoch: 146/200 Iteration: 880 Train loss: 1.493356 Train acc: 0.350000\n",
      "Epoch: 146/200 Iteration: 880 Validation loss: 1.525840 Validation acc: 0.335000\n",
      "Epoch: 147/200 Iteration: 885 Train loss: 1.519315 Train acc: 0.320000\n",
      "Epoch: 148/200 Iteration: 890 Train loss: 1.459592 Train acc: 0.360000\n",
      "Epoch: 148/200 Iteration: 890 Validation loss: 1.521150 Validation acc: 0.340000\n",
      "Epoch: 149/200 Iteration: 895 Train loss: 1.488615 Train acc: 0.410000\n",
      "Epoch: 149/200 Iteration: 900 Train loss: 1.418586 Train acc: 0.420000\n",
      "Epoch: 149/200 Iteration: 900 Validation loss: 1.516388 Validation acc: 0.345000\n",
      "Epoch: 150/200 Iteration: 905 Train loss: 1.455312 Train acc: 0.430000\n",
      "Epoch: 151/200 Iteration: 910 Train loss: 1.471695 Train acc: 0.360000\n",
      "Epoch: 151/200 Iteration: 910 Validation loss: 1.511568 Validation acc: 0.350000\n",
      "Epoch: 152/200 Iteration: 915 Train loss: 1.498336 Train acc: 0.360000\n",
      "Epoch: 153/200 Iteration: 920 Train loss: 1.452693 Train acc: 0.390000\n",
      "Epoch: 153/200 Iteration: 920 Validation loss: 1.506766 Validation acc: 0.360000\n",
      "Epoch: 154/200 Iteration: 925 Train loss: 1.500074 Train acc: 0.390000\n",
      "Epoch: 154/200 Iteration: 930 Train loss: 1.416568 Train acc: 0.420000\n",
      "Epoch: 154/200 Iteration: 930 Validation loss: 1.501886 Validation acc: 0.365000\n",
      "Epoch: 155/200 Iteration: 935 Train loss: 1.454285 Train acc: 0.440000\n",
      "Epoch: 156/200 Iteration: 940 Train loss: 1.456250 Train acc: 0.430000\n",
      "Epoch: 156/200 Iteration: 940 Validation loss: 1.497000 Validation acc: 0.380000\n",
      "Epoch: 157/200 Iteration: 945 Train loss: 1.493657 Train acc: 0.330000\n",
      "Epoch: 158/200 Iteration: 950 Train loss: 1.428590 Train acc: 0.390000\n",
      "Epoch: 158/200 Iteration: 950 Validation loss: 1.492094 Validation acc: 0.380000\n",
      "Epoch: 159/200 Iteration: 955 Train loss: 1.464206 Train acc: 0.430000\n",
      "Epoch: 159/200 Iteration: 960 Train loss: 1.389912 Train acc: 0.440000\n",
      "Epoch: 159/200 Iteration: 960 Validation loss: 1.487092 Validation acc: 0.390000\n",
      "Epoch: 160/200 Iteration: 965 Train loss: 1.422789 Train acc: 0.490000\n",
      "Epoch: 161/200 Iteration: 970 Train loss: 1.441199 Train acc: 0.450000\n",
      "Epoch: 161/200 Iteration: 970 Validation loss: 1.481989 Validation acc: 0.405000\n",
      "Epoch: 162/200 Iteration: 975 Train loss: 1.475566 Train acc: 0.360000\n",
      "Epoch: 163/200 Iteration: 980 Train loss: 1.433355 Train acc: 0.420000\n",
      "Epoch: 163/200 Iteration: 980 Validation loss: 1.476902 Validation acc: 0.410000\n",
      "Epoch: 164/200 Iteration: 985 Train loss: 1.473147 Train acc: 0.440000\n",
      "Epoch: 164/200 Iteration: 990 Train loss: 1.366767 Train acc: 0.470000\n",
      "Epoch: 164/200 Iteration: 990 Validation loss: 1.471843 Validation acc: 0.420000\n",
      "Epoch: 165/200 Iteration: 995 Train loss: 1.407823 Train acc: 0.460000\n",
      "Epoch: 166/200 Iteration: 1000 Train loss: 1.443697 Train acc: 0.400000\n",
      "Epoch: 166/200 Iteration: 1000 Validation loss: 1.466755 Validation acc: 0.420000\n",
      "Epoch: 167/200 Iteration: 1005 Train loss: 1.474329 Train acc: 0.320000\n",
      "Epoch: 168/200 Iteration: 1010 Train loss: 1.396573 Train acc: 0.480000\n",
      "Epoch: 168/200 Iteration: 1010 Validation loss: 1.461639 Validation acc: 0.425000\n",
      "Epoch: 169/200 Iteration: 1015 Train loss: 1.456108 Train acc: 0.450000\n",
      "Epoch: 169/200 Iteration: 1020 Train loss: 1.370166 Train acc: 0.450000\n",
      "Epoch: 169/200 Iteration: 1020 Validation loss: 1.456429 Validation acc: 0.435000\n",
      "Epoch: 170/200 Iteration: 1025 Train loss: 1.402616 Train acc: 0.460000\n",
      "Epoch: 171/200 Iteration: 1030 Train loss: 1.423944 Train acc: 0.470000\n",
      "Epoch: 171/200 Iteration: 1030 Validation loss: 1.451138 Validation acc: 0.440000\n",
      "Epoch: 172/200 Iteration: 1035 Train loss: 1.455375 Train acc: 0.400000\n",
      "Epoch: 173/200 Iteration: 1040 Train loss: 1.362118 Train acc: 0.500000\n",
      "Epoch: 173/200 Iteration: 1040 Validation loss: 1.445785 Validation acc: 0.445000\n",
      "Epoch: 174/200 Iteration: 1045 Train loss: 1.442436 Train acc: 0.480000\n",
      "Epoch: 174/200 Iteration: 1050 Train loss: 1.375391 Train acc: 0.470000\n",
      "Epoch: 174/200 Iteration: 1050 Validation loss: 1.440427 Validation acc: 0.445000\n",
      "Epoch: 175/200 Iteration: 1055 Train loss: 1.404694 Train acc: 0.510000\n",
      "Epoch: 176/200 Iteration: 1060 Train loss: 1.422262 Train acc: 0.500000\n",
      "Epoch: 176/200 Iteration: 1060 Validation loss: 1.434987 Validation acc: 0.450000\n",
      "Epoch: 177/200 Iteration: 1065 Train loss: 1.439559 Train acc: 0.420000\n",
      "Epoch: 178/200 Iteration: 1070 Train loss: 1.337207 Train acc: 0.550000\n",
      "Epoch: 178/200 Iteration: 1070 Validation loss: 1.429595 Validation acc: 0.450000\n",
      "Epoch: 179/200 Iteration: 1075 Train loss: 1.428344 Train acc: 0.480000\n",
      "Epoch: 179/200 Iteration: 1080 Train loss: 1.349445 Train acc: 0.450000\n",
      "Epoch: 179/200 Iteration: 1080 Validation loss: 1.424103 Validation acc: 0.445000\n",
      "Epoch: 180/200 Iteration: 1085 Train loss: 1.398044 Train acc: 0.470000\n",
      "Epoch: 181/200 Iteration: 1090 Train loss: 1.403551 Train acc: 0.470000\n",
      "Epoch: 181/200 Iteration: 1090 Validation loss: 1.418549 Validation acc: 0.450000\n",
      "Epoch: 182/200 Iteration: 1095 Train loss: 1.411292 Train acc: 0.420000\n",
      "Epoch: 183/200 Iteration: 1100 Train loss: 1.375643 Train acc: 0.500000\n",
      "Epoch: 183/200 Iteration: 1100 Validation loss: 1.412976 Validation acc: 0.460000\n",
      "Epoch: 184/200 Iteration: 1105 Train loss: 1.403634 Train acc: 0.470000\n",
      "Epoch: 184/200 Iteration: 1110 Train loss: 1.343858 Train acc: 0.530000\n",
      "Epoch: 184/200 Iteration: 1110 Validation loss: 1.407291 Validation acc: 0.460000\n",
      "Epoch: 185/200 Iteration: 1115 Train loss: 1.359991 Train acc: 0.550000\n",
      "Epoch: 186/200 Iteration: 1120 Train loss: 1.363420 Train acc: 0.520000\n",
      "Epoch: 186/200 Iteration: 1120 Validation loss: 1.401527 Validation acc: 0.480000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 187/200 Iteration: 1125 Train loss: 1.399365 Train acc: 0.410000\n",
      "Epoch: 188/200 Iteration: 1130 Train loss: 1.330843 Train acc: 0.510000\n",
      "Epoch: 188/200 Iteration: 1130 Validation loss: 1.395766 Validation acc: 0.485000\n",
      "Epoch: 189/200 Iteration: 1135 Train loss: 1.399923 Train acc: 0.520000\n",
      "Epoch: 189/200 Iteration: 1140 Train loss: 1.293825 Train acc: 0.530000\n",
      "Epoch: 189/200 Iteration: 1140 Validation loss: 1.389954 Validation acc: 0.490000\n",
      "Epoch: 190/200 Iteration: 1145 Train loss: 1.343659 Train acc: 0.520000\n",
      "Epoch: 191/200 Iteration: 1150 Train loss: 1.352073 Train acc: 0.480000\n",
      "Epoch: 191/200 Iteration: 1150 Validation loss: 1.384086 Validation acc: 0.500000\n",
      "Epoch: 192/200 Iteration: 1155 Train loss: 1.393610 Train acc: 0.440000\n",
      "Epoch: 193/200 Iteration: 1160 Train loss: 1.311744 Train acc: 0.520000\n",
      "Epoch: 193/200 Iteration: 1160 Validation loss: 1.378189 Validation acc: 0.500000\n",
      "Epoch: 194/200 Iteration: 1165 Train loss: 1.376629 Train acc: 0.520000\n",
      "Epoch: 194/200 Iteration: 1170 Train loss: 1.305052 Train acc: 0.530000\n",
      "Epoch: 194/200 Iteration: 1170 Validation loss: 1.372195 Validation acc: 0.515000\n",
      "Epoch: 195/200 Iteration: 1175 Train loss: 1.359070 Train acc: 0.480000\n",
      "Epoch: 196/200 Iteration: 1180 Train loss: 1.345142 Train acc: 0.560000\n",
      "Epoch: 196/200 Iteration: 1180 Validation loss: 1.366248 Validation acc: 0.515000\n",
      "Epoch: 197/200 Iteration: 1185 Train loss: 1.363599 Train acc: 0.490000\n",
      "Epoch: 198/200 Iteration: 1190 Train loss: 1.279644 Train acc: 0.600000\n",
      "Epoch: 198/200 Iteration: 1190 Validation loss: 1.360367 Validation acc: 0.515000\n",
      "Epoch: 199/200 Iteration: 1195 Train loss: 1.350871 Train acc: 0.520000\n",
      "Epoch: 199/200 Iteration: 1200 Train loss: 1.284426 Train acc: 0.540000\n",
      "Epoch: 199/200 Iteration: 1200 Validation loss: 1.354274 Validation acc: 0.525000\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 10 iterations\n",
    "            if (iteration%10 == 0):                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                \n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0}  \n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-cnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 10 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 10 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints-cnn/har.ckpt\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[1 1 4 1 5 4 5 0 5 2 0 1 0 5 0 5 0 5 1 0 5 1 5 5 0 1 0 4 5 2 0 5 1 1 5 0 5\n",
      " 4 0 5 0 5 5 4 5 4 1 1 4 0 0 4 1 0 5 5 5 0 1 5 5 5 0 1 0 0 0 1 4 4 5 0 0 4\n",
      " 0 1 4 0 0 5 0 0 5 0 4 0 1 5 5 5 4 1 0 0 1 5 0 4 0 5]\n",
      "0.44\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "[5 2 5 5 1 0 0 4 5 0 0 1 0 5 1 5 1 5 0 5 0 1 5 4 5 1 0 4 4 1 1 0 5 1 0 2 5\n",
      " 5 0 5 1 1 0 1 4 5 0 4 1 0 0 5 4 5 5 4 0 5 5 4 4 5 4 4 1 0 2 0 4 4 0 5 4 5\n",
      " 0 5 0 4 5 5 2 4 0 5 5 5 5 0 0 5 1 5 5 4 1 4 4 1 2 0]\n",
      "0.49\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n",
      "[0 4 5 1 1 0 5 1 4 2 5 0 5 5 2 1 1 5 0 2 1 2 1 5 5 5 1 4 0 1 0 5 0 4 1 4 1\n",
      " 5 5 0 0 1 5 1 5 4 5 0 1 5 5 0 0 1 5 0 4 0 0 4 1 5 4 1 0 0 5 5 0 1 0 1 4 4\n",
      " 1 4 5 0 4 5 4 5 5 5 5 5 4 0 0 0 0 4 0 0 1 5 5 1 5 5]\n",
      "0.58\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 4 4 5 1 4 5 0 0 1 4 5 5 5 5 5 4 5 0 4 1 1 4 0 1 5 0 4 5 5 1 0 5 4 4\n",
      " 1 0 0 1 5 4 1 0 5 0 5 5 5 1 0 5 0 5 4 1 0 4 0 4 5 5 1 1 5 0 1 5 1 4 4 5 5\n",
      " 1 1 4 5 5 1 4 5 1 1 4 5 4 0 5 1 0 1 5 5 5 2 2 0 0 4]\n",
      "0.49\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "[4 0 0 5 0 4 5 1 0 5 0 5 0 5 4 0 5 0 0 0 5 5 4 5 1 0 5 5 2 1 5 5 0 5 0 1 0\n",
      " 5 0 0 0 5 5 5 2 5 2 0 0 4 0 1 4 5 4 0 1 1 5 4 0 4 0 5 0 5 5 0 0 5 0 4 0 1\n",
      " 5 5 0 4 0 0 0 5 0 4 5 4 5 4 4 0 5 0 5 4 5 5 5 4 0 1]\n",
      "0.53\n",
      "[[0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n",
      "[5 1 4 5 0 4 4 1 3 0 0 5 4 4 4 4 0 1 0 5 5 5 5 2 1 5 1 0 4 0 5 4 1 4 5 4 4\n",
      " 5 0 5 5 1 5 0 0 2 0 1 0 1 0 5 5 5 1 5 5 1 5 4 2 0 5 4 0 5 1 5 0 4 5 5 5 5\n",
      " 5 1 5 4 0 0 5 1 0 1 1 5 5 4 1 1 4 5 1 5 5 4 5 4 5 5]\n",
      "0.53\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n",
      "[0 5 0 0 4 0 1 5 4 5 0 5 5 5 4 5 0 1 5 0 4 4 4 1 5 0 5 0 5 5 0 5 5 4 5 4 0\n",
      " 0 0 4 5 4 1 5 5 5 4 0 1 0 0 5 1 1 2 0 1 5 5 0 0 4 5 5 0 0 1 4 5 5 0 0 1 5\n",
      " 2 5 4 4 4 0 0 2 1 0 1 5 1 4 5 0 4 4 4 5 0 1 4 5 4 5]\n",
      "0.57\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n",
      "[5 0 4 0 4 4 5 4 4 5 5 4 1 0 5 0 5 0 1 5 5 1 4 5 1 0 1 0 5 2 1 0 5 0 1 2 4\n",
      " 4 4 0 2 0 0 4 0 5 0 5 1 0 1 0 1 5 4 4 4 0 5 5 5 1 0 5 1 5 0 4 0 5 4 5 5 1\n",
      " 4 5 5 5 5 4 4 5 2 4 5 4 0 4 1 0 5 1 4 0 4 4 0 5 4 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]]\n",
      "[1 4 2 0 5 0 5 2 1 2 4 0 5 5 5 4 0 5 1 0 4 5 5 5 1 0 5 4 0 5 5 0 4 5 5 4 0\n",
      " 1 0 0 5 5 5 5 4 5 5 4 5 1 0 1 0 1 4 0 4 0 0 1 0 0 5 1 2 5 5 1 1 2 5 0 0 5\n",
      " 4 0 5 5 5 4 5 0 5 4 4 4 0 1 5 5 0 5 4 0 2 1 5 1 0 0]\n",
      "0.49\n",
      "Test accuracy: 0.522222\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-cnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        print(y_t)\n",
    "        print(sess.run(tf.argmax(logits, 1), feed_dict=feed))\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        print(batch_acc)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
